% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Notas de Clase: Series de Tiempo},
  pdfauthor={Benjamín Oliva, Omar Alfaro Rivera \& Emiliano Pérez Caullieres},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Notas de Clase: Series de Tiempo}
\author{Benjamín Oliva, Omar Alfaro Rivera \& Emiliano Pérez Caullieres}
\date{2023-12-04}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{anuxe1lisis-de-series-de-tiempo}{%
\chapter*{Análisis de Series de Tiempo}\label{anuxe1lisis-de-series-de-tiempo}}
\addcontentsline{toc}{chapter}{Análisis de Series de Tiempo}

\textbf{Notas de Clase}

\textbf{Otoño 2023}

by Benjamín Oliva, Omar Alfaro Rivera \& Emiliano Pérez Caullieres

\includegraphics[width=4.16667in,height=3.125in]{Portada.png}

\hypertarget{contexto-del-documento}{%
\section*{Contexto del documento}\label{contexto-del-documento}}
\addcontentsline{toc}{section}{Contexto del documento}

Estas son notas de clase de la materia de Análisis de Series de Tiempo en la Facultad de Economía de la Universidad Nacional Autónoma de México.

Este es un trabajo siempre en proceso de mejora, para cualquier comentario o aclaración, contactar al correo \href{mailto:benjov@ciencias.unam.mx}{\nolinkurl{benjov@ciencias.unam.mx}} o \href{mailto:omarxalpha@gmail.com}{\nolinkurl{omarxalpha@gmail.com}}.

La versión PDF de estas notas se encuentra en: \url{https://github.com/benjov/Series-Tiempo/blob/main/docs/Notas-Series-Tiempo.pdf}

Las tablas de datos empleadas en los diferentes ejemplos se encuentran en: \url{https://github.com/benjov/Series-Tiempo/tree/main/BD}

\hypertarget{introducciuxf3n}{%
\chapter{Introducción}\label{introducciuxf3n}}

Estas notas son un resumen, una síntesis comparativa y, en algunos casos, una interpretación propia de los libros de texto de Brooks (2019), Cowpertwait y Metcalfe (2009), Guerrero-Guzmán (2014), Enders (2015), Franses y van Dijk (2003), Kirchgassner, Wolters, y Hassler (2012), Lutkepohl (2005), Wei (2019), entre otros. En algunos casos se incorpora información adicional para efectos de dar contexto al tema analizado (ver sección de Bibliografía para mayores detalles).

El objetivo de este documento es proporcionar un conjunto de apuntes o notas que sirvan de apoyo para la clase de Series de Tiempo en la Facultad de Economía de la UNAM. Por esta razón, no deben considerarse como notas exhaustivas o como un sustituto de la clase y los laboratorios. Asimismo, es deseable que los alumnos puedan aportar sus observaciones y correcciones a estas notas, las observaciones a estas notas son esperadas y siempre serán bienvenidas y agradecidas.

Este es un trabajo siempre en proceso de mejora, para cualquier comentario o aclaración, contactar al correo \href{mailto:benjov@ciencias.unam.mx}{\nolinkurl{benjov@ciencias.unam.mx}} o \href{mailto:omarxalpha@gmail.com}{\nolinkurl{omarxalpha@gmail.com}}.

En estas notas se estudian los temas que típicamente son incluidos como parte de un curso estándar de análisis de series de tiempo y agrega otros tantos, los cuales son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Modelos estacionarios univaraidos: \(AR(p)\), \(MA(q)\), \(ARMA(p, q)\) y \(ARIMA(p, d, q)\), y filtros para eliminar estacionalidad, entre otros;
\item
  Modelos no estacionarios univariados y Pruebas de raíz unitaria (o pruebas para determinar que una serie es estacionaria);
\item
  Modelos multivariados, entre lo que se incluye a los Vectores Autoregresivos (VAR) y los procedimientos de Cointegración
\item
  Modelación de series univariadas con errores con heterocedasticidad y autocorrelación: ARCH(r), GARCH(n), etc.;
\item
  Modelos multivariados con errores con heterocedasticidad y autocorrelación: M-GARCH y M-GARCH-M;
\item
  Casos particulares en los que las series incluidas en un modelo multivariado no son del mismo orden de integración, conocidos como modelos ADRL.
\item
  Modelos de Datos Panel en series de tiempo, y
\item
  Modelos no lineales como los de cambios de régimen.
\end{enumerate}

\hypertarget{la-naturaleza-de-los-datos-de-series-de-tiempo}{%
\section{La naturaleza de los datos de Series de Tiempo}\label{la-naturaleza-de-los-datos-de-series-de-tiempo}}

El análisis de series de tiempo tiene muchas aplicaciones en diversos campos de la ciencia. Por ejemplo, en la economía continuamente se está expuesto a información recopilada de los mercados financieros, indicadores de empleo, índices o indicadores del nivel de producción, índices de precios, etc. En otros campos de las ciencias sociales se emplea el análisis de series de tiempo para analizar la evolución de la población, los nacimientos, o el número de personas con matriculas escolares. Finalmente, en las ciencias exactas se pueden encontrar casos como los de un epidemiólogo que puede estar interesado en el número de casos de influenza observados en algún periodo de tiempo dado y si a estos se les puede asociar con algún tipo de estacionalidad o si se trata del inicio de un fenómeno atípico.

La primera aproximación que se suele tener a las series de tiempo es mediante el examen de datos puestos en una gráfica, en la cual uno de los ejes es el tiempo y el otro es el valor tomado por la variable. No obstante, en este tipo de exámenes existen dos enfoques. Por un lado, existe el efoque de la importancia del tiempo, el cual consiste en reconocer cómo lo que sucede hoy es afectado por lo que pasó ayer o, en general, en periodos pasados, o cómo lo que pasa hoy afectará los eventos futuros. Por otro lado, existe el enfoque del análisis frecuentista o de frecuencia, mediante el cual se busca reconocer la importancia que tiene para los investigadores los ciclos --por ejemplo, ciclos estacionales, momentos de crisis económicas, etc.--

\hypertarget{ejemplos-y-aplicaciones-de-las-series-de-tiempo}{%
\section{Ejemplos y aplicaciones de las Series de Tiempo}\label{ejemplos-y-aplicaciones-de-las-series-de-tiempo}}

Un primer ejemplo que puede ilustrar la presencia de los dos tipos de
enfoques antes mencionadas es la Figura \ref{fig:fig1}. En esta figura se muestra la evolución del Indicador Global de la Actividad Económica (IGAE) en su versión global o del total de la economía y en su versión únicamente para las actividades primarias entre enero de 2002 y mayo de 2023.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readxl)}

\NormalTok{Base\_1 }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_1\_TimeSeries.xlsx"}\NormalTok{)}
\NormalTok{IGAE\_2013 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{IGAE\_2013, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\NormalTok{IGAE\_PRIM\_2013 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{IGAE\_PRIM\_2013, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{) }
\NormalTok{ICC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{ICC, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\NormalTok{ICC\_LAG }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{ICC\_LAG, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\NormalTok{IPC\_BMV }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{IPC\_BMV, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\NormalTok{TDC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Base\_1}\SpecialCharTok{$}\NormalTok{TDC, }\AttributeTok{start =} \DecValTok{2002}\NormalTok{, }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(IGAE\_2013, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{60}\NormalTok{,}\DecValTok{160}\NormalTok{)) }
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ T) }
\CommentTok{\# Indicador Global de la Actividad Económica, Act. Prim., base 2008}
\FunctionTok{plot}\NormalTok{(IGAE\_PRIM\_2013, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }
     \AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{60}\NormalTok{,}\DecValTok{160}\NormalTok{))}
\CommentTok{\# Leyenda}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"IGAE"}\NormalTok{,}\StringTok{"IGAE Act. Prim."}\NormalTok{), }\AttributeTok{cex =} \FloatTok{0.8}\NormalTok{, }
       \AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig1-1} 

}

\caption{Indicador Global de Actividad Económica (IGAE) Global y para las Actividades Primarias (2008=100), Ene.2002 - May.2023}\label{fig:fig1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

Como se puede observar, el IGAE del total de la economía muestra, principalmente, que el enfoque del tiempo es más relevante. Es decir, que existe cierta persistencia en el indicador, lo que significa que la economía crece en razón del crecimiento reportado en periodos pasados. No obstante, lo que no podemos reconocer es que los eventos futuros tienen un efecto en el desempeño de la economía hoy día. Así, no es común observar cambios abruptos del indicador, salvo por la crisis global de 2008 y la reciente crisis causada por la Covid-19.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(ICC, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{29}\NormalTok{, }\DecValTok{50}\NormalTok{))}
\CommentTok{\# Comando que indica a R que sin borrar la grafica anterior, }
\CommentTok{\# grafique la siguiente.}
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ T) }
\CommentTok{\# Indice ??Como considera usted la situacion economica del pais }
\CommentTok{\# hoy en dia comparada con la de hace 12 meses?, base enero 2003}
\FunctionTok{plot}\NormalTok{(ICC\_LAG, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{29}\NormalTok{,}\DecValTok{50}\NormalTok{))}
\CommentTok{\# Leyenda}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomleft"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"ICC"}\NormalTok{,}\StringTok{"ICC lag"}\NormalTok{), }\AttributeTok{cex =} \FloatTok{0.8}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }
       \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig2-1} 

}

\caption{Índice de Confianza del Consumidor (ICC): General y resultado de ¿Cómo considera usted la situación economica del país hoy en día comparada con la de hace 12 meses? (puntos), Ene.2002-may.2023}\label{fig:fig2}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

Por el contrario, el IGAE de las actividades primarias muestra una presencia significativa de la importancia de la frecuencia. No pasa desapercibido que existen muchos ciclos en la evolución del indicador. Algo que suena común en las actividades primarias, cuya producción depende de eventos que son ciclícos agrícolas asociados con el clima u otros factores determinantes de la oferta de productos agrícolas. Otro factor que puede incluir en el indicador son elementos de demanda, más que los de oferta. Por ejemplo, el consumo de alimentos típicos de algunas temporadas del año.

Como segundo ejemplo, en la Figura \ref{fig:fig2} se ilustra la evolución reciente del índice de Confianza del Consumidor (ICC) en dos de sus versiones: i) el Índice global y ii) el Índice de confianza de los consumidores cuando estos consideran la situación actual en la economía en relación el año anterior.

Destacamos que el ICC mide las expectativas de los consumidores en razón de la información pasada y de la esperada, segun dichos consumidores.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\CommentTok{\# Indice de Precios y Cotizaciones de la Bolsa Mexicana de Valores}
\FunctionTok{plot}\NormalTok{(IPC\_BMV, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Indice de Precios y }\SpecialCharTok{\textbackslash{}n}\StringTok{Cotizaciones BMV"}\NormalTok{)}
\CommentTok{\# Tipo de Cambio para Solventar Obligaciones en Moneda Extranjera}
\FunctionTok{plot}\NormalTok{(TDC, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Pesos X Dolar"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Tipo de Cambio"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig3-1} 

}

\caption{índice de Precios y Cotizaciones de la Bolsa Mexicana de Valores (Panel Derecho) y Tipo de Cambio para Solventar Obligaciones en Moneda Extranjera, pesos por dólar (Panel izquierdo), Ene.2002-May.2023}\label{fig:fig3}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Así, es probable que las dos series de tiempo exhiban un gran peso para los eventos pasados, pero a la vez, un componente --probablemente menor-- del componente de frecuencia. Esto último en razón de que los consumidores suelen considerar en sus expectativas de consumo los periódos cíclicos de la economía: temporadas navideñaas, pagos de colegiaturas, etc. Este sengundo ejemplo tambien ilustra que la confianza del consumidor no necesariamente está directamente correlacionada con el desempeño de la economía.

Como tercer ejemplo se muestra la evolución de dos series. La Figura \ref{fig:fig3} ilustra el comportamiento reciente de dos indicadores que son referencia para los inversionistas. Por un lado, se ubica el índice de Precios y Cotizaciones de la BMV (IPC), el cuál refleja el valor de las acciones de empresas que cotizan en la BMV y el volumen de acciones comercializadas, en conjunto. De esta forma, se ha interpretado que el IPC refleja el rendimiento del capital promedio invertido en las empresas que cotizan en la BMV.

Por otro lado, en la Figura \ref{fig:fig3} se presenta la evolución del Tipo de Cambio (TDC) --indicador financiero que se suele utilizar como medio de reserva de valor--. Esto, en razón de que el TDC es conocido como un instrumento que en momentos de crisis toma valores contraciclicos de la economía mexicana. No obstante, ambos indicadores no son comparables. Para hacerlos comparbles en la Figura \ref{fig:fig4} se presentan en versión índice con una base en el primer mes de la muestra.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{IPC\_BMV\_I }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{IPC\_BMV}\SpecialCharTok{/}\NormalTok{IPC\_BMV[}\DecValTok{1}\NormalTok{]}
\NormalTok{TDC\_I }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{TDC}\SpecialCharTok{/}\NormalTok{TDC[}\DecValTok{1}\NormalTok{]}
\CommentTok{\# Indice del indice de Precios y Cotizaciones de la Bolsa Mexicana }
\CommentTok{\# de Valores}
\FunctionTok{plot}\NormalTok{(IPC\_BMV\_I, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{80}\NormalTok{,}\DecValTok{740}\NormalTok{))}
\CommentTok{\# Comando que indica a R que sin borrar la grafica anterior, }
\CommentTok{\# grafique la siguiente.}
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ T)}
\CommentTok{\# Indice del Tipo de Cambio para Solventar Obligaciones en }
\CommentTok{\# Moneda Extranjera}
\FunctionTok{plot}\NormalTok{(TDC\_I, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Indice"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{80}\NormalTok{,}\DecValTok{740}\NormalTok{))}
\CommentTok{\# Leyenda}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"Indice del IPC"}\NormalTok{,}\StringTok{"Indice del TDC"}\NormalTok{), }\AttributeTok{cex =} \FloatTok{0.8}\NormalTok{, }
       \AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig4-1} 

}

\caption{Índice del índice de Precios y Cotizaciones de la Bolsa Mexicana de Valores (Panel Derecho) e Índice del Tipo de Cambio para Solventar Obligaciones en Moneda Extranjera (ambos enero de 2002 = 100), pesos por dólar (Panel izquierdo), Ene.2002-May.2023 }\label{fig:fig4}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

En la perspectiva de la Figura \ref{fig:fig4} se puede apreciar que el TDC no es tan rentable, ya que una inversión en la BMV mediante el IPC, en el largo plazo, muestra más redimientos. Asimismo, la Figura \ref{fig:fig4} ilustra que en ambas series se observa un dominio de la condición de tiempo y no uno de frecuencia. Es decir, tanto el IPC como el TDC no responden a condiciones como ciclos o temporadas que si son observables en actividades económicas como las
primarias.

Finalmente, la Figura \ref{fig:fig5} ilustra un característica que también resulta de gran interés en el analásis de series de tiempo: los datos de alta frecuencia y de comportamiento no regular. Como se puede observar, en la Figura \ref{fig:fig5} se muestran las diferencias logarítmicas de las series de IGAE de la actividad total, el IPC y el TDC.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\CommentTok{\# Indicador Global de la Actividad Econ?mica, base 2008}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(IGAE\_2013), }\AttributeTok{lag =} \DecValTok{1}\NormalTok{), }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Var. \%"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Indicador Global de la Actividad Economica"}\NormalTok{) }
\CommentTok{\# Indice de Precios y Cotizaciones de la Bolsa Mexicana de Valores}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(IPC\_BMV), }\AttributeTok{lag =} \DecValTok{1}\NormalTok{), }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Var. \%"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Indice de Precios y Cotizaciones BMV"}\NormalTok{)}
\CommentTok{\# Tipo de Cambio para Solventar Obligaciones en Moneda Extranjera}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(TDC), }\AttributeTok{lag =} \DecValTok{1}\NormalTok{), }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Pesos X Dolar"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Tipo de Cambio"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig5-1} 

}

\caption{Tasas de Crecimiento mensuales (diferencias logarítmicas) de Indicador Global de la Actividad Económica, Índice de Precios y Cotizaciones de la Bolsa Mexicana de Valores (Panel Derecho) y Tipo de Cambio para Solventar Obligaciones en Moneda Extranjera, Ene.2002-May.2023}\label{fig:fig5}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Dichas diferencias se pueden interpretar como una tasa de crecimiento de las series por las siguientes razones. Consideremos una serie de tiempo dada por \(y_t\), cuya versión logarítmica es \(ln(y_t\)). De esta forma, la diferencia logarítmica esta dada por la ecuación \eqref{eq:difflog}:

\begin{equation}
   \Delta ln(y_t) = ln(y_t) - ln(y_{t-1}) = ln \left( \frac{y_t}{y_{t-1}} \right)
   \label{eq:difflog}
\end{equation}

Ahora bien, si retomamos la definición de tasa de crecimiento (TC) de una serie de tiempo \(y_t\) entre el periodo \(t\) y \(t-1\) podemos obtener que:

\begin{equation}
    TC = \frac{y_t - y_{t-1}}{y_{t-1}} = \frac{y_t}{y_{t-1}} - 1
    \label{eq:TC}
\end{equation}

De esta forma, si tomamos el logarítmo de la expresión de la ecuación \eqref{eq:TC} obtenemos la siguiente aproximación:

\begin{equation}
    \frac{y_t}{y_{t-1}} -1  \approx ln \left( \frac{y_t}{y_{t-1}} \right) = ln(y_t) - ln(y_{t-1})
    \label{eq:TCDiffLog}
\end{equation}

La ecuación \eqref{eq:TCDiffLog} es cierta cuando los valores de \(y_t\) y \(y_{t-1}\) son muy parecidos, es decir, cuando las variaciones no son tan abruptas. Otra forma de interpretar la ecuación \eqref{eq:TCDiffLog} es que para tasas de crecimiento pequeñas, se puede utilizar como una buena aproximación a la diferencia logarítmica mostrada en la ecuación \eqref{eq:difflog}.

En la Figura \ref{fig:fig5} se reportan las diferencias logarítmicas del IGAE, IPC y TDC, todos, como una media de distitntos tipos de redimientos. Es decir, podemos decir que un capitalista promedio (suponiendo que solo puede invertir en la actividad económica, en la bolsa o en el dólar), puede observar que le es más redituable en función de sus preferencias.

Notése que la dinámica de las variaciones de cada una de las series es significativamente diferente. Destaca que el TDC es una de las variables que, en general, no muestra grandes cambios a lo largo del tiempo. No obstante, se han observado cambios radicales, cuando menos en el año 2008. Lo anterior, son caracteristicas que se han observado para el IPC. En cambio, el IGAE muestra un comportamiento más estable o estacionario.

\hypertarget{elementos-de-ecuaciones-en-diferencia}{%
\chapter{Elementos de Ecuaciones en Diferencia}\label{elementos-de-ecuaciones-en-diferencia}}

\hypertarget{ecuaciones-en-diferencia-para-procesos-deterministas}{%
\section{Ecuaciones en Diferencia para procesos deterministas}\label{ecuaciones-en-diferencia-para-procesos-deterministas}}

En el capítulo previo se hizó una introducción al concepto de series de tiempo. En este Capítulo se pretende desarrollar la construcción de los procesos generadores de datos de las series de tiempo. En un sentido más formal, se expondrá que las series de tiempo se pueden considerar como una secuencia de variables aleatorias.

Para tales efectos, se desarrollará una introducción al concepto de ecuaciones en diferencia. Así, las preguntas que se pretende responder son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  ¿Cuál es la solución de la ecuación en diferencia que se estudia?
\item
  ¿Cuáles son las condiciones para que un proceso estocástico, representado mediante una ecuación en diferencia, llegue a alcanzar un punto de equilibrio en el largo plazo?
\end{enumerate}

El término de \emph{ecuación en diferencia} sirve para denominar un proceso similar o equivalente dentro de las ecuaciones diferenciales, dentro del cual se consideran a un conjunto de variables que están en función del tiempo. Así, si consideramos al tiempo como una variable continua, es decir, consideramos una variable \(Z(t)\), podemos expresar las siguientes expresiones para la ecuación diferencial:
\begin{equation}
    \frac{dZ(t)}{dt}; \frac{d^2Z(t)}{dt^2}; \ldots; \frac{d^kZ(t)}{dt^k}
        \label{eq:eqDiff}
\end{equation}

Por otro lado, suponiendo el caso del tiempo en forma discreta, es decir, con \(t = \ldots, -2, -1, 0, 1, 2, \ldots\), entonces el comportamiento de la serie de variables dadas por \(Z_t\), la cual se puede expresar como:
\begin{equation}
    \Delta Z_t; \Delta^2 Z_t; \ldots; \Delta^k Z_t
    \label{eq:Diff1}
\end{equation}

Observemos que una forma técnicamente más correcta es escribir las expresiones anteriores como:
\begin{equation}
    \frac{\Delta Z_t}{\Delta t}; \frac{\Delta^2 Z_t}{\Delta t^2}; \ldots; \frac{\Delta^k Z_t}{\Delta t^k}
    \label{eq:Diff2}
\end{equation}

No obstante, no pasa desapercibido que \(\Delta t = 1\), por lo que resultan equivalentes ambos conjuntos de expresiones \eqref{eq:Diff1} y \eqref{eq:Diff2}.

\hypertarget{ecuaciones-en-diferencia-lineales-de-primer-orden}{%
\subsection{Ecuaciones en Diferencia Lineales de Primer Orden}\label{ecuaciones-en-diferencia-lineales-de-primer-orden}}

El primer caso que se suele estudiar en relación a Ecuaciones en Diferencia es el de las Ecuaciones en Diferencia Lineales de Primer Orden. Al respecto, al igual que en el caso continúo, las variaciones de la variable \(Z_t\) se pueden expresar como se ilustra en el siguiente ejemplo. Consideremos la siguiente ecuación:
\begin{equation}
    Z_t = a_0 + a_1 Z_{t-1}
    \label{eq:EDPO}
\end{equation}

Donde, \(t = \ldots, -2, -1, 0, 1, 2, \ldots\), y \(a_0\) y \(a_1 \neq 0\) son números reales constantes. De \eqref{eq:EDPO} podememos despejar la variable \(Z_{t-1}\) y obtener una forma de ecuación en diferencia:
\begin{equation}
    Z_t - a_1 Z_{t-1} = a_0
    \label{eq:EDPO2}
\end{equation}

Ahora denotemos a \(L Z_t = Z_{t-1}\), es decir, mediante el operador \(L\) se puede rezagar una variable dada. En general, podemos decir que el operador tiene dos propiedades, la primera es que es lineal en el sentido de que abre sumas y saca escalares como se muestra en la siguiente expresión para el caso de un (1) rezago:
\begin{equation}
    L(\alpha Z_{t} + \beta) = \alpha Z_{t-1} + \beta
    \label{eq:E1Lag}
\end{equation}

Donde \(\alpha, \beta \in \mathbb{R}\) y \(\alpha, \beta \neq 0\). Otro reesultado implícito en esta primera propiedad es que el operador rezago aplicado a cualquier escalar dará como resultado el escalar, puesto que este es una constante sin importa el momento \(t\) en el cual se encuentre la variable \(Z\).

La segunda propiedad del operador es que se puede aplicar de forma consecutiva a una misma variable. Es decir, \(L ( Z_{t-1}) = L L Z_{t} = L^2 Z_{t}\), por lo que en general tendremos: \(L^p Z_t = Z_{t-p}\) (con \(p \in \mathbb{Z}\)). Así, en el caso de \(p\) rezagos la propiedad de linealidad del operador rezago será:
\begin{equation}
    L^p (\alpha Z_{t} + \beta) = \alpha Z_{t-p} + \beta
   \label{eq:LinProp}
\end{equation}

Dicho lo anterio podemos escribir la solución general de \eqref{eq:EDPO2} como:
\begin{eqnarray}
    Z_t - a_1 L Z_t & = & a_0 \nonumber \\
    (1 - a_1 L)Z_t & = & a_0 \nonumber \\
    Z_t & = & a_0 \frac{1}{1 - a_1 L} + s a^t_1 \nonumber \\
    Z_t & = & a_0 \frac{1}{1 - a_1} + s a^t_1
    \label{eq:PROC01}
\end{eqnarray}

Donde \(a_1 \neq 1\) y \(t = \ldots, -2, -1, 0, 1, 2, \ldots\). Notése que la aplicación del operador rezago \(L\) a la constante \(a_1\) dará como resultado el valor de la misma constante, ya que ésta no depende del momento \(t\) en el cuál observemos a la variable \(Z_t\). En la ecuación \eqref{eq:PROC01} se adiciona un término \(s a^t_1\) que permite ubicar la trayectoria inicial de la solución de la ecuación. El componente no significa un cambio respecto de la ecuación \eqref{eq:EDPO2} original, ya que si buscaramos reconstruir a ésta ecuación tendríamos:
\begin{eqnarray}
    (1 - a_1 L) s a^t_1 & = & s a^t_1 - a_1 s L a^{t}_1 \nonumber \\
    & = & s a^t_1 - a_1 s a^{t - 1}_1 \nonumber \\
    & = & s a^t_1 - s a^t_1 \nonumber \\
    & = & 0 \nonumber
\end{eqnarray}

La ecuación \eqref{eq:PROC01} se suele interpretar como la solución de largo plazo. Ahora demostraremos por qué es cierta la ecuación y discutiremos algunas condiciones que se deben observar en esta solución para que sea una solución convergente. No obstante, primero discutiremos un método indirecto e incompleto para demostrar el resultado, dicho método es conocido como el método iterativo. Plantearemos las siguientes ecuaciones partículares donde suponemos la existencia del valor inicial \(Z_0\) del proceso:
\begin{equation*}
    Z_1 = a_0 + a_1 Z_0
\end{equation*}

\begin{eqnarray*}
Z_2 & = & a_0 + a_1 Z_1 \\
    & = & a_0 + a_1 (a_0 + a_1 Z_0) \\
    & = & a_0 +  a_0 a_1 + a^2_1 Z_0 \\
    & = & a_0 (1 + a_1) + a^2_1 Z_0
\end{eqnarray*}

\begin{eqnarray*}
Z_3 & = & a_0 + a_1 Z_2 \\
    & = & a_0 + a_1 (a_0 +  a_0 a_1 + a^2_1 Z_0) \\
    & = & a_0 +  a_0 a_1 + a_0 a^2_1 + a^3_1 Z_0 \\
    & = & a_0 (1 + a_1 + a^2_1) + a^3_1 Z_0
\end{eqnarray*}

De lo anterior se puede inferir que el método iterativo convergerá hacia una expresión como la siguiente en el momento \(t\):
\begin{eqnarray}
Z_t & = & a_0 + a_1 Z_{t-1} \nonumber \\
    & = & a_0 (1 + a_1 + a^2_1 + \ldots + a^{t-1}_1) + a^t_1 Z_0 \nonumber \\
    & = & a_0 \sum^{t-1}_{i = 0}{a^i_1} + a^t_1 Z_0
    \label{eq:SUM}
\end{eqnarray}

Donde, es necesario que en la ecuación \eqref{eq:SUM} se cumpla que \(\lvert{a_1}\lvert < 1\) para que la suma sea convergente --más adelante detallaremos esta afirmación--. A este tipo de ecuaciones se les puede denominar como lineales. Esto en razón de que ningún término de la variable \(Z\) aparce elevado a ninguna potencia distinta a 1. También, son de primer orden, ya que el rezago de la variable \(Z\) es sólo de un período.

En adelante trabajaremos con ecuaciones en las que la variable \(Z\) se encuentra rezagada en cualquiera de los siguientes casos:
\begin{equation}
    Z_t, Z_{t-1}, Z_{t-2}, Z_{t-3}, \ldots, Z_{t-p}, \ldots
    \label{eq:SUM0}
\end{equation}

Por lo que diremos que en adelante el curso versará sobre ecuaciones en diferencia lineales y de cualquier orden \(p\).

Retomando la ecuación \eqref{eq:SUM} y considerando la parte de la suma de los términos de \(a^i_1\), de tal forma que buscaremos dar una expresión más compresible a dicho término. Definamos la siguiente expresión como:
\begin{equation}
    S_{t-1} = \sum^{t-1}_{i = 0}{a^i_1}
    \label{eq:St1}
\end{equation}

Por lo tanto, \(S_t\) estaría dado por la siguiente expresión:
\begin{eqnarray}
S_{t} & = & a_1 \sum^{t-1}_{i = 0}{a^i_1} \nonumber \\
      & = & a_1 (1 + a_1 + a^2_1 + \ldots + a^{t-1}_1) \nonumber \\
      & = & a_1 + a^2_1 + a^3_1 + \ldots + a^{t}_1 \nonumber \\
      & = & a_1 S_{t-1}
      \label{eq:St}
\end{eqnarray}

Tomando los dos resultados de las ecuaciones \eqref{eq:St1} y \eqref{eq:St} anteriores, podemos expresar que si a \(S_{t-1}\) le restamos \(S_t\), y desarrollando ambos lados de la ecuación anterior podemos obtener:
\begin{eqnarray}
    S_{t-1} - a_1 S_{t-1} & = & S_{t-1} - S_{t} \nonumber \\
    (1 - a_1) S_{t-1} & = & (1 + a_1 + a^2_1 + \ldots + a^{t-1}_1) - (a_1 + a^2_1 + a^3_1 + \ldots + a^{t}_1) \nonumber \\
    (1 - a_1) S_{t-1} & = & 1 - a^{t}_1 \nonumber
\end{eqnarray}

Así, podemos concluir que:
\begin{equation}
    S_{t-1} = \frac{1 - a^{t}_1}{1 - a_1}
    \label{eq:SUM2}
\end{equation}

Conjuntando éste último resultado de la ecuación \eqref{eq:SUM2} con la ecuación \eqref{eq:SUM} tenemos la siguiente solución por el método de iteración:
\begin{equation}
    Z_t = a_0 \left( \frac{1 - a^{t}_1}{1 - a_1} \right) + a^t_1 Z_0
    \label{eq:SOLITER}
\end{equation}

De esta forma la ecuación \eqref{eq:SOLITER} es una solución para la ecuación \eqref{eq:SUM}, que es una ecuación de un proceso de una Ecuación en Diferencia plantenado en la ecuación \eqref{eq:EDPO}. Está solución aún no es general, en el sentido de que sea válida para cualquiel tipo de proceso: convergente o divergente. Dicha convergencia o divengencia estará determinada por el paramétro \(a_1\). No debe pasar desapercibido que cuando \(t \rightarrow \infty\) o cuando la muestra es muy grande (lo que es equivalente), podemos decir que la solución solo puede converger a la siguiente expresión cuando se considera que \(|a_1| < 1\):
\begin{equation}
    Z_t = a_0 \left( \frac{1}{1 - a_1} \right)
    \label{eq:trayec}
\end{equation}

Retomemos ahora el caso general descrito en la ecuación \eqref{eq:PROC01} y determinemos una solución general en la cual \(a_1 \neq 1\) y \(t = \ldots, -2, -1, 0, 1, 2, \ldots\). Para ello observemos que el siguiente componente en la ecuación mencionada se puede interpretar como la suma infinita de términos descritos como:
\begin{eqnarray}
    \frac{1}{1 - a_1} & = & 1 + a_1 + a_1^2 + \ldots + a_1^t + \ldots \nonumber \\
    & = & \sum_{i = 0}^{\infty} a_1^{i}
    \label{eq:SUMINF}
\end{eqnarray}

Donde claramente es necesario que \(|a_1| < 1\). Por lo tanto, sólo faltaría determinar el valor de la constante \(s\) en la ecuación \eqref{eq:PROC01} de la siguiente forma, supongamos que observamos el proceso en el momento inicial, por lo que es posible determinar el valor de la constante conociendo el valor inicial del proceso como sigue:
\begin{equation}
    Z_0 = a_0 \frac{1}{1 - a_1} + s
\label{eq:Z0}
\end{equation}

De la ecuación \eqref{eq:Z0} tenemos que:
\begin{equation}
    s = Z_0 - a_0 \frac{1}{1 - a_1}
\label{eq:eqs}
\end{equation}

Así, juntando la ecuación \eqref{eq:PROC01} y ecuación \eqref{eq:eqs} tenemos la expresión:
\begin{equation}
    Z_t = a_0 \frac{1 - a^t_1}{1 - a_1} + a^t_1 Z_0
\label{eq:SOLGEN}
\end{equation}

No debe pasar desapercibido que está solución es la misma que la mostrada en la ecuación \eqref{eq:SOLITER}, por lo que en realidad ambas ecuaciones son una solución general indistintamente entre las ecuaciones \eqref{eq:SOLITER} y \eqref{eq:SOLGEN}. Ambas convergen a la expresión como la ecuación \eqref{eq:trayec}, con la misma condición de convergencia \(|a_1| < 1\). Para ilustrar estas ecuaciones veámos algunos ejemplos al respecto.

Consideremos que tenemos un proceso \(Z_t\) que es descrito por una ecuación en diferencia lineal de primer orden dada por:
\begin{equation}
    Z_t = 2 + 0.9 Z_{t-1}
\label{eq:ex1}
\end{equation}

Siguiendo la expresión mostrada en la ecuación \eqref{eq:SOLGEN}, obtenemos la expresión:
\begin{equation}
    Z_t = 2 \left( \frac{1 - 0.9^{t}}{1 - 0.9} \right) + 0.9^t Z_0
\label{eq:ex2}
\end{equation}

Donde asumiremos que el valor inicial es \(Z_0 = 10\) y que la expresión debe converger al valor de 20, cuando \(t\) es muy grande o tiende a infinito. De forma similar tomemos otro ejemplo, en el cual asumimos la siguiente expresión:
\begin{equation}
    Z_t = 2 - 0.5 Z_{t-1}
\label{eq:ex3}
\end{equation}

Siguiendo la expresión mostrada en la ecuación \eqref{eq:SOLGEN}, obtenemos:
\begin{equation}
    Z_t = 2 \left( \frac{1 - (-0.5)^{t}}{1 + 0.5} \right) + (-0.5)^t Z_0
\label{eq:ex4}
\end{equation}

Donde asumiremos que el valor inicial es \(Z_0 = 10\) y que la ecuación converge al valor de \(1.3333333 \ldots\), cuando \(t\) es muy grande o tiende a infinito. Ahora simulemos el comportamiento de ambos procesos y estableceremos los resultados del Cuadro \ref{tab:table1}. Notemos que el segundo proceso converge de una forma más rapida que el primero. El Cuadro \ref{tab:table1} se ilustra en las siguientes dos Figura \ref{fig:fig21} y Figura \ref{fig:fig22}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(knitr)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(kableExtra)}

\NormalTok{Tiempo }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{)}
\NormalTok{Zt }\OtherTok{=} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\DecValTok{101}\NormalTok{)}
\NormalTok{Zt2 }\OtherTok{=} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\DecValTok{101}\NormalTok{)}
\NormalTok{Zt[}\DecValTok{1}\NormalTok{] }\OtherTok{=} \DecValTok{10}
\NormalTok{Zt2[}\DecValTok{1}\NormalTok{] }\OtherTok{=} \DecValTok{10}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\SpecialCharTok{:}\DecValTok{101}\NormalTok{))\{}
\NormalTok{  Zt[i] }\OtherTok{=} \DecValTok{2}\FloatTok{+0.9}\SpecialCharTok{*}\NormalTok{Zt[i}\DecValTok{{-}1}\NormalTok{]}
\NormalTok{  Zt2[i] }\OtherTok{=} \DecValTok{2} \SpecialCharTok{{-}} \FloatTok{0.5}\SpecialCharTok{*}\NormalTok{Zt2[i}\DecValTok{{-}1}\NormalTok{]}
\NormalTok{\}}
\NormalTok{lista }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{16}\NormalTok{, }\DecValTok{97}\SpecialCharTok{:}\DecValTok{101}\NormalTok{)}
\NormalTok{Tiempo1 }\OtherTok{=}\NormalTok{ Tiempo[lista]}
\NormalTok{Zt1}\OtherTok{=}\NormalTok{Zt[lista]}
\NormalTok{Zt21}\OtherTok{=}\NormalTok{Zt2[lista]}

\NormalTok{tabla1 }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(Tiempo1, Zt1, Zt21)}
\FunctionTok{colnames}\NormalTok{(tabla1) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{, }\StringTok{"$Z\_t =2+0.9Z\_\{t{-}1\}$"}\NormalTok{, }
                      \StringTok{"$Z\_t = 2{-}0.5Z\_\{t{-}1\}$"}\NormalTok{)}

\FunctionTok{kable}\NormalTok{(tabla1, }
      \AttributeTok{caption =} \StringTok{"Dos ejemplos de Ecuaciones Lineales de Primer Orden"}\NormalTok{, }
      \AttributeTok{format =} \StringTok{"pandoc"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable\_styling}\NormalTok{(}\AttributeTok{font\_size =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrr@{}}
\caption{\label{tab:table1}Dos ejemplos de Ecuaciones Lineales de Primer Orden}\tabularnewline
\toprule\noalign{}
Tiempo & \(Z_t =2+0.9Z_{t-1}\) & \(Z_t = 2-0.5Z_{t-1}\) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Tiempo & \(Z_t =2+0.9Z_{t-1}\) & \(Z_t = 2-0.5Z_{t-1}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 10.00000 & 10.000000 \\
1 & 11.00000 & -3.000000 \\
2 & 11.90000 & 3.500000 \\
3 & 12.71000 & 0.250000 \\
4 & 13.43900 & 1.875000 \\
5 & 14.09510 & 1.062500 \\
6 & 14.68559 & 1.468750 \\
7 & 15.21703 & 1.265625 \\
8 & 15.69533 & 1.367188 \\
9 & 16.12580 & 1.316406 \\
10 & 16.51322 & 1.341797 \\
11 & 16.86189 & 1.329102 \\
12 & 17.17570 & 1.335449 \\
13 & 17.45813 & 1.332275 \\
14 & 17.71232 & 1.333862 \\
15 & 17.94109 & 1.333069 \\
96 & 19.99960 & 1.333333 \\
97 & 19.99964 & 1.333333 \\
98 & 19.99967 & 1.333333 \\
99 & 19.99970 & 1.333333 \\
100 & 19.99973 & 1.333333 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tabla }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{( Tiempo, Zt, Zt2 )}

\FunctionTok{ggplot}\NormalTok{( }\AttributeTok{data =}\NormalTok{ tabla , }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Tiempo, }\AttributeTok{y =}\NormalTok{ Zt) )}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{col=}\StringTok{"blue4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{col=} \StringTok{"blue4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\FunctionTok{expression}\NormalTok{(Z[t]))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig21-1} 

}

\caption{Evolución del proceso dado por $Z_t =2+0.9Z_{t-1}$}\label{fig:fig21}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ tabla , }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Tiempo, }\AttributeTok{y=}\NormalTok{Zt2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{col=}\StringTok{"red4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{col=} \StringTok{"red4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\FunctionTok{expression}\NormalTok{(Z[t]))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig22-1} 

}

\caption{Evolución del proceso dado por $Z_t =2-0.5Z_{t-1}$}\label{fig:fig22}
\end{figure}

\hypertarget{ecuaciones-en-diferencia-lineales-de-segundo-orden-y-de-orden-superior}{%
\subsection{Ecuaciones en Diferencia Lineales de Segundo Orden y de orden superior}\label{ecuaciones-en-diferencia-lineales-de-segundo-orden-y-de-orden-superior}}

Como un segundo caso a estudiar se ubica el caso de las Ecuaciones en Diferencia Lineales de Segundo Orden y de orden superior. Primero, sea una ecuación como la siguiente, la cual es lineal y de segundo orden, ya que tiene asociado un término de \(Z_t\) rezagado dos periódos:
\begin{equation}
    Z_t = a_0 + a_1 Z_{t-1} + a_2 Z_{t-2}
    \label{eq:EDSO}
\end{equation}

Donde \(t = \ldots, -2, -1, 0, 1, 2, \ldots\) y \(a_1, a_2 \neq 0\). Reordenando la ecuación \eqref{eq:EDSO} podemos escribir:
\begin{eqnarray}
    Z_t - a_1 Z_{t-1} - a_2 Z_{t-2} & = & a_0 \nonumber \\
    Z_t - a_1 L Z_{t} - a_2 L^2 Z_{t} & = & a_0 \nonumber \\
    (1 - a_1 L - a_2 L^2)Z_t & = & a_0 
    \label{eq:EDSOSOL}
\end{eqnarray}

Así, la solución general propuesta para la ecuación \eqref{eq:EDSOSOL} es la siguiente, la cual es una forma analóga a una Ecuación Lineal en Diferencia de Primer Orden:
\begin{equation}
    Z_t = \frac{a_0}{1 - a_1 - a_2} + s_1 g^t_1 + s_2 g^t_2
    \label{eq:SOLGEN2}
\end{equation}

En donde \(s_1\) y \(s_2\) son constantes que se determinan mediante dos condiciones iniciales --por lo que para resolver este tipo de ecuaciones requerimos conocer dos condiciones iniciales--. Los valores de \(g_1\) y \(g_2\) están relacionados con los coeficientes \(a_1\) y \(a_2\), de esta forma:
\begin{equation}
  a_1  =  g_1 + g_2
  \label{eq:a1}
\end{equation}

\begin{equation}
    a_2  =  - g_1 g_2
    \label{eq:a2}
\end{equation}

Lo anterior surge del siguiente procedimiento y recordando que siempre es posible descomponer una ecuación cuadrática en expresiones como las siguientes:
\begin{eqnarray}
    (1 - a_1 L - a_2 L^2) & = & (1 - g_1 L)(1 - g_2 L) \nonumber \\
    & = & 1 - g_1 L - g_2 L + g_1 g_2 L^2 \nonumber \\
    & = & 1 - (g_1 + g_2) L + g_1 g_2 L^2
    \label{eq:eqcaracteristica}
\end{eqnarray}

Donde se observa la equivalencia mostrada en las ecuaciones \eqref{eq:a1} y \eqref{eq:a2}. Así, considerando la ecuación \eqref{eq:SOLGEN2} tenemos que:
\begin{eqnarray}
    (1 - a_1 L - a_2 L^2) Z_t & = & (1 - g_1 L)(1 - g_2 L) Z_t \nonumber \\
    & = & a_0 + (1 - g_1 L)(1 - g_2 L) s_1 g^t_1 \nonumber \\
    &  & + (1 - g_1 L)(1 - g_2 L) s_2 g^t_2
    \label{eq:eqcaracteristica1}
\end{eqnarray}

Por lo tanto, buscamos que para que el proceso sea equivalente y podamos interpretar que la ecuación \eqref{eq:SOLGEN2} sea una solución general deberá pasar lo siguiente:
\begin{equation}
    (1 - g_1 L) (1 - g_2 L) s_1 g^t_1 + (1 - g_1 L) (1 - g_2 L) s_2 g^t_2 = 0
    \label{eq:eqcaracteristica2}
\end{equation}

O, escrito de otra forma:
\begin{equation}
    (1 - g_1 L) s_1 g^t_1 = (1 - g_2 L) s_2 g^t_2 = 0
    \label{eq:eqcaracteristica3}
\end{equation}

Ahora determinemos cuáles son los valores \(g_1\) y \(g_2\) dados los valores \(a_1\) y \(a_2\) que nos permitan determinar si el proceso será convergente. Para ello debemos resolver la siguiente ecuación que se deriva de la ecuación \eqref{eq:eqcaracteristica}:
\begin{equation}
    1 - a_1 x - a_2 x^2 = (1 - g_1 x)(1 - g_2 x) = 0
    \label{eq:eqcaracteristica4}
\end{equation}

Donde, claramente existen dos raíces: \(x_1 = g^{-1}_1\) y \(x_2 = g^{-1}_2\). Así, la solución estará dada por las raíces de la ecuación característica:
\begin{eqnarray}
    1 - a_1 x - a_2 x^2 = 0 \nonumber \\
    a_2 x^2 + a_1 x - 1 = 0
    \label{eq:POL2}
\end{eqnarray}

Cuya solución es:
\begin{equation}
    x = \frac{- a_1 \pm \sqrt{a^2_1 + 4 a_2}}{2 a_2}
    \label{eq:eqcaracteristica5}
\end{equation}

Es importante distinguir tres diferentes casos en relación con las raíces que surgen como solución de la ecuación \eqref{eq:POL2}, estos son:

\textbf{Caso I}. Si \(a^2_1 + 4 a_2 > 0\), la ecuación \eqref{eq:POL2} proporcionará dos valores de raíces reales y distintos, eso es \(x_1 = g^{-1}_1 \neq x_2 = g^{-1}_2\). Si por ahora suponemos que \(|{g_1} < 1|\) y que \(|{g_2} < 1|\), entonces tendremos que:
\begin{eqnarray}
    (1 - g_1 L)^{-1} (1 - g_2 L)^{-1} a_0 & =&  \left( \sum^{\infty}_{j = 0}{g^j_1 L^j} \right) \left( \sum^{\infty}_{j = 0}{g^j_2 L^j} \right) a_0 \nonumber \\
    & = & \left( \sum^{\infty}_{j = 0}{g^j_1} \right) \left( \sum^{\infty}_{j = 0}{g^j_2} \right) a_0 \nonumber \\
    & = & \frac{a_0}{(1 - g_1)(1 - g_2)} \nonumber \\
    & = & \frac{a_0}{1 - a_1 - a_2}
    \label{eq:eqcaracteristica6}
\end{eqnarray}

Esto último es el punto de equilibrio de la ecuación \eqref{eq:SOLGEN2}; considerando que \(|{g_1} < 1|\) y que \(|{g_2} < 1|\) --notemos que los demás casos son divergentes, ya que la suma anterior nno connvergería--. De esta forma la solución de la ecuación estará dada por:
\begin{equation}
    \lim_{t \to \infty} Z_t = \frac{a_0}{1 - a_1 - a_2}
    \label{eq:Conver}
\end{equation}

\textbf{Caso II}. Si \(a_1^2 + 4a_2 < 0\) en la ecuación \eqref{eq:POL2}, entonces las raíces serán números complejos conjugados, es decir:
\begin{equation}
g_i^{-1}=a \pm ib
\label{eq:Conver1}
\end{equation}

\begin{eqnarray}
    g_i  =  u \pm iv 
    \label{eq:Conver2}
\end{eqnarray}

Dichas raíces las podemos escribir en coordenadas polares como:
\begin{eqnarray}
    g_1^{-1} = r e^{i \theta} = r (cos(\theta) + i sen(\theta))
    \label{eq:Conver3}
\end{eqnarray}
\begin{eqnarray}
    g_2^{-1}  =  r e^{-i \theta} = r (cos(\theta) - i sen(\theta))
    \label{eq:Conver4}
\end{eqnarray}
Donde: \(r = \sqrt{u^2 + v^2}\), a esta expresión también se le conoce como modulo. Alternativamente, podemos escribir que \(r = \sqrt{g_1 g_2}\). La única condición es que \(r < 1\) para que el proceso descrito en la ecuación \eqref{eq:SOLGEN2} sea convergente.

Al igual que en el \textbf{Caso I}, el punto de equilibrio de la ecuación se debería ubicar al rededor \eqref{eq:Conver}, siempre que \(r < 1\), por lo que el factor que determina la convergencia es el modulo, ya que si el modulo es mayor a 1, el proceso será divergente, pero si es menor a 1 convergerá a \eqref{eq:Conver}. Para ilustrar, el caso contrario es divergente puesto que representa trayentorias senoidales (oscilatorias) que sólo pueden converger si a medida que pasa el tiempo, las ondas son menos amplias.

\textbf{Caso III}. Ahora revisemos el caso en el que \(a_1^2 + 4a_2 = 0\), de esta forma las raíces serán identicas:
\begin{equation}
    g = g_1^{-1} = g_2^{-1} = \frac{-a_1}{2 a_2}
    \label{eq:Conver6}
\end{equation}

Así, el punto de equilibrio será dado por la solución descrita como:
\begin{eqnarray}
    (1 - g L)^2 Z_t & = & a_0 \nonumber \\
    Z_t & = & \frac{a_0}{(1 - g L)^2} + s_1 g^t + s_2 t g^t \nonumber \\
    & = & a_0 \sum_{i = 0}^{\infty} (1 + i) g^j + s_1 g^t + s_2 t g^t
    \label{eq:Conver7}
\end{eqnarray}

Donde la expresión amnterior es resultado de considerar el siguiente procedimiento. Sea:
\begin{eqnarray}
    f(g) & = & \frac{1}{(1 - g)} = \sum_{j = 0}^{\infty} g^j \nonumber
\end{eqnarray}

Por lo que si hacemos la primer derivada del la expresión anterior tenemos que:
\begin{eqnarray}
    f'(g) & = & \frac{1}{(1 - g)^2} \nonumber \\
    & = & \sum_{j = 0}^{\infty} j g^{j-1} \nonumber \\
    & = & 0 + g^0 + 2 g^1 + 3 g^2 + \ldots \nonumber \\
    & = & \sum_{j = 0}^{\infty} (1 + j) g^j \nonumber
\end{eqnarray}

Ahora veámos un ejemplo de una Ecuación Lineal en Diferencia de Segundo Orden. Supongamos la ecuación y el desarrollo siguientes:
\begin{eqnarray}
    Z_t & = & 3 + 0.9 Z_{t-1} - 0.2 Z_{t-2} \nonumber \\
    (1 - 0.9 L + 0.2 L^2) Z_t & = & 3 \nonumber
\end{eqnarray}

La solución dada por una ecuación similar a la expresión \eqref{eq:POL2}, obtendríamos la solución dada por las ecuaciones equivalentes a:
\begin{eqnarray}
    1 - 0.9 x + 0.2 x^2 = 0 \nonumber \\
    - 0.2 x^2 + 0.9 x - 1 = 0 \nonumber
\end{eqnarray}

De donde las raíces del polinomio característico \(x_1 = g_1^{-1}\) y \(x_2 = g_2^{-1}\) se obtienen de la expresión dada por:
\begin{eqnarray}
    x & = &\frac{-0.9 \pm \sqrt{0.81 + (4)(-0.2)}}{(2)(-0.2)} \nonumber \\
    & = & \frac{0.9 \pm 0.1}{0.4} \nonumber
\end{eqnarray}

Dado que el componente \(a^2_1 + 4 a_2\) es positivo, obtendremos dos raíces reales. Las raíces estarán dadas por \(x_1 = 2.5\) y \(x_2 = 2.0\), de lo cual podemos determinar que \(g_1 = 0.4\) y \(g_2 = 0.5\). De esta forma tenemos que \(|g_1| < 1\) y \(|g_2| < 1\), así la ecuación converge a la expresión dada por las siguientes expresiones:
\begin{eqnarray}
    Z_t & = & \frac{3}{1 - 0.9 L + 0.2 L^2} + s_1 (0.4)^t + s_2 (0.5)^t \nonumber \\
    & = & \frac{3}{1 - 0.9 + 0.2} + s_1 (0.4)^t + s_2 (0.5)^t \nonumber \\
    & = & \frac{3}{(1 - 0.4)(1 - 0.5)} + s_1 (0.4)^t + s_2 (0.5)^t \nonumber
\end{eqnarray}

Al final, la ecuación que describe la solución general será:
\begin{equation}
    z_t = 10 + s_1 (0.4)^t + s_2 (0.5)^t
    \label{eq:Conver9}
\end{equation}

Para determinar los valores de \(s_1\) y \(s_2\) necesitamos obtener dos valores iniciales de la ecuación para lo cual iniciaremos como \(t = 0\) y luego obtenemos el valor de \(t = 1\), consideremos el valor de \(Z_0 = 0\) y \(Z_1 = 50\):
\begin{eqnarray*}
    Z_0 & = & 10 + s_1(0.4)^0  + s_2(0.5)^0 \\
    0 & = & 10 + s_1 + s_2 \\
    Z_1 & = & 10 + s_1(0.4)^1  + s_2(0.5)^1 \\
    50 & = & 10 + 0.4 s_1 + 0.5 s_2
\end{eqnarray*}

Por lo que la solución es: \(s_1 = -450\) y \(s_2 = 440\), de donde podemos expresar la ecuación como:
\begin{equation}
    Z_t = 10 - 450(0.4)^t + 440(0.5)^t
\label{eq:Ejem01}
\end{equation}

La ecuación \eqref{eq:Ejem01} anterior convergerá al valor de 10 cuando \(t \rightarrow \infty\). Para ilustrar la trayectoria de esta ecuación tomemos un cuadro similar al de los ejemplos anteriores. En el Cuadro \ref{tab:table2} y la Figura \ref{fig:fig23} mostramos los resultados de la trayectorua para 100 periodos.

Finalmente, discutiremos la solución para las Ecuaciones Lineales en Diferencia de Orden \(p\), donde \(p \geq 2\). En general una ecuación de este tipo se puede escribir como:
\begin{equation}
    Z_t = a_0 + a_1 Z_{t-1} + a_2 Z_{t-2} + \ldots + a_p Z_{t-p}
    \label{eq:EDOP}
\end{equation}

Donde \(t = \ldots, -2, -1, 0, 1, 2, \ldots\) y \(a_p \neq 0\). La ecuación \eqref{eq:EDOP} se puede escribir como:
\begin{eqnarray}
    Z_t - a_1 Z_{t-1} - a_2 Z_{t-2} - \ldots - a_p Z_{t-p} & = & a_0 \nonumber \\
    Z_t - a_1 L Z_t - a_2 L^2 Z_t - \ldots - a_p L^p Z_t & = & a_0 \nonumber \\
    (1 - a_1 L - a_2 L^2 - \ldots - a_p L^p) Z_t & = & a_0
    \label{eq:EDOP2}
\end{eqnarray}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\OtherTok{=} \FunctionTok{ts}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{))}

\NormalTok{Zt }\OtherTok{=} \DecValTok{10{-}450}\SpecialCharTok{*}\NormalTok{(}\FloatTok{0.4}\SpecialCharTok{\^{}}\NormalTok{t)}\SpecialCharTok{+}\DecValTok{440}\SpecialCharTok{*}\NormalTok{(}\FloatTok{0.5}\SpecialCharTok{\^{}}\NormalTok{t)}

\NormalTok{tabla\_2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{( t, Zt) }

\NormalTok{lista }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{16}\NormalTok{, }\DecValTok{97}\SpecialCharTok{:}\DecValTok{101}\NormalTok{)}
\NormalTok{t1 }\OtherTok{=}\NormalTok{ t[lista]}
\NormalTok{Zt1}\OtherTok{=}\NormalTok{Zt[lista]}


\NormalTok{tabla1 }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(Tiempo1, Zt1)}
\FunctionTok{colnames}\NormalTok{(tabla1) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{, }\StringTok{"$Z\_t =10{-}450(0.4)\^{}t+440(0.5)\^{}t$"}\NormalTok{)}

\FunctionTok{kable}\NormalTok{(tabla1, }
      \AttributeTok{caption =} \StringTok{"Un ejemplo de Ecuación de Segundo Orden"}\NormalTok{, }
      \AttributeTok{format =} \StringTok{"pandoc"}\NormalTok{)}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable\_styling}\NormalTok{(}\AttributeTok{font\_size =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rr@{}}
\caption{\label{tab:table2}Un ejemplo de Ecuación de Segundo Orden}\tabularnewline
\toprule\noalign{}
Tiempo & \(Z_t =10-450(0.4)^t+440(0.5)^t\) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Tiempo & \(Z_t =10-450(0.4)^t+440(0.5)^t\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0.00000 \\
1 & 50.00000 \\
2 & 48.00000 \\
3 & 36.20000 \\
4 & 25.98000 \\
5 & 19.14200 \\
6 & 15.03180 \\
7 & 12.70022 \\
8 & 11.42384 \\
9 & 10.74141 \\
10 & 10.38250 \\
11 & 10.19597 \\
12 & 10.09987 \\
13 & 10.05069 \\
14 & 10.02565 \\
15 & 10.01294 \\
96 & 10.00000 \\
97 & 10.00000 \\
98 & 10.00000 \\
99 & 10.00000 \\
100 & 10.00000 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ tabla\_2, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ t, }\AttributeTok{y=}\NormalTok{Zt)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{col=}\StringTok{"green4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{col=} \StringTok{"green4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\FunctionTok{expression}\NormalTok{(Z[t]))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig23-1} 

}

\caption{Evolución del proceso dado por $Z_t =3+0.9Z_{t-1}-0.2Z_{t-2}$}\label{fig:fig23}
\end{figure}

Por el Teorema Fundamental del Álgebra es posible escribir a la ecuación \eqref{eq:EDOP2} como:
\begin{eqnarray}
    (1 - g_1 L)(1 - g_1 L) \ldots (1 - g_p L) Z_t & = & a_0
    \label{eq:EDOP3}
\end{eqnarray}

Utilizando la ecuación \eqref{eq:EDOP2} y la ecuación \eqref{eq:EDOP3} tenemos que la solución general de una ecuación como la descrita en \eqref{eq:EDOP} se puede escribir como:
\begin{equation}
    Z_t  =  \frac{a_0}{1 - a_1 - a_2 - \ldots - a_p} + s_1 g^t_1 + s_2 g^t_2 + \ldots + s_p g^t_p \\
    \label{eq:EDOPGEN}
\end{equation}\\
\begin{eqnarray}
    Z_t & = & \frac{a_0}{(1 - g_1)(1 - g_1) \ldots (1 - g_p)} + s_1 g^t_1 + s_2 g^t_2 + \ldots + s_p g^t_p 
    \label{eq:EDOPGEN2}
\end{eqnarray}

Donde \(s_1\), \(s_2\), \ldots, \(s_p\) son cosntantes que se determinan utilizando \(p\) valores partículares de \(Z_t\), y la solución general descrita en las ecuaciones \eqref{eq:EDOPGEN} y \eqref{eq:EDOPGEN2} implica encontrar \(p\) raíces: \(x_1 = g^{-1}_1\), \(x_2 = g^{-1}_2\), \ldots, \(x_p = g^{-1}_p\) de los siguientes polinomios equivalentes:
\begin{eqnarray}
    (1 - g_1)(1 - g_1) \ldots (1 - g_p) = 0
    \label{eq:POLGEN1}
\end{eqnarray}

\begin{eqnarray}
    1 - a_1 x - a_2 x^2 - \ldots - a_p x^p = 0
    \label{eq:POLGEN2}
\end{eqnarray}

\begin{eqnarray}
    a_p x^p + \ldots + a_2 x^2 + a_1 x - 1 = 0
    \label{eq:POLGEN3}
\end{eqnarray}

Antes de plantear la solución general, analicemos una solución patícular cuando un conjunto de las \(p\) raíces, digamos un total de \(m\), son iguales, es decir, cuando sucede que \(g_1 = g_2 = \ldots = g_m = g\) (con \(1 < m \leq p\)). En este caso la solución general en la ecuación \eqref{eq:EDOPGEN2} se escribe como:
\begin{eqnarray}
    Z_t & = & \frac{a_0}{(1 - g)^m(1 - g_{m+1}) \ldots (1 - g_p)} \nonumber \\ 
    & & + s_1 g^t + s_2 t g^t + \ldots + s_m t^{m-1} g^t + s_{m+1} g^t_{m+1} + \ldots + s_{p} g^t_{p}
    \label{eq:EDOPGEN3}
\end{eqnarray}

Definamos:
\begin{equation}
    f(g) = \frac{1}{1 - g} = \sum_{j = 0}^{\infty} g^j
    \label{eq:EDOPGEN4}
\end{equation}

Si retomamos el método descrito parráfos arriba tenemos las siguientes expresiones. Cuando \(m = 2\):
\begin{equation}
    f'(g) = \frac{1}{(1 - g)^2} = \sum_{j = 0}^{\infty} j g^{j-1} = \sum_{j = 0}^{\infty} (1 + j) g^j \nonumber
\end{equation}

En el otro extremo, cuando \(m = p\):
\begin{equation}
    f^{(p-1)}(g) = \frac{p-1}{(1 - g)^p} = \sum_{j = 0}^{\infty} \frac{(p-1+j)(p-2+j) \ldots (2+j)(1+j)}{(p-1)!} g^j
    \label{eq:EDOPGEN5}
\end{equation}

Así, en el extremo cuando \(m = p\) la solución general podría estar dada por:
\begin{eqnarray}
    Z_t & = & a_0 \sum_{j = 0}^{\infty} \frac{(p-1+j)(p-2+j) \ldots (2+j)(1+j)}{(p-1)!} g^j \nonumber \\
    & & + g^t \sum_{i = 0}^p s_i t^{i-1}
    \label{eq:EDOPGEN6}
\end{eqnarray}

Donde \(|{g} < 1|\), \(t = \ldots, -2, -1, 0, 1, 2, \ldots\). Para finalizar esta sección, plantearemos la expresión de polinomio característico que nos permitirá hacer el análisis de convergencia de los procesos. Partamos de que la ecuación \eqref{eq:POLGEN3} se puede escribir como:
\begin{equation}
    (x^{-1})^p - a_1 (x^{-1})^{p-1} - a_2 (x^{-1})^{p-1} - \ldots - a_p = 0
    \label{eq:POLGEN55}
\end{equation}

La ecuación \eqref{eq:POLGEN55} permite interpretar las raíces del polinomio característico de forma directa ya que \(x^{-1}_1 = g_1\), \(x^{-1}_2 = g_2\), \ldots, \(x^{-1}_p = g_p\). Así, siempre que \(p \geq 1\) en la ecuación \eqref{eq:EDOP}, diremos que el proceso descrito en esa ecuación dará como resultado un proceso convergente si se cumplen las dos condiciones \eqref{eq:COND1} y \eqref{eq:COND2}:
\begin{equation}
    |a_p| < 1  
    \label{eq:COND1}
\end{equation}
\begin{equation}
    a_1 + a_2 + \ldots + a_p < 1
    \label{eq:COND2}
\end{equation}

Alternativamente, cuando las raíces son reales lo anterior es equivalente a la expresión \eqref{eq:COND3}:
\begin{eqnarray}
    |g_i| < 1
    \label{eq:COND3}
\end{eqnarray}

Para \(\forall i = 1, 2, \ldots, p\). Cuando la raíces son imaginarias, las dos condiciones \eqref{eq:COND1} y \eqref{eq:COND2} son equivalentes a la expresión \eqref{eq:COND4}:
\begin{eqnarray}
    \sqrt{g_i g_j} = \sqrt{u^2 + v^2} < 1 
    \label{eq:COND4}
\end{eqnarray}

Para \(\forall i \neq j\) y \(i, j = 1, 2, \ldots, p\). Cuando \(g_1 = g_2 = \ldots = g_p = g\), la condición de la ecuación \eqref{eq:COND3} se resume a que \(|g| < 1\). En resumen, las condiciones descritas en las ecuaciones \eqref{eq:COND3} y \eqref{eq:COND4} se puden ilustrar con un circulo unitario como el de la Figura \ref{fig:fig24} en que sí las raíces se ubican dentro de éste, podemos decir que el proceso es convergente en el largo plazo.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Crear datos para el círculo}
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\SpecialCharTok{*}\NormalTok{pi, }\AttributeTok{length.out=}\DecValTok{100}\NormalTok{)}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{cos}\NormalTok{(theta)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{sin}\NormalTok{(theta)}
\NormalTok{circle\_data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(x, y)}

\CommentTok{\# Dibujar el círculo}
\FunctionTok{ggplot}\NormalTok{(circle\_data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x, }\AttributeTok{y=}\NormalTok{y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_polygon}\NormalTok{(}\AttributeTok{fill=}\ConstantTok{NA}\NormalTok{, }\AttributeTok{color=}\StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_fixed}\NormalTok{(}\AttributeTok{ratio=}\DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.5}\NormalTok{, }\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.5}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig24-1} 

}

\caption{Circulo unitario en el que se cumple que $|g_i|<1$ y $(g_i g_j)^{1/2} = (u^2 + v^2)^{1/2} < 1$}\label{fig:fig24}
\end{figure}

\hypertarget{operador-de-rezago-l}{%
\section{Operador de rezago L}\label{operador-de-rezago-l}}

Denotemos, como se ha mencionado con anterioridad, con \(L\) al operador de rezago, el cual nos permitirá construir una relación entre diferencias y medias móviles como se verá más adelante en los procesos univariados \(AR(p)\), \(MA(q)\) y, en general, \(ARIMA(p, d, q)\). Sean \(X\), \(Y\) o \(Z\) variables con las que denotaremos a una serie de tiempo (note que hasta el momento no hemos definido qué es una serie de tiempo, no obstante no es necesario definirla para hacer uso del operador).

En esta sección resumiremos algunas propiedades usadas en el capítulo y en capítulos más adelante. Así, si a dicha serie le aplicamos el operador rezago antes definido, el resultado deberá ser que cada uno de los valores de la serie es retardado o regresado un período. Es decir:

\begin{equation}
    L Z_t = Z_{t-1}
    \label{eq:Lag1}
\end{equation}

De esta forma, si aplicamos el operador rezago \(L\) a la nueva serie de tiempo dada por \(Z_{t-1}\) podemos obtener \(Z_{t-2}\), haciendo uso de la ecuación \eqref{eq:Lag1} podemos obtener:
\begin{equation}
    L Z_{t-1} = L(L Z_t) = L^2 Z_t = Z_{t-2}
    \label{eq:Lag2}
\end{equation}

Mediante una generalización podemos obtener:
\begin{equation}
    L^k Z_t = Z_{t-k}
    \label{eq:Lag3}
\end{equation}

Para \(k = \ldots, -2, -1, 0, 1, 2, \ldots\). Así, para \(k = 0\) obtenemos la identidad dado que \(L^0 Z_t = Z_t\), de tal forma que siempre asumiremos que \(L^0 = 1\). En otro caso, cuando \(k > 0\) a la serie de tiempo a la cual se le aplique el operador rezago \(L\) se le deberá aplicar un rezago de \(k\) periodos a cada uno de los elementos de la serie. Por el contrario, cuando \(k < 0\) el operador rezago significa que se deberá adelantar \(|k|\) veces a cada elemento de la serie. Por ejemplo, \(L^{-3} Z_t = Z_{t+3}\).

Las reglas descritas en lo subsecuente se mantienen indistintamene cuando aplican para el caso de rezagar como para cuando se adelanta una serie. Como primera propiedad tomemos a la siguiente propiedad:
\begin{equation}
    L^{m} Z_{t-n} = L^{m} (L^{n} Z_{t}) = L^{m + n} Z_{t} = Z_{t-(n + m)} 
    \label{eq:Lag4}
\end{equation}

De lo anterior podemos inferir el siguiente resultado:
\begin{equation}
    \Delta Z_{t} = Z_{t} - Z_{t-1} = (1 - L) Z_{t} 
    \label{eq:Lag5}
\end{equation}

En el caso de la diferencia de órden cuatro o cuarta diferencia se puede expresar como:
\begin{equation}
    \Delta_{4} Z_{t} = Z_{t} - Z_{t-4} = (1 - L^4) Z_{t}
\label{eq:Diff4}
\end{equation}

Al respecto, vale la pena aclarar que en ocaciones se hará uso de una notación alternativa dada por: \(\Delta^k\) o \(\Delta_k\), donde \(k = 1, 2, 3, \ldots\), indistintamente, ya que en ambos casos se referirá a una diferencia de orden \(k\). Esta notación resulta de gran utilidad cuando se quiere comparar periodos equivalentes como, por ejemplo, el mismo trimestre pero de un año anterior. De forma similar, para el caso de logarítmos podemos escribir a la ecuación \eqref{eq:Diff4} como:
\begin{equation}
    \Delta^{4} ln(Z_{t}) = \Delta_{4} ln(Z_{t}) = ln(Z_{t}) - ln(Z_{t-4}) = (1 - L^4) ln(Z_{t}) 
    \label{eq:Diff5}
\end{equation}

Para el caso de una serie de tiempo que se le ha transformado mediante medias móviles, digamos de \(4\) periodos, podemos escribirla como:
\begin{equation}
    Zs_{t} = \frac{1}{4}(Z_{t} + Z_{t-1} + Z_{t-2} + Z_{t-3}) = \frac{1}{4}(1 + L + L^2 + L^3)Z_{t}
    \label{eq:Diff6}
\end{equation}

Una generalización del anterior caso puede ser escrito como un polinomio de orden \(p\) con el operador rezago \(L\) dado como:
\begin{eqnarray}
    \alpha(L) Z_{t} & = & (1 - \alpha_1 L - \alpha_2 L^2 - \ldots - \alpha_p L^p) Z_{t} \nonumber \\
    & = & Z_{t} - \alpha_1 Z_{t-1} - \alpha_2 Z_{t-2} - \ldots - \alpha_p Z_{t-p}
\label{eq:Ecp1}
\end{eqnarray}

Donde \(\alpha_i\) puede ser remplazada por cualquier constante \(a_i\), con \(i = 1, 2, 3, \ldots\), para escribir ecuaciones como las anteriores. Adicionalmente, podemos decir que la ecuación \eqref{eq:Ecp1} es una generalización del caso de medias móviles, el cual admite una poderación distinta para cada uno de los elementos rezagados.

Existe la posibilidad de operar más de un polinomio a la vez. Para múltiples polinomios (digamos, los polinomios \(\alpha(L)\) y \(\beta(L)\)) podemos escribir el siguiente resultado:
\begin{equation}
    \alpha(L) \beta(L) = \beta(L) \alpha(L)
    \label{eq:Diff7}
\end{equation}

Tales polinomios del operador rezago también son llamados \emph{filtros lineales}. A manera de ejemplo tomemos el siguiente caso de diferencias para una serie de \(Z_t\):
\begin{equation}
    \Delta Z_{t} = (1 - L) Z_{t} = Z_{t} - Z_{t-1} 
    \label{eq:Diff8}
\end{equation}

y un proceso de medias móviles para la misma serie de \(Z_t\):
\begin{equation}
    Zs_{t} = \frac{1}{4}(1 + L^1 + L^2 + L^3) Z_{t} = \frac{1}{4}(Z_{t} + Z_{t-1} + Z_{t-2} + Z_{t-3}) 
    \label{eq:Diff9}
\end{equation}

De tal forma que el producto de ambos procesos se puede escribir como:
\begin{equation}
(1 - L) \times \frac{1}{4}(1 + L^1 + L^2 + L^3) Z_{t} = \frac{1}{4}(1 - L^4) Z_{t}
\label{eq:Diff10}
\end{equation}

Es decir, que el producto de dos polinomios, uno de diferencias y otro más de medias móviles, resulta en uno de diferencias pero de mayor grado, en este caso de grado 4.

\hypertarget{modelos-de-series-de-tiempo-estacionarias}{%
\chapter{Modelos de Series de Tiempo Estacionarias}\label{modelos-de-series-de-tiempo-estacionarias}}

\hypertarget{definiciuxf3n-de-ergodicidad-y-estacionariedad}{%
\section{Definición de ergodicidad y estacionariedad}\label{definiciuxf3n-de-ergodicidad-y-estacionariedad}}

A partir de esta sección introduciremos mayor formalidad matemática al análisis de las series de tiempo. Por ello cambiaremos un poco la notación y ocuparemos a \(X_t\) en lugar de \(Z_t\) como objeto de nuestro análisis. Con \(X_t\) denotaremos a una serie de tiempo, ya que con \(Z_t\) denotareemos a una variable, sin que ella fuera necesariamente una serie de tiempo en los términos que a continuación discutimos. Asimismo, iniciaremos por establecer una serie de definiciones.

De esta forma, definiremos a una \emph{serie de tiempo} como un vector de variables aleatorias de dimensión \(T\), dado como:
\begin{equation}
    X_1, X_2, X_3, \ldots ,X_T
    \label{eq:Serie0}
\end{equation}

Cada una de las \(X_t\) (\(t = 1, 2, \ldots, T\)) consideradas como una variable aleatoria. Así, también podemos denotar a la serie de tiempo como:
\begin{equation}
    \{ X_t \}^T_{t = 1}
    \label{eq:Serie}
\end{equation}

Es decir, definiremos a \emph{una serie de tiempo como una realización de un proceso estocástico} --o un Proceso Generador de Datos (PGD). Consideremos una muestra de los múlples posibles resultados de muestras de tamaño \(T\), la colección dada por:
\begin{equation}
    \{X^{(1)}_1, X^{(1)}_2, \ldots, X^{(1)}_T\}
    \label{eq:Serie1}
\end{equation}

Digamos que la ecuación \eqref{eq:Serie1} es una de las tantas posibles resultantes del proceso estocástico o PGD. Eventualmente podríamos estar dispuestos a observar este proceso indefinidamente, de forma tal que estemos interesados en observar a la secuencia dada por \(\{ X^{(1)}_t \}^{\infty}_{t = 1}\), lo cual no dejaría se ser sólo una de las tantas realizaciones o secuencias del proceso estocástico original.

Tan solo por poner un ejemplo, podríamos observar las siguientes realizaciones del mismo PGD:
\begin{eqnarray*}
    & \{X^{(2)}_1, X^{(2)}_2, \ldots, X^{(2)}_T\} & \\
    & \{X^{(3)}_1, X^{(3)}_2, \ldots, X^{(3)}_T\} & \\
    & \{X^{(4)}_1, X^{(4)}_2, \ldots, X^{(4)}_T\} & \\
    & \vdots & \\
    & \{X^{(j)}_1, X^{(j)}_2, \ldots, X^{(j)}_T\} & 
\end{eqnarray*}

Donde \(j \in \mathbb{Z}\). En lo subsecuente, diremos que una serie de tiempo es una realización del proceso estocástico subyacente. Considerando, en consecuencia, al proceso estocástico con todas sus posibilidades de realización.

Para hacer más sencilla la notación no distinguiremos entre el proceso en sí mismo y una de sus realizaciones, es decir, siempre escribiremos a una serie de tiempo como la secuencia mostrada en la ecuación \eqref{eq:Serie}, o más precisamente como la siguiente realización:
\begin{equation}
    \{ X_1, X_2, \ldots, X_T \}
    \label{eq:Serie2}
\end{equation}

O simplemente:
\begin{equation}
    X_1, X_2, \ldots, X_T
    \label{eq:Serie3}
\end{equation}

El proceso estocástico de dimensión \(T\) puede ser completamente descrito por su función de distribución multivaraida de dimensión \(T\). No obstante, esto no resulta ser práctico cuando se opere más adelante en el curso. Por ello, en el curso, y en general casi todos los textos lo hacen, sólo nos enfocaremos en sus primer y segundo momentos, es decir, en sus medias o valores esperados:
\begin{equation*}
    \mathbb{E}[X_t]
\end{equation*}

Para \(t = 1, 2, \ldots, T\); o:
\begin{equation*}
\left[
    \begin{array}{c}
    \mathbb{E}[X_1] \\
    \mathbb{E}[X_2] \\
    \vdots \\
    \mathbb{E}[X_T]
    \end{array}
\right]
\end{equation*}

o,
\begin{equation*}
\left[
    \begin{array}{c}
    \mathbb{E}[X_1], \mathbb{E}[X_2], \ldots, \mathbb{E}[X_T]
    \end{array}
\right]
\end{equation*}

De sus variazas:
\begin{equation*}
    Var[X_t] = \mathbb{E}[(X_t - \mathbb{E}[X_t])^2]
\end{equation*}

Para \(t = 1, 2, \ldots, T\), y de sus \(T(T-1)/2\) covarianzas:
\begin{equation*}
    Cov[X_t,X_s] = \mathbb{E}[(X_t - \mathbb{E}[X_t])(X_s - \mathbb{E}[X_s])]
\end{equation*}

Para \(t < s\). Por lo tanto, en la forma matricial podemos escribir lo siguiente:
\begin{equation*}
\left[
    \begin{array}{c c c c}
    Var[X_1] & Cov[X_1,X_2] & \cdots & Cov[X_1,X_T] \\
    Cov[X_2,X_1] & Var[X_2] & \cdots & Cov[X_2,X_T] \\
    \vdots & \vdots & \ddots & \vdots \\
    Cov[X_T,X_1] & Cov[X_T,X_2] & \cdots & Var[X_T] \\
    \end{array}
\right]
\end{equation*}

\begin{equation}
= \left[
    \begin{array}{c c c c}
    \sigma_1^2 & \rho_{12} & \cdots & \rho_{1T} \\
    \rho_{21} & \sigma_2^2 & \cdots & \rho_{2T} \\
    \vdots & \vdots & \ddots & \vdots \\
    \rho_{T1} & \rho_{T2} & \cdots & \sigma_T^2 \\
    \end{array}
\right]
    \label{eq:MATCOV}
\end{equation}

Donde es claro que en la matriz de la ecuación \eqref{eq:MATCOV} existen \(T(T-1)/2\) covarianzas distintas, ya que se cumple que \(Cov[X_t,X_s] = Cov[X_s,X_t]\), para \(t \neq s\).

A menudo, esas covarianzas son denominadas como autocovarianzas puesto que ellas son covarianzas entre variables aleatorias pertenecientes al mismo proceso estocástico pero en un momento \(t\) diferente. Si el proceso estocástico tiene una distribución normal multivariada, su función de distribución estará totalmente descrita por sus momentos de primer y segundo orden.

Ahora introduciremos el concepto de ergodicidad, el cual indica que los momentos muestrales, los cuales son calculados en la base de una serie de tiempo con un número finito de observaciones, en la medida que \(T \rightarrow \infty\) sus correspondientes momentos muestrales, tienden a los verdaderos valores poblacionales, los cuales definiremos como \(\mu\), para la media, y \(\sigma^2_X\) para la varianza.

Este concepto sólo es cierto si asumimos que, por ejemplo, el valor esperado y la varianza son como se dice a continuación para todo \(t = 1, 2, \ldots, T\):
\begin{eqnarray}
    \mathbb{E}[X_t] = \mu_t = \mu \\
    \label{MEDIA}
    \label{eq:ESPERANZA}
\end{eqnarray}
\begin{eqnarray}
    Var[X_t] = \sigma^2_X
    \label{eq:VARIANZA}
\end{eqnarray}

Mas formalmente, se dice que el PGD o el proceso estocástico es ergódico en la media si:
\begin{equation}
    \displaystyle\lim_{T \to \infty}{\mathbb{E} \left[ \left( \frac{1}{T} \sum^{T}_{t = 1} (X_t - \mu) \right) ^2 \right]} = 0
    \label{eq:LIM1}
\end{equation}

y ergódico en la varianza si:
\begin{equation}
    \displaystyle\lim_{T \to \infty}{\mathbb{E} \left[ \left( \frac{1}{T} \sum^{T}_{t = 1} (X_t - \mu) ^2 - \sigma^2_X \right) ^2 \right]} = 0
    \label{eq:LIM2}
\end{equation}

Estas condiciones se les conoce como \emph{propiedades de consistencia} para las variables aleatorias. Sin embargo, éstas no pueden ser probadas. Por ello se les denomina como un supuesto que pueden cumplir algunas de las series. Más importante aún: \textbf{un proceso estocástico que tiende a estar en equilibrio estadístico en un orden ergódico, es estacionario}.

Podemos distinguir dos tipos de estacionariedad. Si asumimos que la función común de distribución del proceso estocástico no cambia a lo largo del tiempo, se dice que el proceso es \emph{estrictamente estacionario}. Como este concepto es dificil de aplicar en la práctica, solo consideraremos a la \emph{estacionariedad débil} o estacionariedad en sus momentos.

Definiremos a la estacionariedad por sus momentos del correspondiente proceso estocástico dado por \(\{X_t\}\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Estacionariedad en media}: Un proceso estocástico es estacionario en media si \(E[X_t] = \mu_t = \mu\) es constante para todo \(t\).
\item
  \emph{Estacionariedad en varianza}: Un proceso estocástico es estacionario en varianza si \(Var[X_t] = \mathbb{E}[(X_t - \mu_t)^2] = \sigma^2_X = \gamma(0)\) es constante y finita para todo \(t\).
\item
  \emph{Estacionariedad en covarianza}: Un proceso estocástico es estacionario en covarianza si \(Cov[X_t,X_s] = \mathbb{E}[(X_t - \mu_t)(X_s - \mu_s)] = \gamma(|s-t|)\) es sólo una función del tiempo y de la distancia entre las dos variables aleatorias. Por lo que no depende del tiempo denotado por \(t\) (no depende de la información contemporánea).
\item
  \emph{Estacionariedad débil}: Como la estacionariedad en varianza resulta de forma inmediata de la estacionariedad en covarianza cuando se asume que \(s = t\), un proceso estocástico es débilmente estacionario cuando es estacionario en media y covarianza.
\end{enumerate}

Puesto que resulta poco factible asumir una estacionariedad diferente a la débil, es adelante siempre que digamos que un proceso es estacionario se referirá al caso débil y sólo diremos que el proceso es estacionario, sin el apelativo de débil.

Ahora veamos un ejemplo de lo anterior. Supongamos una serie de tiempo denotada por: \(\{U_t\}^T_{t = 0}\). Decimos que el proceso estocástico \(\{U_t\}\) es un \emph{proceso estocástico puramente aleatorio} o es un \emph{proceso estocástico de ruido blanco o caminata aleatoria}, si éste tiene las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathbb{E}[U_t] = 0\), \(\forall t\);
\item
  \(Var[U_t] = \mathbb{E}[(U_t - \mu_t)^2] = \mathbb{E}[(U_t - \mu)^2] = \mathbb{E}[(U_t)^2] = \sigma^2\), \(\forall t\), y
\item
  \(Cov[U_t,U_s] = \mathbb{E}[(U_t - \mu_t)(U_s - \mu_s)] = \mathbb{E}[(U_t - \mu)(U_s - \mu)] = \mathbb{E}[U_t U_s] = 0\), \(\forall t \neq s\).
\end{enumerate}

En otras palabras, un proceso \(U_t\) es un ruido blanco si su valor esperado (promedio) es cero (0), tiene una varianza finita y constante, y además no le importa la historia pasada. Así, su valor presente no se ve influenciado por sus valores pasados no importando respecto de que periodo se tome referencia.

En apariencia, por sus propiedades, este proceso es débilmente estacionario --o simplemente, estacionario--. Todas las variables aleatorias tienen una media de cero, una varianza \(\sigma^2\) y no existe correlación entre ellas.

Propongamos un ejemplo para ilustrar la teoría previa. Supongamos que definimos un nuevo proceso estocástico \(\{X_t\}\) como:
\begin{equation}
    X_t = \left\{ \begin{array}{l} U_0  \mbox{ para } t = 0 \\ X_{t-1} + U_t \mbox{ para } t = 1, 2, 3, \ldots \end{array}\right.
    \label{eq:em1}
\end{equation}

Donde \(\{ U_t \}\) es un proceso puramente aleatorio. Este proceso estocástico, o caminata aleatoria sin tendencia (ajuste - drift), puede ser reescrito como:
\begin{equation}
    X_t = \sum^t_{j = 0} U_j
    \label{eq:em2}
\end{equation}

Tratemos de dar más claridad al ejemplo, para ello asumamos que generamos a \(\{U_t\}\) por medio del lanzamiento de una moneda. Donde obtenemos una cara (águila) con una probabilidad de \(0.5\), en cuyo caso decimos que la variable aleatoria \(U_t\) tomará el valor de \(+1\), y una cruz (sol) con una probabilidad de \(0.5\), en cuyo caso decimos que la variable aleatoria \(U_t\) toma el valor de \(-1\).

Este planteamiento cumple con las propiedas enunciadas ya que:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathbb{E}[U_t] = 0.5 \times -1 + 0.5 \times 1 = 0\), \(\forall t\)
\item
  \(Var[U_t] = \mathbb{E}[(U_t - 0)^2] = \frac{1}{2}((-1)^2) + \frac{1}{2}((1)^2) = 1\), \(\forall t\)
\item
  \(Cov[U_t,U_s] = \mathbb{E}[(U_t - 0)(U_s - 0)] = \mathbb{E}[U_t \cdot U_s] = 0\), \(\forall t \neq s\).
\end{enumerate}

Retomando a nuestro proceso \(X_t\), diremos que el caso de \(X_0 = 0\), para \(t = 0\). Si verificamos cúales son sus primeros y segundos momentos de \(\{X_t\}\) tenemos:
\begin{equation}
    \mathbb{E}[X_t] = \mathbb{E}\left[ \sum^t_{j=1} U_j \right] = \sum^t_{j=1} \mathbb{E}[U_j] = 0
    \label{eq:em3}
\end{equation}

En cuanto a la varianza:
\begin{eqnarray}
    Var[X_t] & = & Var \left[ \sum^t_{j=1} U_j \right] \nonumber \\
    & = & \sum^t_{j=1} Var[U_j] + 2 * \sum_{j \neq k} Cov[U_j,U_k] \nonumber \\
    & = & \sum^t_{j=1} 1 \nonumber \\
    & = & t
    \label{eq:em4}
\end{eqnarray}

Lo anterior, dado que hemos supuesto que en la caminata aleatoria todas la variables aleatorias son independientes, es decir, \(Cov[U_t,U_s] = E[U_t \cdot U_s] = 0\). Por su parte, la covarianza del proceso estocástico se puede ver como:
\begin{eqnarray*}
    Cov[X_t,X_s] & = & \mathbb{E} \left[ \left( \sum^t_{j=1} U_j - 0 \right) \left( \sum^s_{i=1} U_i - 0 \right) \right] \\
    & = & \mathbb{E}[(U_1 + U_2 + \ldots + U_t)(U_1 + U_2 + \ldots + U_s)] \\
    & = & \sum^t_{j=1} \sum^s_{i=1} \mathbb{E}[U_j U_i] \\
    & = & \mathbb{E}[U^2_1] + \mathbb{E}[U^2_2] + \ldots + \mathbb{E}[U^2_k] \\
    & = & \sigma^2 + \sigma^2 + \ldots + \sigma^2 \\
    & = & 1 + 1 + 1 + 1 \\
    & = & min(t,s)
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\CommentTok{\# Utilizaremos una función guardada en un archivo a parte}
\CommentTok{\# Llamamos a la función:}
\FunctionTok{source}\NormalTok{(}\StringTok{"Caminata.R"}\NormalTok{)}

\CommentTok{\# Definimos argumentos de la función}
\NormalTok{Opciones }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\CommentTok{\#}
\NormalTok{Soporte }\OtherTok{\textless{}{-}} \DecValTok{10000}

\CommentTok{\# Vamos a réplicar el proceso con estos parámetros}
\NormalTok{Rango }\OtherTok{\textless{}{-}} \DecValTok{200}
\CommentTok{\#}
\NormalTok{Caminos }\OtherTok{\textless{}{-}} \DecValTok{10}

\CommentTok{\#}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{Caminos)\{}
\NormalTok{  TT }\OtherTok{\textless{}{-}} \FunctionTok{data.matrix}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{Caminata}\NormalTok{(Opciones, Soporte)[}\DecValTok{1}\NormalTok{]))}
  \CommentTok{\#}
\NormalTok{  G\_t }\OtherTok{\textless{}{-}} \FunctionTok{data.matrix}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{Caminata}\NormalTok{(Opciones, Soporte)[}\DecValTok{2}\NormalTok{]))}
  \CommentTok{\#}
  \FunctionTok{plot}\NormalTok{(TT, G\_t, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Ganancias"}\NormalTok{, }
       \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Rango,Rango))}
  \CommentTok{\#}
  \FunctionTok{par}\NormalTok{(}\AttributeTok{new =} \ConstantTok{TRUE}\NormalTok{)}
  \CommentTok{\#}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\DecValTok{1}
\NormalTok{\}}
\CommentTok{\#}
\FunctionTok{par}\NormalTok{(}\AttributeTok{new =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig31-1} 

}

\caption{Ejemplo de 10 trayectorias de la caminata aleatoria, cuando sólo es posible cambios de +1 y -1}\label{fig:fig31}
\end{figure}

Así, el proceso estocástico dado por la caminata alaeatoria sin un término de ajuste es estacionario en media, pero no en varianza o en covarianza, y consecuentemente, en general no estacionario, condición que contraria al caso del proceso simple descrito en \(U_t\).

Es facil ver que muchas de las posibilidades de realización de este proceso estocástico (series de tiempo) pueden tomar cualquiera de las rutas consideradas en el Figura \ref{fig:fig31}.

\hypertarget{funciuxf3n-de-autocorrelaciuxf3n}{%
\section{Función de autocorrelación}\label{funciuxf3n-de-autocorrelaciuxf3n}}

Para ampliar la discusión, es posible calcular la fuerza o intensidad de la dependencia de las variables aleatorias dentro de un proceso estocástico, ello mediante el uso de las autocovarianzas. Cuando las covarianzas son normalizadas respecto de la varianza, el resultado es un término que es independiente de las unidad de medida aplicada, y se conoce como la \emph{función de autocorrelación}.

Para procesos estacionarios, dicha función de autocorrelación esta dada por:
\begin{equation}
    \rho(\tau) = \frac{\mathbb{E}[(X_t - \mu)(X_{t+\tau} - \mu)]}{\mathbb{E}[(X_t - \mu)^2]} = \frac{\gamma(\tau)}{\gamma(0)}
    \label{eq:em5}
\end{equation}

Donde \(\tau = \ldots, -2, -1, 0, 1, 2, \ldots\). Dicha función tiene las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\rho(0) = 1\). Es fácil demostrar que la función \(\rho(0)\) es:
\end{enumerate}

\begin{equation}
    \rho(0) = \frac{\mathbb{E}[(X_t - \mu)(X_{t + 0} - \mu)]}{\mathbb{E}[(X_t - \mu)^2]} = \frac{\mathbb{E}[(X_t - \mu)^2]}{\mathbb{E}[(X_t - \mu)^2]} = 1
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\rho(\tau) = \rho(-\tau)\). Partiendo de la definción de \(\rho(\tau)\) podemos ver que la distancia que existe entre \(t\) y \(t + \tau\) es \(\tau\), de esta forma la autocorrelación de la variable \(X\) entre los periodos antes señalados debería ser la misma para el caso en que \(\rho(-\tau)\). Partamos de la ecuación para ver más claramente:
\end{enumerate}

\begin{equation}
    \rho(\tau) = \frac{\mathbb{E}[(X_t - \mu)(X_{t + \tau} - \mu)]}{\mathbb{E}[(X_t - \mu)^2]} = \frac{\mathbb{E}[(X_t - \mu)(X_{t - \tau} - \mu)]}{\mathbb{E}[(X_t - \mu)^2]} = \rho(-\tau)
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \(\lvert\rho(\tau)\lvert \leq 1\), para todo \(\tau\).
\end{enumerate}

Derivado de las propiedades 1 y 2 antes descritas se puede concluir que sólo es necesario conocer la función de autocorrelación para el caso de \(\tau = 1, 2, 3, \ldots\), ya que de estos casos podemos derivar los valores de la función de autocorrelación complementarios de \(\tau = \ldots, -3, -2, -1\).

Partiendo de los supuestos de ergodicidad en relación a la media, varianza y covarianzas de un proceso estacionario, podemos estimar dichos paramétros con las siguientes formulaciones o propuestas de estimadores puntuales:
\begin{equation}
    \hat{\mu} = \frac{1}{T} \sum^T_{t=1} X_t
    \label{eq:em6}
\end{equation}

\begin{equation}
    \hat{\gamma}(0) = \frac{1}{T} \sum^T_{t=1} (X_t - \hat{\mu})^2 = \hat{\sigma}^2
    \label{eq:em7}
\end{equation}

\begin{equation}
    \hat{\gamma}(\tau) = \frac{1}{T} \sum^{T - \tau}_{t=1} (X_t - \hat{\mu})(X_{t+\tau} - \hat{\mu}) \mbox{, para } \tau = 1, 2, \ldots, T-1
    \label{eq:em8}
\end{equation}

No hacemos la demostración en estas notas --sería deseable que el alumno revisará la afimación-- pero estos últimos son estimadores consistentes de \(\mu\), \(\gamma(0)\) y \(\gamma(\tau)\). Por su parte, un estimador consistente de la función de autocorrelación estará dado por:
\begin{equation}
  \hat{\rho}(\tau) = \frac{\sum^{T - \tau}_{t=1} (X_t - \hat{\mu})(X_{t+\tau} - \hat{\mu})}{\sum^T_{t=1} (X_t - \hat{\mu})^2} = \frac{\hat{\gamma}(\tau)}{\hat{\gamma}(0)}
  \label{eq:eqautocorr}
\end{equation}

El estimador de la ecuación \eqref{eq:eqautocorr} es asintóticamente insesgado. Por ejemplo, para el caso de un proceso de ruido blanco o caminata aleatoria, su varianza puede ser aproximada por el valor dado \(1/T\). Ésta tiene, asintóticamente, una distribución normal. Dado esto, el intervalo de confianza al \(95\%\) será el dado por \(\pm 2/\sqrt{T}\), en el cual se encuentra la mayoría de los coeficientes de autocorrelación estimados.

Ahora discutamos algunos ejemplos o aplicaciones. Cuando se realiza la evaluación de la estimación de un modelo de series de tiempo es importante saber si los residuales del modelo realmente tienen propiedades de un proceso puramente aleatorio, en partícular, si ellos no están correlacionados entre sí. Así, la hipotésis a probar será:
\begin{equation}
    H_0 : \rho(\tau) = 0 \mbox{, para todo } \tau = 1, 2, \ldots, m \mbox{ y } m < T
    \label{eq:eqautocorr1}
\end{equation}

Esta expresión se puede interpretar como una prueba respecto de si la correlación entre la información de periodos atrás es cero con la información contemporánea. Para hacer una pruena global de la hipotésis de sí un número \(m\) de coeficientes de autocovarianzas son cero Box y Pierce (1970) desarrollarón la siguiente estadística:
\begin{equation}
    Q^* = T \sum_{j = 1}^{m} \hat{\rho} (j)^2
    \label{eq:eqautocorr2}
\end{equation}

Bajo la hipotésis nula esta estadística se distribulle asintóticamente como una chi cuadrado (\(\chi^2\)) con \(m-k\) grados de libertad y con \(k\) que representa al número de paramétros estimados.

Haciendo una aplicación estricta de la distribución de esta estadística, sabemos que esta se mantiene asintóticamente. Greta, Ljung y Box (1978) propusieron la siguiente modificación de la estadística para muestras pequeñas:
\begin{equation}
    Q = T(T + 2) \sum_{j = 1}^{m} \frac{\hat{\rho} (j)^2}{T - j}
    \label{eq:eqautocorr3}
\end{equation}

La cual también se distribulle asintóticamente como \(\chi^2\) con \(m-k\) grados de libertad.

También es intuitivamente claro que la hipótesis nula de no autocorrelación de residuales debería ser rechazada si alguno de los valores \(\hat{\rho} (j)\) es muy grande, es decir, si \(Q\) o \(Q^*\) es muy grande. O más precisamente, si estas estadísticas son más grandes que los correspondientes valores críticos de la distribución \(\chi^2\) con \(m-k\) grados de libertad a algún grado dado de signficancia.

Una alternativa para esta prueba es una del tipo Multiplicadores de Lagrange (o LM) desarrollada por Breusch (1978) y Godfrey (1978). La cual, al igual que las estadísticas \(Q\) y \(Q^*\), la hipotesis nula está dada por:

\begin{quote}
\(H_0\): Los residuales no están autocorrelacionados.
\end{quote}

\begin{quote}
\(H_a\): Los residuales muestran alguna acutocorrelación de forma autoregresiva o de medias móviles.
\end{quote}

La prueba consiste en realizar una regresión auxiliar en la cual los residuales se estiman en función de las variables explicativas del modelo original y en los residuales mismos pero rezagados hasta el término \(m\) (regresión auxiliar). La prueba resulta en una estadìstica con una distribución \(\chi^2\) con \(m\) grados de libertad la cual está dada por la expresión:
\begin{equation}
    LM = T \times R^2
    \label{eq:eqautocorr4}
\end{equation}

Donde \(R^2\) es el resultante de la regresión auxiliar y \(T\) es el número de observaciones totales.

En comparación con una prueba Durbin - Watson que es comúnmente usada en la econometría tradicional, para probar autocorrelación de los residuales, las estadísticas \(Q\), \(Q^*\) y \(LM\) tienen las siguientes ventajas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Permiten corroborar la existencia de autocorrelación para cualquier orden, y no solo para un primer orden (es decir, para cualquier valor de \(\tau = 1, 2, 3, \ldots\));
\item
  Los resultados se mantienen aún y cuando exista una probable variable endógena en forma rezagada, y
\item
  No depende del orden o la forma en que se acomoden las observaciones, algo que es muy probalble que ocurra en la econometría tradicional.
\end{enumerate}

El hecho de los residuales no estén autocorrelacionados no implica que estos sean independientes y normalmente distribuidos. La ausencia de autocorrelación no implica una independencia estocástica si las variables son normalmente distribuidas.

A menudo se asume que estos residuales están distribuidos normalmente, ya que la mayoría de las pruebas estadísticas tienen este supuesto detrás. No obstante, ello también depende de los otros momentos de la distribución, específicamente del tercer y cuarto momento. Los cuales expresan como:
\begin{equation*}
    \mathbb{E}[(X_t - \mathbb{E}[X_t])^i] \mbox{, } i = 3, 4
\end{equation*}

El tercer momento es necesario para determinar el sesgo, el cual esta dado como:
\begin{equation}
    \hat{S} = \frac{1}{T} \frac{\sum_{t = 1}^{T} (X_t - \hat{\mu})^3}{\sqrt{\hat{\gamma}(0)^3}}
    \label{eq:eqautocorr6}
\end{equation}

Para distribuciones simetricas (como en el caso de la distribución normal) el valor teórico para el sesgo es cero.

La curtosis, la cual esta dada en función del cuarto momento, se puede expresar como:
\begin{equation}
    \hat{K} = \frac{1}{T} \frac{\sum_{t = 1}^{T} (X_t - \hat{\mu})^4}{\hat{\gamma}(0)^2}
    \label{eq:eqautocorr7}
\end{equation}

Para el caso de una distribución normal, esta estadística toma el valor de 3. Valores más grandes que 3 indican que la distribución tienen colas anchas. En tales casos se ubican a los datos financieros.

Usando el valor de las estadísticas para medir el sesgo y la curtosis, \(S\) y \(K\), respectivamente, Jarque y Bera (1980) propusieron una prueba de normalidad, la cual puede ser aplicada a series de tiempo en niveles o en diferencias indistintamente. Dicha prueba se expresa como:
\begin{equation}
    JB = \frac{T}{6} \left(\hat{S} + \frac{1}{4} (\hat{K} - 3)^2 \right) 
    \label{eq:eqautocorr8}
\end{equation}

La cual tiene una distribución \(\chi^2\) con \(2\) grados de libertad y donde \(T\) es el tamaño de la muestra. La hipótesis de que las observaciones están distribuidas de forma normal se rechaza si los valores de la estadística de prueba es más grande que los correspondientes valores criticos en tablas.

Veamos un ejemplo para ilustrar el uso de la función de autocorrelación. Tomemos como variable al número de pasajeros transportados por el sistema de transporte del metro de la CDMX.\footnote{Los datos y algoritmo está disponible en el repositorio de GitHub y corresponde a la Clase 3.} Los datos empleados fueron tomados del INEGI y son una serie de tiempo en el periodo que va de enero de 2000 a junio de 2019, es decir, 234 observaciones. Como se puede apreciar en la Figura \ref{fig:fig32}, el número de pasajeros por mes ha oscilado significativamente a lo largo de tiempo. Incluso podemos observar un cambio estructural de la serie entre 2011 y 2012. Asimismo, podemos ubicar una caida atípica que ocurrió en septiembre de 2017.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Datos, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Periodo, }\AttributeTok{y =}\NormalTok{ Pax\_Metro)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\#geom\_point(size = 1.0, color = "darkblue") + }
  \CommentTok{\#theme\_bw() + }
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Millones de pasajeros"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{11}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.margin =} \FunctionTok{unit}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\StringTok{"cm"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Pasajeros Transportados en el Metro de la CDMX"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"(Ene{-}2000 a Jul{-}2021)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Fuente: Elaboración propia con información del INEGI, }\SpecialCharTok{\textbackslash{}n}\StringTok{https://www.inegi.org.mx/app/indicadores/?tm=0\&t=1090"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig32-1} 

}

\caption{Evolución del número de pasajeros en el Metro de la CDMX, enero 2000 a mayo 2023}\label{fig:fig32}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"Pax\_Metro.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{20}\NormalTok{, }\AttributeTok{height =} \DecValTok{15}\NormalTok{, }\AttributeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A esta serie de tiempo le calculamos los pincipales estadísticos hasta ahora estudiados y obtenemos el Cuadro \ref{tab:foo}. En dicho cuadro se destaca que se muestra la función de autocirrelación para los tres primeros rezagos. Para mayor detalle, en la Figura \ref{fig:fig33} se muestra la función de autocorrelación, en donde las bandas descritas por las líneas azules son el intervalo de confianza dentro de las cuales no se puede rechazar la hipotésis nula de que \(H_0: \hat{\rho}(p) = 0\), para todo \(\tau = 1, 2, \ldots, T-1\).

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{\label{tab:foo} Estadísticas descriptivas del número de pasajeros en el Metro de la CDMX, enero de 2000 a junio de 2019}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadística
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Valor
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadística
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Valor
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\hat{\mu} = \frac{1}{T} \sum^T_{t=1} X_t\) & 124.3000 \\
\(\hat{\gamma}(0) = \frac{1}{T} \sum^T_{t=1} (X_t - \hat{\mu})^2\) & 103.6400 \\
\(\hat{\gamma}(1) = \frac{1}{T} \sum^{T - 1}_{t=1} (X_t - \hat{\mu})(X_{t+1} - \hat{\mu})\) & 63.1100 \\
\(\hat{\gamma}(2) = \frac{1}{T} \sum^{T - 2}_{t=1} (X_t - \hat{\mu})(X_{t+2} - \hat{\mu})\) & 72.9100 \\
\(\hat{\gamma}(3) = \frac{1}{T} \sum^{T - 3}_{t=1} (X_t - \hat{\mu})(X_{t+3} - \hat{\mu})\) & 63.6900 \\
\(\hat{\rho}(1) = \frac{\sum^{T - 1}_{t=1} (X_t - \hat{\mu})(X_{t+1} - \hat{\mu})}{\sum^T_{t=1} (X_t - \hat{\mu})^2} = \frac{\hat{\gamma}(1)}{\hat{\gamma}(0)}\) & 0.6089 \\
\(\hat{\rho}(2) = \frac{\sum^{T - 2}_{t=1} (X_t - \hat{\mu})(X_{t+2} - \hat{\mu})}{\sum^T_{t=1} (X_t - \hat{\mu})^2} = \frac{\hat{\gamma}(2)}{\hat{\gamma}(0)}\) & 0.7035 \\
\(\hat{\rho}(3) = \frac{\sum^{T - 3}_{t=1} (X_t - \hat{\mu})(X_{t+3} - \hat{\mu})}{\sum^T_{t=1} (X_t - \hat{\mu})^2} = \frac{\hat{\gamma}(3)}{\hat{\gamma}(0)}\) & 0.6145 \\
\(Q^* = T \sum_{j = 1}^{1} \hat{\rho} (j)^2\) & 86.7577 \\
\(Q^* = T \sum_{j = 1}^{2} \hat{\rho} (j)^2\) & 290.9279 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Pax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro, }
                \AttributeTok{start =} \DecValTok{2000}\NormalTok{, }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\FunctionTok{acf}\NormalTok{(Pax\_Metro, }
    \AttributeTok{lag.max =} \DecValTok{150}\NormalTok{, }
    \AttributeTok{xlab =} \StringTok{\textquotesingle{}Resagos k en meses\textquotesingle{}}\NormalTok{, }
    \AttributeTok{main =} \StringTok{"Funcion de Autocorrelación del número de pasajeros del metro"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig33-1} 

}

\caption{Función de Autocorrelación: 150 rezagos del número de pasajeros en el Metro de la CDMX, enero de 2000 a mayo de 2023}\label{fig:fig33}
\end{figure}

\hypertarget{procesos-estacionarios-univariados}{%
\chapter{Procesos estacionarios univariados}\label{procesos-estacionarios-univariados}}

En este capítulo analizaremos el método o metodología de análisis de series de tiempo propuesto por Box y Jenkins (1970). Los modelos
propuestos dentro de está metodología o conjunto de métodos se han vuelto indispensables para efectos de realizar pronósticos de corto
plazo.

En este sentido, se analizarán los métodos más importantes en series de tiempo: procesos autoregresivos (AR) y procesos de medias móviles (MA). Asimismo, se realizará un análisis de los procesos que resultan de la combinación de ambos, conocida como ARMA, los cuales son más comúnmente usados para realizar pronósticos.

\hypertarget{procesos-autoregresivos-ar}{%
\section{Procesos Autoregresivos (AR)}\label{procesos-autoregresivos-ar}}

Los procesos autoregresivos tienen su origen en el trabajo de Cochrane y Orcutt de 1949, mediante el cual analizaron los residuales de una regresión clásica como un proceso autoregresivo. Puede consultarse el apéndice para la discusión del modelo de regresión clásica.

\hypertarget{ar1}{%
\subsection{AR(1)}\label{ar1}}

Como primer caso analizaremos al proceso autoregresivo de primer orden, \(AR(1)\), el cual podemos definir como una Ecuación Lineal en Diferencia Estocástica de Primer Orden. Diremos que una Ecuación Lineal en Diferencia de Primer Orden es estocástica si en su representación analítica considera un componente estocástico como en la ecuación \eqref{eq:EDOEst} descrita a continuación:
\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + U_t
    \label{eq:EDOEst}
\end{equation}

Donde \(a_0\) es un término constante, \(U_t\) es un proceso estacionario, con media cero (0), una varianza finita y constante (\(\sigma^2\)) y una covarianza que depende de la distancia entre \(t\) y cualquier \(t-s\) (\(\gamma_s\))--que no depende de los valores pasados o futuros de la variable--, \(X_0\) es el valor inicial del proceso \(X_t\). No obstante, en ocasiones vamos a asumir que la covarianza será cero (0), por lo que en esos casos tendremos un proceso puramente aleatorio. Considerando la ecuación \eqref{eq:EDOEst} y un proceso de sustitución sucesivo podemos establecer lo siguiente, empezando con \(X_1\):
\begin{eqnarray*}
    X_{1} & = & a_0 + a_1 X_{0} + U_{1}
\end{eqnarray*}

Para \(X_2\):
\begin{eqnarray*}
    X_{2} & = & a_0 + a_1 X_{1} + U_{2} \\
    & = & a_0 + a_1 (a_0 + a_1 X_{0} + U_{1}) + U_{2} \\
    & = & a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}
\end{eqnarray*}

Para \(X_3\):
\begin{eqnarray*}
    X_{3} & = & a_0 + \alpha X_{2} + U_{3} \\
    & = & a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}) + U_{3} \\
    & = & a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 X_{0} + a_1^2 U_{1} + a_1 U_{2} + U_{3}
\end{eqnarray*}

Así, para cualquier \(X_t\), \(t = 1, 2, 3, \ldots\), obtendríamos:
\begin{eqnarray}
    X_{t} & = & a_0 + a_1 X_{t - 1} + U_{t} \nonumber \\
    & = & a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 a_0 + \ldots + a_1^{t-2} a_0 + a_1^{t-1} X_{0} \nonumber \\
    &   & + a_1^{t-2} U_{1} + \ldots + a_1 U_{t - 2} + U_{t - 1}) + U_{t} \nonumber \\
    & = & a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 a_0 + \ldots + a_1^{t-1} a_0 + a_1^{t} X_{0} \nonumber \\
    &   & + a_1^{t-1} U_{1} + \ldots a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t} \nonumber \\
    & = & (1 + a_1 + a_1^2 + a_1^3 + \ldots + a_1^{t-1}) a_0 + a_1^{t} X_{0} \nonumber \\
    &   & + a_1^{t-1} U_{1} + \ldots + a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t}  \nonumber\\
    & = & \frac{1 - a_1^t}{1 - a_1} a_0 + a_1^{t} X_{0} + \sum^{t-1}_{j = 0} a_1^{j} U_{t - j} 
    \label{eq:EDOSSol}
\end{eqnarray}

De esta forma en la ecuación \eqref{eq:EDOSSol} observamos un proceso que es explicado por dos partes: una que depende del tiempo y otra que depende de un proceso estocástico. Asimismo, debe notarse que la condición de convergencia es idéntica que en el caso de ecuaciones en diferencia estudiadas al inicio del curso: \$ \textbar a\_1\textbar{} \textless{} 1\$, por lo que cuando \(t \to \infty\), la expresión \eqref{eq:EDOSSol} será la siguiente:
\begin{equation}
    X_t = a_0 \frac{1}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^{j} U_{t - j}
    \label{eq:EDOSLP}
\end{equation}

Así, desaparece la parte dependiente del tiempo y únicamente prevalece la parte que es dependiente del proceso estocástico. Esta es la solución de largo plazo del proceso \(AR(1)\), la cual depende del proceso estocástico. Notemos, además, que esta solución implica que la variable o la serie de tiempo \(X_t\) es tambien un proceso estocástico que hereda las propiedades de \(U_t\). Así, \(X_t\) es también un proceso estocástico estacionario, como demostraremos más adelante.

Observemos que la ecuación \eqref{eq:EDOSLP} se puede reescribir si consideramos la formulación que en la literatura se denomina como la descomposición de Wold, en la cual se define que es posible asumir que \(\psi_j = a_1^j\) y se considera el caso en el cual \$ \textbar a\_1\textbar{} \textless{} 1 \$, de esta forma tendremos que por ejemplo cuando:
\begin{equation*}
    \sum^{\infty}_{j = 0} \psi^2_j = \sum^{\infty}_{j = 0} a_1^{2j} = \frac{1}{1 - a_1^2} 
\end{equation*}

Alternativamente y de forma similar a las ecuaciones en diferencia estudiadas previamente podemos escribir el proceso \(AR(1)\) mediante el uso del operador rezago como:
\begin{eqnarray}
    X_t & = & a_0 + a_1 L X_t + U_t \nonumber \\
    X_t - a_1 L X_t & = & a_0 + U_t \nonumber \\
    (1 - a_1 L) X_t & = & a_0 + U_t \nonumber \\
    X_t & = & \frac{a_0}{1 - a_1 L} + \frac{1}{1 - a_1 L} U_t
    \label{eq:AR01}
\end{eqnarray}

En esta última ecuación retomamos el siguiente término para reescribirlo como:
\begin{equation}
    \frac{1}{1 - a_1 L} = 1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots 
\end{equation}

Tomando este resultado para sustituirlo en ecuación \eqref{eq:AR01}, obtenemos la siguiente expresión:
\begin{eqnarray}
    X_t & = & (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots) a_0 + (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots) U_t \nonumber \\
    & = & (1 + a_1 + a_1^2 + a_1^3 + \ldots) a_0 + U_t + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \ldots \nonumber \\
    & = & \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j}
    \label{eq:AR1Sol}
\end{eqnarray}

Donde la condición de convergencia y estabilidad del proceso descrito en esta ecuación es que \$ \textbar a\_1\textbar{} \textless{} 1 \$. Por lo que hemos demostrado que mediante el uso del operador de rezago es posible llegar al mismo resultado que obtuvimos mediante el procedimiento de sustituciones iterativas.

La ecuación \eqref{eq:AR1Sol} se puede interpretar como sigue. La solución o trayectoria de equilibrio de un AR(1) se divide en dos
partes. La primera es una constante que depende de los valores de \(a_0\) y \(a_1\). La segunda parte es la suma ponderada de las desviaciones o errores observados y acumulados en el tiempo hasta el momento \(t\).

Ahora obtendremos los momentos que describen a la serie de tiempo cuando se trata de un porceso \(AR(1)\). Para ello debemos obtener la media, la varianza y las covarianzas de \(X_t\). Para los siguientes resultados debemos recordar y tener en mente que si \(U_t\) es un proceso puramente aleatorio, entonces:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathbb{E}[U_t] = 0\) para todo \(t\)
\item
  \(Var[U_t] = \sigma^2\) para todo \(t\)
\item
  \(Cov[U_t, U_s] = 0\) para todo \(t \neq s\)
\end{enumerate}

Dicho lo anterior y partiendo de la ecuación \eqref{eq:AR1Sol}, el primer momento o valor esperado de la serie de tiempo será el siguiente:
\begin{eqnarray}
    \mathbb{E}[X_t] & = & \mathbb{E} \left[ \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} \right] \nonumber \\
    & = & \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j \mathbb{E}[U_{t-j}] \nonumber \\
    & = & \frac{a_0}{1 - a_1} = \mu
    \label{eq:AR1m1}
\end{eqnarray}

Respecto de la varianza podemos escribir la siguiente expresión a partir de la ecuación \eqref{eq:AR1Sol}:
\begin{eqnarray}
    Var[X_t] & = & \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    & = & \mathbb{E} \left[ \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} - \frac{a_0}{1 - a_1} \right)^2 \right] \nonumber \\
    & = & \mathbb{E}[(U_{t} + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \ldots)^2] \nonumber \\
    & = & \mathbb{E}[U^2_{t} + a_1^2 U^2_{t-1} + a_1^4 U^2_{t-2} + a_1^6 U^2_{t-3} + \ldots \nonumber \\
    &   & + 2 a_1 U_t U_{t-1} + 2 a_1^2 U_t U_{t-2} + \ldots] \nonumber \\
    & = & \mathbb{E}[U^2_{t}] + a_1^2 \mathbb{E}[U^2_{t-1}] + a_1^4 \mathbb{E}[U^2_{t-2}] + a_1^6 \mathbb{E}[U^2_{t-3}] + \ldots \nonumber \\
    & = & \sigma^2 + a_1^2 \sigma^2 + a_1^4 \sigma^2 + a_1^6 \sigma^2 + \ldots \nonumber \\
    & = & \sigma^2 (1 + a_1^2 + a_1^4 + a_1^6 + \ldots) \nonumber \\
    & = & \sigma^2 \frac{1}{1 - a_1^2} = \gamma(0)
    \label{eq:AR1Var}
\end{eqnarray}

Previo a analizar la covarianza de la serie recordemos que para el proceso puramente aleatorio \(U_t\) su varianza y covarianza puede verse como \(\mathbb{E}[U_t, U_s] = \sigma^2\), para \(t = s\), y \(\mathbb{E}[U_t, U_s] = 0\), para cualquier otro caso, respectivamente.

Dicho lo anterior, partiendo de la ecuación \eqref{eq:AR1Sol} la covarianza de la serie estará dada por:
\begin{eqnarray}
    Cov(X_t, X_{t-\tau}) & = & \mathbb{E}[(X_t - \mu)(X_{t-\tau} - \mu)] \nonumber \\
    & = & \mathbb{E} \left[ \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} - \frac{a_0}{1 - a_1} \right) \right. \nonumber \\
    &   & \left. \times \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-\tau-j} - \frac{a_0}{1 - a_1} \right) \right] \nonumber \\
    & = & a_1^{\tau} \mathbb{E}[U^2_{t-\tau} + a_1 U^2_{t-\tau-1} + a_1^2 U^2_{t-\tau-2} + a_1^3 U^2_{t-\tau-3} + \ldots] \nonumber \\
    & = & a_1^{\tau} \sigma^2 \frac{1}{1 - a_1^2} = \gamma(\tau)
    \label{eq:AR1Cov}
\end{eqnarray}

Notése que con estos resultados en las ecuaciones \eqref{eq:AR1Var} y \eqref{eq:AR1Cov} podemos construir la función de autocorrelación
teórica como sigue:
\begin{eqnarray}
    \rho(\tau) & = & \frac{\gamma(\tau)}{\gamma(0)} \nonumber \\
    & = & a_1^\tau
\end{eqnarray}

Donde \(\tau = 1, 2, 3, \ldots\) y \$ \textbar a\_1\textbar{} \textless{} 1 \$. Este último resultado significa que cuando el proceso autoregresivo es de orden 1
(es decir, AR(1)) la función de autocorrelación teóricamente es igual al parámetro \(a_1\) elevado al número de rezagos considerados. No obstante, note que esto no significa que la autocorrelación observada sea como lo expresa en planteamiento anterior. Por el contrario, una observación sencilla mostraría que la autocorrelación observada sería ligeramente distinta a la autocorrelación teórica.

Ahora veámos algunos ejemplos. En el primer ejemplo simularemos una serie y mostraremos el analísis de un proceso construído considerando un proceso puramente aleatorio como componente \(U_t\). Por su parte, en un segundo ejemplo aplicaremos el análisis a una serie de tiempo de una variable económica observada.

Para el primer ejemplo consideremos un proceso dado por la forma de un \(AR(1)\) como en la ecuación \eqref{eq:AR01} cuya solución esta dada por la ecuación \eqref{eq:AR1Sol}. En especifico, supongamos que el término o componente estocástico \(U_t\) es una serie generada a partir de numeros aleatorios de una función normal con media \(0\) y desviación estándar \(4\). Los detalles del proceso simulado se muestra en las siguientes gráficas.

La Figura \ref{fig:fig41} ilustra el comportamiento que se debería observar en una serie considerando el procedimiento iterativo de
construcción. Por su parte, la Figura \ref{fig:fig42} ilustra el proceso o trayectoria de la solución de la serie de tiempo. Finalmente, las Figuras \ref{fig:fig43} y \ref{fig:fig44} muestran el correlograma calculado considerando una función de autocorrelación aplicada al porceso real y una función de autocorrelación aplicada al proceso teórico, respectivamente.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(latex2exp)}

\NormalTok{a0 }\OtherTok{\textless{}{-}} \DecValTok{5}\NormalTok{; a1 }\OtherTok{\textless{}{-}} \FloatTok{0.9}\NormalTok{; X\_0 }\OtherTok{\textless{}{-}}\NormalTok{ (a0}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ a1)); T }\OtherTok{\textless{}{-}} \DecValTok{1000}

\NormalTok{X\_t }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Tiempo =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\NormalTok{T))}


\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}

\CommentTok{\# Agregamos un término estocástico al data frame}

\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{U\_t }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(T}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{4}\NormalTok{)}

\CommentTok{\# Agregamos columnas con NA\textquotesingle{}s para un proceso teorico y uno real}
\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{X\_t }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{XR\_t }\OtherTok{\textless{}{-}} \ConstantTok{NA}

\CommentTok{\# La serie teórica inicia en un valor inicial X\_0}
\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{X\_t[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ X\_0}

\CommentTok{\# La serie real inicia en un valor inicial X\_0}
\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{XR\_t[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ X\_0}

\CommentTok{\# Agregamos una columna para la función de Autocorrelación teórica:}
\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{rho }\OtherTok{\textless{}{-}}\ConstantTok{NA}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\NormalTok{(T }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)) \{}
  \CommentTok{\# Real:}
\NormalTok{  X\_t}\SpecialCharTok{$}\NormalTok{XR\_t[i] }\OtherTok{=}\NormalTok{ a0 }\SpecialCharTok{+}\NormalTok{ a1}\SpecialCharTok{*}\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{XR\_t[i}\DecValTok{{-}1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ X\_t}\SpecialCharTok{$}\NormalTok{U\_t[i}\DecValTok{{-}1}\NormalTok{]}
  
  \CommentTok{\# Teórico:}
\NormalTok{  X\_t}\SpecialCharTok{$}\NormalTok{X\_t[i] }\OtherTok{=}\NormalTok{ X\_t}\SpecialCharTok{$}\NormalTok{X\_t[i}\DecValTok{{-}1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ (a1}\SpecialCharTok{\^{}}\NormalTok{(i}\DecValTok{{-}1}\NormalTok{))}\SpecialCharTok{*}\NormalTok{X\_t}\SpecialCharTok{$}\NormalTok{U\_t[i}\DecValTok{{-}1}\NormalTok{]}
  
  \CommentTok{\# Autocorrelación:}
\NormalTok{  X\_t}\SpecialCharTok{$}\NormalTok{rho[i}\DecValTok{{-}1}\NormalTok{] }\OtherTok{=}\NormalTok{ a1}\SpecialCharTok{\^{}}\NormalTok{(i}\DecValTok{{-}1}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ X\_t, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Tiempo, }\AttributeTok{y =}\NormalTok{ XR\_t)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkred"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\#theme\_bw() + }
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$X\_t$"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{11}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{, }
                                  \AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.margin =} \FunctionTok{unit}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\StringTok{"cm"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Comportamiento del Proceso Real (\textquotesingle{}Estimado\textquotesingle{})"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Con un error con Distribución Normal (media = 0, desviación estándar = 4)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Fuente: Elaboración propia."}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig41-1} 

}

\caption{Comportamiento del Proceso Real ('Estimado')}\label{fig:fig41}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"G\_AR\_1\_Real.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{20}\NormalTok{, }\AttributeTok{height =} \DecValTok{10}\NormalTok{, }\AttributeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ X\_t, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Tiempo, }\AttributeTok{y =}\NormalTok{ X\_t)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\#theme\_bw() + }
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$X\_t$"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{11}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{, }
                                  \AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.margin =} \FunctionTok{unit}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\StringTok{"cm"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Comportamiento del Proceso Teórico"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Con un error con Distribución Normal (media = 0, desviación estándar = 4)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Fuente: Elaboración propia."}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig42-1} 

}

\caption{Comportamiento del Proceso Teórico}\label{fig:fig42}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"G\_AR\_1\_Teo.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{20}\NormalTok{, }\AttributeTok{height =} \DecValTok{10}\NormalTok{, }\AttributeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(X\_t}\SpecialCharTok{$}\NormalTok{XR\_t, }\AttributeTok{lag.max =} \DecValTok{30}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }
    \AttributeTok{ylab =} \StringTok{"Autocorrelacion"}\NormalTok{,}
    \AttributeTok{xlab=}\StringTok{"Rezagos"}\NormalTok{, }
    \AttributeTok{main=}\StringTok{"Funcion de Autocorrelacion Real"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig43-1} 

}

\caption{Funcion de Autocorrelacion Real}\label{fig:fig43}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{barplot}\NormalTok{(X\_t}\SpecialCharTok{$}\NormalTok{rho[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{30}\NormalTok{], }\AttributeTok{names.arg =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{30}\NormalTok{), }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }
        \AttributeTok{border=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{density =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{), }
        \AttributeTok{ylab =} \StringTok{"Autocorrelacion"}\NormalTok{, }
        \AttributeTok{xlab=}\StringTok{"Rezagos"}\NormalTok{, }
        \AttributeTok{main=}\StringTok{"Funcion de Autocorrelacion Teórica"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig44-1} 

}

\caption{Funcion de Autocorrelacion Teórica}\label{fig:fig44}
\end{figure}

Recordemos que una trayectoria de equilibrio o solución de un \(AR(1)\) es como se muestra en la ecuación \eqref{eq:AR1Sol}. Así, nuestra serie simulada cumple con la característica de que los errores son más relevantes cuando la serie es corta. Por el contrario, los errores son menos relevantes, cuando la serie es muy larga. La Figura \ref{fig:fig45} ilustra esta observación de la trayectoria de
equilibrio.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ X\_t, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Tiempo)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ XR\_t), }\AttributeTok{size =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkred"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ X\_t), }\AttributeTok{size =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\#theme\_bw() + }
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$X\_t$"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{11}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{, }
                                  \AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.margin =} \FunctionTok{unit}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\StringTok{"cm"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Comportamiento de los Procesos Real y Teórico"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Con un error con Distribución Normal (media = 0, desviación estándar = 4)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Fuente: Elaboración propia."}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig45-1} 

}

\caption{Comportamiento de los Procesos Real y Teórico}\label{fig:fig45}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"G\_AR\_1\_Comb.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{20}\NormalTok{, }\AttributeTok{height =} \DecValTok{10}\NormalTok{, }\AttributeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para el segundo ejemplo consideremos una aplicación a una serie de tiempo en especifico: Pasajeros transportados mensualmente en el Sistema de Transporte Colectivo Metro (pasajeros medidos en millones).\footnote{Fuente: INEGI, \url{https://www.inegi.org.mx/app/indicadores/?tm=0&t=1090}.}

A la serie se le aplicará una metodología de estimación dada por el método de Máxima Verosimilitud (ML, por sus siglás en inglés). Antes de realizar el proceso de estimación consideremos una transformación de diferencias logaritmicas, con el objeto de obtener una serie de tiempo expresada en tasas de crecimiento\footnote{Estas tasas no son porcentuales, para hacerlas porcentuales faltaría multiplicar por 100 cada calor de la serie.} y con un comportamiento parecido a un proceso estacionario.

Así, para cada una de las series que analicemos en diferencias logaritmicas respecto del momento \(k\) las expresaremos bajo la siguiente transformación:
\begin{equation*}
    DLX_t = log(X_t) - log(X_{t-k})
\end{equation*}

Donde \(k = 1, 2, 3, \ldots\) y \(log(.)\) es la función logaritmo natural. Esta expresión se pude interpretar como una tasa de crecimiento puesto que asumimos variaciones pequeñas para las cuales se cumple que: \(log(X_t) - log(X_{t-k}) \approx \frac{X_t - X_{t-k}}{X_t}\).

Primero, para realizar el análisis de una serie de tiempo deberemos decidir si éste se realizará para la serie en niveles o en diferencias. Por convención, decimos que la series esta en niveles si ésta se analiza sin heacerle ninguna transformación o si se analiza aplicando solo logarimos. Cuando la serie se analiza en diferencias significa que la diferencia se hace sin aplicar logaritmos o aplicando logaritmos. Sin embargo, la convención es hacer un análisis en diferencias logaritmicas.

Para decidir cómo analizar la serie de pasajeros en el metro de la CDMX en la Figura \ref{fig:fig46}\} se muestra la gráfica de la serie en niveles (sin transformación logaritmica y con transformación logarítmica) y en diferencias logarítmicas mensuales (es decir, con \(k = 1\)).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(stats)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# En Niveles}
\NormalTok{Pax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro, }\AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# En Logaritmos:}
\NormalTok{Pax\_LMetro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro), }\AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# Diferencias mensuales:}
\NormalTok{Pax\_DLMetro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{( }\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro) }\SpecialCharTok{{-}} 
                   \FunctionTok{lag}\NormalTok{( }\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro), }\DecValTok{1}\NormalTok{ ),}
                 \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\#}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(Pax\_Metro, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Pasajeros transportados (Millones) en el SCM"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(Pax\_LMetro, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"LN Pasajeros transportados (Millones) en el SCM"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkblue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(Pax\_DLMetro, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Diff LN Pasajeros transportados (Millones) en el SCM"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"darkred"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig46-1} 

}

\caption{Pasajeros transportados (Millones) en el metro de la CDM en niveles y en diferencias logaritmicas}\label{fig:fig46}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

A continuación, estimaremos una \(AR(1)\) para la serie en niveles bajo la transformación logaritmica (\(PaxLMetro_t\)) y en diferencias logarítmitcas (\(PaxDLMetro_t\)). Para el primer caso obtenemos el siguiente resultado:

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:AR01} AR(1) para la variable \(PaxLMetro_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(PaxLMetro_t\) & \(=\) & \(4.7419\) & \(+\) & \(0.5916\) & \(PaxLMetro_{t-1}\) \\
& & \((0.0105)\) & & \((0.0526)\) & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.004335\) & \(AIC\) & \(=\) & \(-602.73\) \\
\end{longtable}

Para el segundo caso obtenemos el siguiente resultado:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}@{}}
\caption{\label{tab:AR0101} AR(1) para la variable \(PaxDLMetro_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(PaxDLMetro_t\) & \(=\) & \(0.0007\) & \(-\) & \(0.6194\) & \(PaxDLMetro_{t-1}\) \\
& & \((0.0023)\) & & \((0.0511)\) & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.003344\) & \(AIC\) & \(=\) & \(-660.53\) \\
\end{longtable}

En ambos casos observamos que el parámetro asociado al componente AR es significativo y cumple con la restricción de ser en valor absoluto menor a 1, por lo que la solución asociada al procesp será convergente. También en ambos casos se reporta la estadística o Criterio de Información de Akaike (AIC, por sus siglas en inglés), misma que más adelante discutiremos su importancia y aplicación.

\hypertarget{ar2}{%
\subsection{AR(2)}\label{ar2}}

Una vez analizado el caso de \(AR(1)\) analizaremos el caso del \(AR(2)\). La ecuación generalizada del proceso autoregresivo de orden 2 (denotado como \(AR(2)\)) puede ser escrito como:
\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + U_t
    \label{eq:AR2Eq}
\end{equation}

Donde \(U_t\) denota un proceso puramente aleatorio con media cero (\(0\)), varianza constante (\(\sigma^2\)) y autocovarianza cero (\(Cov(U_t, U_s) = 0\), con \(t \neq s\)), y un parametro \(a_2 \neq 0\). Así, utilizando el operador rezago podemos reescribir la ecuación
\eqref{eq:AR2Eq} como:
\begin{eqnarray*}     
    X_t - a_1 X_{t-1} - a_2 X_{t-2} & = & a_0 + U_t \\
    (1 - a_1 L^1 - a_2 L^2) X_t & = & a_0 + U_t
\end{eqnarray*}

Donde, vamos a denotar a \(\alpha (L) = (1 - a_1 L^1 - a_2 L^2)\), y lo llamaremos como un polinomio que depende del operador rezago y que es distinto de cero. De esta forma podemos reescribir a la ecuación \eqref{eq:AR2Eq} como:
\begin{equation}
    \alpha(L) X_t = a_0 + U_t
\end{equation}

Ahora, supongamos que existe el inverso multiplicativo del polinomio \(\alpha(L)\), el cual será denotado como: \(\alpha^{-1}(L)\) y cumple con que:
\begin{equation}
    \alpha^{-1}(L) \alpha(L) = 1    
\end{equation}

Así, podemos escribir la solución a la ecuación \eqref{eq:AR2Eq} como:
\begin{equation*}
    X_t = \alpha^{-1}(L) \delta + \alpha^{-1}(L) U_t
\end{equation*}

Si utilizamos el hecho que \(\alpha^{-1}(L)\) se puede descomponer a través del procedimiento de Wold en un polinomio de forma similar el caso de \(AR(1)\), tenemos que:
\begin{equation}
    \alpha^{-1}(L) = \psi_0 + \psi_1 L + \psi_2 L^2 + \ldots
\end{equation}

Por lo tanto, el inverso multiplicativo \(\alpha^{-1}(L)\) se puede ver como:
\begin{equation}
    1 = (1 - a_1 L^1 - a_2 L^2) (\psi_0 + \psi_1 L + \psi_2 L^2 + \ldots)
    \label{eq:InvAlpha}
\end{equation}

Desarrollando la ecuación \eqref{eq:InvAlpha} tenemos la sigueinte expresión:

\begin{eqnarray*}
  1 & = & \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots \\
  &  &  - a_1 \psi_0 L - a_1 \psi_1 L^2 - a_1 \psi_2 L^3 - \ldots \\
  &  &  - a_2 \psi_0 L^2 - a_2 \psi_1 L^3 - \ldots
\end{eqnarray*}

Ahora, podemos agrupar todos los términos en función del exponente asociado al operador rezago \(L\). La siguiente es una solución partícular y es una de las múltiples que podrían existir que cumpla con la ecuación \eqref{eq:InvAlpha}. Sin embargo, para efectos del análisis sólo necesitamos una de esas soluciones. Utilizaremos las siguientes condiciones que deben cumplirse en una de las posibles soluciones:

\begin{eqnarray*}
  L^0 & : & \Rightarrow \psi_0 = 1 \\
  L^1 & : & \psi_1 - a_1 \psi_0 = 0 \Rightarrow \psi_1 = a_1 \\
  L^2 & : & \psi_2 - a_1 \psi_1 - a_2 \psi_0 = 0 \Rightarrow \psi_2 = a^2_1 + a_2 \\
  L^3 & : & \psi_3 - a_1 \psi_2 - a_2 \psi_1 = 0 \Rightarrow \psi_3 = a^3_1 + 2 a_1 a_2 \\
  & \vdots & 
\end{eqnarray*}

De esta forma podemos observar que en el límite siempre obtendremos una ecuación del tipo \(\psi_j - a_1 \psi_{j-1} - a_2 \psi_{j-2} = 0\) asociada a cada uno de los casos en que exista un \(L^j\), donde \(j \neq 0, 1\), y la cual siempre podremos resolver conociendo que las condiciones iniciales son: \(\psi_0 = 1\) y \(\psi_1 = a_1\).

Así, de las relaciones antes mencionadas y considerando que \(\alpha^{-1} (L)\) aplicada a una constante como \(a_0\), tendrá como
resultado otra constante. De esta forma podemos escribir que la solución del proceso AR(2) en la ecuación \eqref{eq:AR2Eq} será dada por una expresión como sigue:
\begin{equation}
    X_t = \frac{\delta}{1 - a_1 - a_2} + \sum^{\infty}_{j = 0} \psi_{t - j} U_{t - j}
    \label{eq:AR2EqSol}
\end{equation}

Donde todos los parametros \(\psi_i\) está determinado por los parámetros \(a_0\), \(a_1\) y \(a_2\). En particular, \(\psi_0 = 1\) y \(\psi_1 = a_1\) como describimos anteriormente. Al igual que en el caso del \(AR(1)\), en la ecuación \eqref{eq:AR2EqSol} las condiciones de estabilidad estarán dadas por las soluciones del siguiente polinomio característico:\footnote{Note que raíces son equivalentes al inversio de las del polinomio dado por $\lambda^2 a_2 - \lambda a_1 - 1 = 0$.}
\begin{equation}
    \lambda^2 - \lambda a_1 - a_2 = 0
\end{equation}

Así, la condición de estabilidad de la trayectoria es que \$ \textbar{} \lambda\_i \textbar{} \textless{} 1 \$, para \(i = 1, 2\). Es decir, es necesario que cada
una de las raíces sea, en valor absoluto, siempre menor que la unidad. Estas son las condiciones de estabilidad para el proceso \(AR(2)\).

Finalmente, al igual que en un \(AR(1)\), a continuación determinamos los momentos de una serie que sigue un proceso \(AR(2)\). Iniciamos con la determinación de la media de la serie:
\begin{equation}
    \mathbb{E}[X_t] = \mu = \frac{a_0}{1 - a_1 - a_2}
\end{equation}

Lo anterior es cierto puesto que \(\mathbb{E}[U_{t - i}] = 0\), para todo \(i = 0, 1, 2, \ldots\). Para determinar la varianza utilizaremos las siguientes relaciones basadas en el uso del valor esperado, varianza y covarianza de la serie. Adicionalmente, para simplificar el trabajo asumamos que \(a_0 = 0\), lo cual implica que \(\mu = 0\). Dicho lo anterior, partamos de:
\begin{eqnarray*}
    \mathbb{E}[X_t X_{t - \tau}] & = & \mathbb{E}[(a_1 X_{t-1} + a_2 X_{t-2} + U_t) X_{t - \tau}]\\
    & = & a_1 \mathbb{E}[X_{t - 1} X_{t - \tau}] + a_2 \mathbb{E}[X_{t - 2} X_{t - \tau}] + \mathbb{E}[U_{t} X_{t - \tau}]
\end{eqnarray*}

Donde \(\tau = 0, 1, 2, 3, \ldots\) y que \(\mathbb{E}[U_{t} X_{t - \tau}] = 0\) para todo \(\tau \neq 0\).\footnote{ Es fácil demostrar está afirmación, sólo requiere de desarrollar la expresión y utilizar el hecho de que $U_t$ es un proceso pueramente aleatorio, por lo que la covarianza es cero (0).} Dicho esto, podemos derivar el valor del valor esperado para diferentes valores de \(\tau\):
\begin{eqnarray*}
    \tau = 0 & : & \gamma(0) = \alpha_1 \gamma(1) + \alpha_2 \gamma(2) + \sigma^2 \\
    \tau = 1 & : & \gamma(1) = \alpha_1 \gamma(0) + \alpha_2 \gamma(1) \\
    \tau = 2 & : & \gamma(2) = \alpha_1 \gamma(1) + \alpha_2 \gamma(0) \\
    & \vdots & 
\end{eqnarray*}

Donde debe ser claro que \(\mathbb{E}[(X_{t} - \mu)(X_{t - \tau} - \mu)] = \mathbb{E}[X_{t} X_{t - \tau}] = \gamma(\tau)\). Así, en general cuando \(\tau \neq 0\):
\begin{equation}    
    \gamma(\tau) = a_1 \gamma(\tau - 1) + a_2 \gamma(\tau - 2)
\end{equation}

Realizando la sustitución recursiva y solucionando el sistema respectivo obtenemos que las varianza y covarianzas estaran determinadas por:
\begin{equation}
    Var[X_t] = \gamma(0) = \frac{1 - a_2}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
\end{equation}

\begin{equation}
    \gamma(1) = \frac{a_1}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
\end{equation}

\begin{equation}
    \gamma(2) = \frac{a^2_1 + a_2 - a^2_2}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
\end{equation}

Recordemos que las funciones de autocorrelación se obtienen de la división de cada unas de las funciones de covarianza (\(\gamma(\tau)\)) por la varianza (\(\gamma(0)\)). Así, podemos construir la siguiente expresión:
\begin{equation}
    \rho(\tau) - a_1 \rho(\tau - 1) - a_2 \rho(\tau - 2) = 0
\end{equation}

Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos nacionales (en vuelos de salidas) para estimar un \(AR(2)\) mediante el método de máxima verosimilitud (ML, por sus siglas en inglés). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logarítmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.

Así, para cada una de las series que analicemos en diferencias logarítmicas las expresaremos bajo la siguiente transformación:
\begin{equation*}
    DLX_t = log(X_t) - log(X_{t-k})
\end{equation*}

Donde \(k = 1, 2, 3, \ldots\) y \(log(.)\) es la función logaritmo natural. Por convención, decimos que la serie está en niveles si ésta se analiza sin heacerle ninguna transformación o se analiza en logarimos. Cuando la serie se analiza en diferencias significa que la diferencia se hace sin aplicar logaritmos. Y cuando la serie analizada está en diferenncias logarítmicas también diremos que esta en diferencias. Sin embargo, lo común es hacer un análisis en logaritmos y en difereencias logarítmicas.

Primero, para decidir si se realizará un AR(2) para la serie en niveles o en diferencias analizaremos su gráfica. La serie en niveles, en niveles bajo una transformación logarítmica y en diferencias logarítmicas mensuales de los pasajeros en vuelos nacionales se muestra en la Figura \ref{fig:fig47}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(stats)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# En Niveles}
\NormalTok{Pax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal, }
              \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{),}
              \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# Logaritmos:}
\NormalTok{LPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal), }
               \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
               \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# Diferencias mensuales:}
\NormalTok{DLPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal) }\SpecialCharTok{{-}} 
                \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal), }\DecValTok{1}\NormalTok{),}
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\#}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(Pax\_Nal, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Pasajeros en vuelos nacionales de salida"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(LPax\_Nal, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"LN Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"LN Pasajeros en vuelos nacionales de salida"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkblue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(DLPax\_Nal, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"DLN Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Diff LN Pasajeros en vuelos nacionales de salida"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"darkred"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig47-1} 

}

\caption{Pasajeros en vuelos de salidas nacionales en niveles y en diferencias logaritmicas}\label{fig:fig47}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

A continuación, estimaremos un \(AR(2)\) para la serie en niveles bajo una transformación logarítmica (\(LPaxNal_t\)) y en diferencias logaritmitcas (\(DLPax_Nal_t\)). Para el primer caso obtenemos el siguiente resultado:

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:AR02} AR(2) para la variable \(LPaxNal_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(LPaxNal_t\) & \(=\) & \(14.6267\) & \(+\) & \(0.7637\) & \(LPaxNal_{t-1}\) \\
& & \((0.1816)\) & & \((0.0637)\) & \\
& & \(0.2025\) & \(LPaxNal_{t-2}\) & & \\
& & \((0.0646)\) & & & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.01138\) & \(AIC\) & \(=\) & \(-372.64\) \\
\end{longtable}

Para el segundo caso obtenemos el siguiente resultado:

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:AR0201} AR(2) para la variable \(DLPaxNal_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(DLPaxNal_t\) & \(=\) & \(0.0050\) & \(+\) & \(0.3205\) & \(DLPaxNal_{t-1}\) \\
& & \((0.0036)\) & & \((0.0592)\) & \\
& & \(0.4242\) & \(DLPaxNal_{t-2}\) & & \\
& & \((0.0591)\) & & & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.009378\) & \(AIC\) & \(=\) & \(-418.3\) \\
\end{longtable}

Para ambos casos entre parentésis indicamos los errores estándar y reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si las soluciones serán convergentes, para ello en la Figura \ref{fig:fig48} mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que ambas propuesta de AR(2) representan una solución convergente y estable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{"arroots.R"}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{"plot.armaroots.R"}\NormalTok{)}

\NormalTok{AR\_LPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(LPax\_Nal, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                     \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\NormalTok{AR\_DLPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(DLPax\_Nal, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                      \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{arroots}\NormalTok{(AR\_LPax\_Nal), }
               \AttributeTok{main=}\StringTok{"Inverse AR roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{AR(2): LN Pax Nal"}\NormalTok{)}

\CommentTok{\#}
\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{arroots}\NormalTok{(AR\_DLPax\_Nal), }
               \AttributeTok{main=}\StringTok{"Inverse AR roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{AR(2): Diff LN Pax Nal"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig48-1} 

}

\caption{Inveso de las Raíces del polinomio característico}\label{fig:fig48}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{arp}{%
\subsection{AR(p)}\label{arp}}

Veremos ahora una generalización de los procesos autoregresivos (AR). Esta generalización es conocida como un proceso \(AR(p)\) y que puede ser descrito por la siguiente ecuación en diferencia estocástica:
\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + a_3 X_{t-3} + \ldots + a_p X_{t-p} + U_t
    \label{eq:ARpEq}
\end{equation}

Donde \(a_p \neq 0\), y \(U_t\) es un proceso puramente aleatorio con media cero (0), varianza constante (\(\sigma^2\)) y covarianza cero (0). Usando el operador rezago, \(L^k\), para \(k = 0, 1, 2, \ldots, p\), obtenemos la siguiente expresión de la ecuación \eqref{eq:ARpEq}:
\begin{equation}
    (1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p) X_t = a_0 + U_t
\end{equation}

Definamos el polinomio \(\alpha(L)\) como:
\begin{equation}
    \alpha(L) = 1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p
    \label{eq:PolA}
\end{equation}

De forma similar que en los procesos \(AR(1)\) y \(AR(2)\), las condiciones de estabilidad del proceso \(AR(p)\) estarán dadas por la solución de la ecuación característica:
\begin{equation}
    \lambda^p - a_1 \lambda^{p-1} - a_2 \lambda^{p-2} - a_3 \lambda^{p-3} - \ldots - a_p = 0
\end{equation}

Así, solo si el polinomio anterior tiene raíces cuyo valor absoluto sea menor a uno (\$ \textbar{} \lambda\_i \textbar{} \textless{} 1 \$) y si \(1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p < 1\) podremos decir que el proceso es convergente y estable. Lo anterior significa que la ecuación \eqref{eq:PolA} puede expresarse en términos de la descomposición de Wold o como la suma infinita de términos como:
\begin{equation}
    \frac{1}{1 - a_1 L  - a_2 L^2 - a_3 L^3  - \ldots - a_p L^p} = \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots
\end{equation}

Donde, por construcción de \(\alpha(L) \alpha^{-1}(L) = 1\) implica que \(\psi_0 = 1\). De forma similar a los proceso AR(1) y AR(2), es posible determinar el valor de los coefieentes \(\psi_j\) en términos de los coefientes \(a_i\). Así, la solución del proceso \(AR(p)\) estará dada por:
\begin{equation}
    X_t = \frac{a_0}{1 - a_1  - a_2 - a_3  - \ldots - a_p} + \sum^{\infty}_{j = 0} \psi_j U_{t-j}
    \label{eq:ARpEqSol}
\end{equation}

Considerando la solución de la ecuación (\eqref{eq:ARpEq}) expresada en la ecuación \eqref{eq:ARpEqSol} podemos determinar los momentos del proceso y que estarán dados por una media como:
\begin{equation}
    \mathbb{E}[X_t] = \mu = \frac{a_o}{1 - a_1  - a_2 - a_3  - \ldots - a_p}
\end{equation}

Lo anterior, considerado que \(\mathbb{E}[U_t] = 0\), para todo \(t\). Para determinar la varianza del proceso, sin pérdida de generalidad, podemos definir una ecuación: \(\gamma(\tau) = \mathbb{E}[X_{t - \tau} X_t]\), la cual (omitiendo la constante, ya que la correlación de una constante con cuaquier variable aleatoria que depende del tiempo es cero (0)) puede ser escrita como:
\begin{equation}
    \gamma(\tau) = \mathbb{E}[(X_{t - \tau}) \cdot (a_1 X_{t-1} + a_2 X_{t-2} + a_3 X_{t-3} + \ldots + + a_p X_{t-p} + U_t)]
\end{equation}

Donde \(\tau = 0, 1, 2, \ldots, p\) y \(a_0 = 0\), lo que implica que \(\mu = 0\). De lo anterior obtenemos el siguiente conjunto de ecuaciones mediante sustituciones de los valores de \(\tau\):
\begin{eqnarray}
    \gamma(0) & = & a_1 \gamma(1) + a_2 \gamma(2) + \ldots + a_p \gamma(p) + \sigma^2 \nonumber \\
    \gamma(1) & = & a_1 \gamma(0) + a_2 \gamma(1) + \ldots + a_p \gamma(p-1) \nonumber \\
    \vdots \nonumber \\
    \gamma(p) & = & a_1 \gamma(p-1) + a_2 \gamma(p-2) + \ldots + a_p \gamma(0) \nonumber
\end{eqnarray}

De esta forma, es fácil observar que la ecuación general para \(p > 0\) estará dada por:
\begin{equation}
    \gamma(p) - a_1 \gamma(\tau - 1) - a_2 \gamma(\tau - 2) - \ldots - a_p \gamma(\tau - p) = 0
    \label{eq:Gammap}
\end{equation}

Dividiendo la ecuación \eqref{eq:Gammap} por \(\gamma(0)\), se obtiene la siguiente ecuación:
\begin{equation}
    \rho(p) - a_1 \rho(\tau - 1) + a_2 \rho(\tau - 2) + \ldots + a_p \rho(\tau - p) = 0
\end{equation}

Así, podemos escribir el siguiente sistema de ecuaciones:
\begin{eqnarray}
    \rho(1) & = & a_1 + a_2 \rho(1) + a_3 \rho(2) + \ldots + a_p \rho(p-1) \nonumber \\
    \rho(2) & = & a_1 \rho(1) + a_2 + a_3 \rho(1) + \ldots + a_p \rho(p-2) \nonumber \\
    & \vdots & \nonumber \\
    \rho(p) & = & a_1 \rho(p-1) + a_2 \rho(p-2) + \ldots + a_p \nonumber
\end{eqnarray}

Lo anterior se puede expresar como un conjunto de vectores y matrices de la siguiente forma:
\begin{equation}
    \left[ 
    \begin{array}{c}
        \rho(1) \\
        \rho(2) \\
        \vdots \\
        \rho(p)
    \end{array} 
    \right]
    = 
    \left[ 
    \begin{array}{c c c c}
        1 & \rho(1) & \ldots & \rho(p - 1) \\
        \rho(1) & 1 & \ldots & \rho(p - 2) \\
        \rho(2) & \rho(1) & \ldots & \rho(p - 3) \\
        \vdots & \vdots & \ldots & \vdots \\
        \rho(p - 1) & \rho(p - 2) & \ldots & 1 \\
    \end{array} 
    \right]
    \left[ 
    \begin{array}{c}
        a_1 \\
        a_2 \\
        a_3 \\
        \vdots \\
        a_p \\
    \end{array} 
    \right]
\end{equation}

De lo anterior podemos escribir la siguiente ecuación que es una forma alternativa para expresar los valores de los coefientes \(a_i\) de la solución del proceso \(AR(p)\):
\begin{equation}
    \boldsymbol{\rho} = \mathbf{R} \mathbf{a}
\end{equation}

Es decir, podemos obtener la siguiente expresión:
\begin{equation}
    \mathbf{a} = \mathbf{R}^{-1} \boldsymbol{\rho}
\end{equation}

Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos internacionales de salida para estimar un \(AR(p)\) mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logaritmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.

Primero, para decidir si se realizará un \(AR(p)\) para la serie en niveles o en diferencias análizaremos su gráfica. La serie de Pasajeros en vuelos internacionales de salidas se muestra en la Figura \ref{fig:fig49}. En está se muestra la gráfica de la serie en niveles (sin transformación logaritmica y con transformación logaritmica) y en diferencias logaritmicas mensuales (es decir, con diferencia respecto del mes inmediato anterior).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(stats)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# En Niveles}
\NormalTok{Pax\_Int }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Int, }
              \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
              \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# Logaritmos:}
\NormalTok{LPax\_Int }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Int), }
               \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
               \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\# Diferencias mensuales:}
\NormalTok{DLPax\_Int }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Int) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Int), }\DecValTok{1}\NormalTok{),}
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\CommentTok{\#}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(Pax\_Int, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Pasajeros en vuelos internacionales de salida"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(LPax\_Int, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"LN Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"LN Pasajeros en vuelos internacionales de salida"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkblue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(DLPax\_Int, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"DLN Pasajeros"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Diff LN Pasajeros en vuelos internacionales de salia"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"darkred"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig49-1} 

}

\caption{Pasajeros en vuelos internacionales de salida en niveles y en diferencias logaritmicas}\label{fig:fig49}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

De la gráfica en la Figura \ref{fig:fig49} observamos que quizá la mejor forma de estimar un \(AR(p)\) es mediante la serie en diferencias, ya que ésta es la que parece ser una serie estacionaria. A continuación, estimaremos una AR(4) para la serie en diferencias logarimitcas (\(DLPaxInt_t\)):

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:AR04} AR(4) para la variable \(DLPaxInt_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(DLPaxInt_t\) & \(=\) & \(0.0050\) & \(+\) & \(0.2701\) & \(DLPaxInt_{t-1}\) \\
& & \((0.0052)\) & & \((0.0655)\) & \\
& & \(-0.4326\) & \(DLPaxNal_{t-2}\) & & \\
& & \((0.0664)\) & & & \\
& & \(-0.1956\) & \(DLPaxNal_{t-3}\) & & \\
& & \((0.0664)\) & & & \\
& & \(-0.0316\) & \(DLPaxNal_{t-4}\) & & \\
& & \((0.0653)\) & & & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.02371\) & \(AIC\) & \(=\) & \(-198.16\) \\
\end{longtable}

Entre parentésis indicamos los errores estándar y reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si las
soluciones serán convergentes, para ello en la Figura \ref{fig:fig410} mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que el AR(4) representan una solución convergente y estable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{"arroots.R"}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{"plot.armaroots.R"}\NormalTok{)}

\NormalTok{AR\_LPax\_Int }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(LPax\_Int, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                     \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\NormalTok{AR\_DLPax\_Int }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(DLPax\_Int, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                      \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{arroots}\NormalTok{(AR\_LPax\_Nal), }
               \AttributeTok{main=}\StringTok{"Inverse AR roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{AR(2): LN Pax Int"}\NormalTok{)}

\CommentTok{\#}
\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{arroots}\NormalTok{(AR\_DLPax\_Nal), }
               \AttributeTok{main=}\StringTok{"Inverse AR roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{AR(2): Diff LN Pax Int"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig410-1} 

}

\caption{Inveso de las Raíces del polinomio característico}\label{fig:fig410}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{procesos-de-medias-muxf3viles-ma}{%
\section{Procesos de Medias Móviles (MA)}\label{procesos-de-medias-muxf3viles-ma}}

\hypertarget{ma1}{%
\subsection{MA(1)}\label{ma1}}

Una vez planteado el proceso generalizado de \(AR(p)\), iniciamos el planteamiento de los proceso de medias móviles, denotados como \(MA(q)\). Iniciemos con el planteamiento del proceso \(MA(1)\), que se puede escribir como una ecuación como la siguiente:
\begin{equation}
    X_t = \mu + U_t - b_1 U_{t-1}
    \label{eq:MA1Eq}
\end{equation}

O como:
\begin{equation}
    X_t - \mu = (1 - b_1 L) U_{t}
\end{equation}

Donde \(U_t\) es un proceso puramente aleatorio, es decir, con \(\mathbb{E}[U_t] = 0\), \(Var[U_t] = \sigma^2\), y \(Cov[U_t, U_s] = 0\).
Así, un proceso \(MA(1)\) puede verse como un proceso AR con una descomposición de Wold en la que \(\psi_0 = 1\), \(\psi_1 = - b_1\) y
\(\psi_j = 0\) para todo \(j > 1\).

Al igual que los procesos autoregresivos, determinaremos los momentos de un proceso \(MA(1)\). En el caso de la media observamos que será:
\begin{eqnarray}
    \mathbb{E}[X_t] & = & \mu + \mathbb{E}[U_t] - b_1 \mathbb{E}[U_{t - 1}] \nonumber \\
    & = & \mu
\end{eqnarray}

Por su parte la varianza estará dada por:
\begin{eqnarray}
    Var[X_t] & = & \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    & = & \mathbb{E}[(U_t - b_1 U_{t-1})^2] \nonumber \\
    & = & \mathbb{E}[U_t^2 - 2 b_1 U_t U_{t-1} + b_1^2 U_{t - 1}^2] \nonumber \\
    & = &\mathbb{E}[U_t^2] - 2 b_1 \mathbb{E}[U_t U_{t-1}] + b_1^2 \mathbb{E}[U_{t - 1}^2]] \nonumber \\
    & = & \sigma^2 + b_1^2 \sigma^2 \nonumber \\
    & = & (1 + b_1^2) \sigma^2 = \gamma(0)
\end{eqnarray}

De esta forma, la varianza del proceso es constante en cualquier periodo \(t\). Para determinar la covarianza utilizaremos la siguiente ecuación:
\begin{eqnarray}
    \mathbb{E}[(x_t - \mu)(x_{t + \tau} - \mu)] & = & \mathbb{E}[(U_t - b_1 U_{t-1})(U_{t + \tau} - b_1 U_{t + \tau - 1})] \nonumber \\
    & = & \mathbb{E}[U_t U_{t + \tau} - b_1 U_t U_{t + \tau - 1} - b_1 U_{t - 1} U_{t + \tau} \nonumber \\
    &   & + b_1^2 U_{t - 1} U_{t + \tau - 1}] \nonumber \\
    & = & \mathbb{E}[U_t U_{t + \tau}] - b_1 \mathbb{E}[U_t U_{t + \tau - 1}] \nonumber \\
    &   & - b_1 \mathbb{E}[U_{t - 1} U_{t + \tau}] + b_1^2 \mathbb{E}[U_{t - 1} U_{t + \tau - 1}]
    \label{eq:MA1Cov}
\end{eqnarray}

Si hacemos sustituciones de diferentes valores de \(\tau\) en la ecuación \eqref{eq:MA1Cov} notaremos que la covarianza será distinta de cero únicamente para el caso de \(\tau = 1, -1\). En ambos casos tendremos como resultado:
\begin{eqnarray}
    \mathbb{E}[(x_t - \mu)(x_{t + 1} - \mu)] & = & \mathbb{E}[(x_t - \mu)(x_{t - 1} - \mu)] \nonumber \\
    & = & - b_1 \mathbb{E}[U_t U_{t}] \nonumber \\
    & = & - b_1 \mathbb{E}[U_{t - 1} U_{t - 1}] \nonumber \\ 
    & = & - b_1^2 \sigma^2 = \gamma(1)
\end{eqnarray}

De esta forma tendremos que las funciones de autocorrelación estarán dadas por los siguientes casos:
\begin{eqnarray}
    \rho(0) & = & 1 \nonumber \\
    \rho(1) & = & \frac{- b_1}{1 + b_1^2} \nonumber \\
    \rho(\tau) & = & 0 \text{ para todo } \tau > 1 \nonumber 
\end{eqnarray}

Ahora regresando a la ecuación \eqref{eq:MA1Eq}, su solución la podemos expresar como:
\begin{eqnarray}
    U_ t & = & - \frac{\mu}{1 - b_1} + \frac{1}{1 - b_1 L} X_t \nonumber \\
    & = & - \frac{\mu}{1 - b_1} + X_t + b_1 X_{t-1} + b_1^2 X_{t-2} + \ldots \nonumber
\end{eqnarray}

Donde la condición para que se cumpla esta ecuación es que \$ \textbar{} b\_1 \textbar{} \textless{} 1 \$. La manera de interpretar esta condición es como una condición de estabilidad de la solución y cómo una condición de invertibilidad. Notemos que un \(MA(1)\) (y en general un \(MA(q)\)) es equivalente a un \(AR(\infty)\), es decir, cuando se invierte un MA se genera un AR con infinitos rezagos.

En esta sección no desarrollaremos un ejemplo, primero explicaremos en qué consiste una modelación del tipo \(MA(q)\) y después platearemos un ejemplo en concreto.

\hypertarget{maq}{%
\subsection{MA(q)}\label{maq}}

En general, el proceso de medias móviles de orden \(q\), \(MA(q)\), puede ser escrito como:
\begin{equation}
    X_t = \mu + U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}
    \label{eq:MAqEQ}
\end{equation}

Podemos reescribir la ecuación \eqref{eq:MAqEQ} utilizando el operador rezago, así tendrémos el proceso de \(MA(q)\) como:
\begin{eqnarray}
    X_t - \mu & = & (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q) U_{t} \nonumber \\
    X_t - \mu & = & \beta(L) U_t
    \label{eq:MAqRed}
\end{eqnarray}

Donde \(U_t\) es un proceso puramente aleatorio con \(\mathbb{E}[U_t] = 0\), \(Var[U_t] = \mathbb{E}[U_t^2] = 0\) y \(Cov[U_t, U_s] = \mathbb{E}[U_t, U_s] = 0\), y \(\beta(L) = 1 - b_1 L - b_2 L^2 - \ldots - b_q L^q\) es un polinomio del operador rezago \(L\). la ecuación \eqref{eq:MAqRed} puede ser interpretada como un proceso \(AR(q)\) sobre la serie \(U_t\).

Ahora determinemos los momentos de un proceso \(MA(q)\):
\begin{eqnarray}
    \mathbb{E}[X_t] & = & \mathbb{E}[\mu + U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}] \nonumber \\
    & = & \mu + \mathbb{E}[U_t] - b_1 \mathbb{E}[U_{t-1}] - b_2 \mathbb{E}[U_{t-2}] - \ldots - b_q \mathbb{E}[U_{t-q}] \nonumber \\
    & = & \mu
\end{eqnarray}

En el caso de la varianza tenemos que se puede expresar como:
\begin{eqnarray}
    Var[X_t] & = & \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    & = & \mathbb{E}[(U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q})^2] \nonumber \\
    & = & \mathbb{E}[U_t^2 + b_1^2 U_{t-1}^2 + b_2^2 U_{t-2}^2 + \ldots + b_q^2 U_{t-q}^2 \nonumber \\
    &   & - 2 b_1 U_t U_{t - 1} - \ldots - 2 b_{q - 1} b_q U_{t - q + 1} U_{t - q}] \nonumber \\
    & = & \mathbb{E}[U_t^2] + b_1^2 \mathbb{E}[U_{t-1}^2] + b_2^2 \mathbb{E}[U_{t-2}^2] + \ldots + b_q^2 \mathbb{E}[U_{t-q}^2] \nonumber \\
    &   & - 2 b_1 \mathbb{E}[U_t U_{t - 1}] - \ldots - 2 b_{q - 1} b_q \mathbb{E}[U_{t - q + 1} U_{t - q}] \nonumber \\
    & = & \sigma^2 + b^2_1 \sigma^2 + b^2_2 \sigma^2 + \ldots + b^2_q \sigma^2 \nonumber \\
    & = & (1 + b^2_1 + b^2_2 + \ldots + b^2_q) \sigma^2
\end{eqnarray}

En el caso de las covarianzas podemos utilizar una idea similar al caso del \(AR(p)\), construir una expresión general para cualquier rezago \(\tau\):
\begin{eqnarray}
    Cov[X_t, X_{t + \tau}] & = & \mathbb{E}[(X_t - \mu)(X_{t + \tau} - \mu)] \nonumber \\
    & = & \mathbb{E}[(U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}) \nonumber \\
    &   & (U_{t + \tau} - b_1 U_{t + \tau -1} - b_2 U_{t + \tau -2} - \ldots - b_q U_{t + \tau - q})] \nonumber
\end{eqnarray}

La expresión anterior se puede desarrollar para múltiples casos de \(\tau = 1, 2, \ldots, q\). De esta forma tenemos el siguiente sistema:
\begin{eqnarray}
    \tau = 1 & : & \gamma(1) = (- b_1 + b_1 b_2 + \ldots + b_{q-1} b_q) \sigma^2 \nonumber \\
    \tau = 2 & : & \gamma(2) = (- b_2 + b_1 b_3 + \ldots + b_{q-2} b_q) \sigma^2 \nonumber \\
    & \vdots & \nonumber \\
    \tau = q & : & \gamma(q) = b_q \sigma^2 \nonumber
\end{eqnarray}

Donde \(\gamma(\tau) = 0\) para todo \(\tau > q\). Es decir, todas las autocovarianzas y autocorrelaciones con ordenes superiores a \(q\) son cero (0). De esta forma, esta caracterítica teórica permite identificar el orden de \(MA(q)\) visualizando la función de autocorrelación y verificando a partir de cual valor de rezago la autocorrelación es no significaiva.

Regresando al problema original que es el de determinar una solución para la eucación \eqref{eq:MAqEQ}, tenemos que dicha solución estará dada por un \(AR(\infty)\) en términos de \(U_t\):
\begin{eqnarray}
    U_t & = & - \frac{\mu}{1 - b_1 - b_2 - \ldots - b_q} + \beta(L)^{-1} X_t \nonumber \\
    &   & - \frac{\mu}{1 - b_1 - b_2 - \ldots - b_q} + \sum_{j = 0}^{\infty} c_j X_{t-j} 
    \label{eq:MAqEQSol}
\end{eqnarray}

Donde se cumple que: \(1 = (1 - b_1 L^1 - b_2 L^2 - \ldots - b_q L^q)(1 - c_1 L - c_2 L^2 - \ldots)\) y los coeficientes \(c_j\) se pueden determinar por un método de coeficientes indeterminados y en términos de los valores \(b_i\). De igual forma que en el caso de la ecuación \eqref{eq:ARpEq}, en la ecuación \eqref{eq:MAqEQSol} se deben cumplir condiciones de estabilidad asociadas con las raíces del polinomio carácterististico dado por:
\begin{equation}
    1 - b_1 x - b_2 x^2 - \ldots b_q x^q = 0
\end{equation}

El cual debe cumplir que \$ \textbar{} x\_i \textbar{} \textless{} 1 \$ y que \(1 - b_1 - b_2 - \ldots b_q < 1\).

Ahora veamos un ejemplo del proceso \(MA(q)\), para lo cual retomaremos la serie de Pasajeros transportados en el metro de la CDMX (\(PaxMetro\)). Estimaremos el \(MA(q)\) mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logaritmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.

La serie de Pasajeros transportados en el metro de la CDMX se muestra en la Figura \ref{fig:fig46} se muestra la gráfica de la serie en niveles (sin transformación logarítmica y con transformación logarítmica) y en diferencias logarítmicas mensuales (es decir, con una diferencia respecto del mes inmediato anterior). Utilizaremos la serie en diferencias, ya que es la que parece ser estacionaria. Esta serie tiene la peculiaridad de que tiene un salto a la baja y uno al alza entre septiembre de 2017 y octubre de 2017. Para controlar ese efecto, en nuestro modelo \(MA(q)\) incluiremos dos variables dummies para dichos meses.

A continuación, estimaremos una \(MA(4)\) para la serie en diferencias:

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:MA04} MA(4) para la variable \(DLPaxMetro_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(DLPaxMetro_t\) & \(=\) & \(0.0000\) & \(-\) & \(0.7804\) & \(U_{t-1}\) \\
& & \((0.0000)\) & & \((0.0661)\) & \\
& \(+\) & \(0.3591\) & \(U_{t-2}\) & & \\
& & \((0.0826)\) & & & \\
& \(-\) & \(0.2775\) & \(U_{t-3}\) & & \\
& & \((0.0908)\) & & & \\
& \(-\) & \(0.1120\) & \(U_{t-4}\) & & \\
& & \((0.0769)\) & & & \\
& \(-\) & \(0.3789\) & \(DSep2017\) & & \\
& & \((0.0436)\) & & & \\
& \(+\) & \(0.3695\) & \(DOct2017\) & & \\
& & \((0.0434)\) & & & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.002176\) & \(AIC\) & \(=\) & \(-749.94\) \\
\end{longtable}

Entre parentésis indicamos los errores estándar y al final reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si la solución serán convergente, para ello en la Figura \ref{fig:fig411} mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que ambas propuesta de AR(2) representan una solución convergente y estable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(stats)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte\_ARIMA.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{"maroots.R"}\NormalTok{)}

\FunctionTok{source}\NormalTok{(}\StringTok{"plot.armaroots.R"}\NormalTok{)}

\NormalTok{Pax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{LPax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro), }
                 \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                 \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLPax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro) }\SpecialCharTok{{-}} 
                  \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Metro), }\DecValTok{1}\NormalTok{),}
                  \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                  \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Sep2017 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Sep2017, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Abr2020 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Abr2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_May2020   }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_May2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{MA\_LPax\_Metro }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(LPax\_Metro, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{), }
                       \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\NormalTok{MA\_LPax\_Metro\_2 }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(LPax\_Metro, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{),}
                       \AttributeTok{xreg =} \FunctionTok{cbind}\NormalTok{(D\_Abr2020, D\_Sep2017, }
\NormalTok{                                    D\_May2020),}
                       \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{maroots}\NormalTok{(MA\_LPax\_Metro), }
               \AttributeTok{main=}\StringTok{"Inverse MA roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{MA(p): LN PAx Metro"}\NormalTok{)}

\FunctionTok{plot.armaroots}\NormalTok{(}\FunctionTok{maroots}\NormalTok{(MA\_LPax\_Metro\_2), }
               \AttributeTok{main=}\StringTok{"Inverse MA roots of }\SpecialCharTok{\textbackslash{}n}\StringTok{MA(p): LN PAx Metro con Dummy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig411-1} 

}

\caption{Inveso de las Raíces del polinomio característico}\label{fig:fig411}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{procesos-armap-q-y-arimap-d-q}{%
\section{Procesos ARMA(p, q) y ARIMA(p, d, q)}\label{procesos-armap-q-y-arimap-d-q}}

Hemos establecido algunas relaciones las de los porcesos AR y los procesos MA, es decir, cómo un \(MA(q)\) de la serie \(X_t\) puede ser reexpresada como un \(AR(\infty)\) de la serie \(U_t\), y viceversa un \(AR(p)\) de la serie \(X_t\) puede ser reeexpresada como un \(MA(\infty)\).

En este sentido, para cerrar esta sección veámos el caso de la especificación que conjunta ambos modelos en un modelo general conocido como \(ARMA(p, q)\) o \(ARIMA(p, d, q)\). La diferencia entre el primero y el segundo es las veces que su tuvo que diferenciar la serie analizada, registro que se lleva en el índice \(d\) de los paramétros dentro del concepto \(ARIMA(p, d, q)\). No obstante, en general nos referiremos al modelo como \(ARMA(p, q)\) y dependerá del analista si modela la serie en niveles (por ejemplo, en logaritmos) o en diferencias logarítmicas (o diferencias sin logaritmos).

\hypertarget{arma1-1}{%
\subsection{ARMA(1, 1)}\label{arma1-1}}

Dicho lo anterior vamos a empezar con el análisis de un \(ARMA(1, 1)\). Un proceso \(ARMA(1, 1)\) puede verse como:
\begin{equation}
    X_t = \delta + a_1 X_{t - 1} + U_t - b_1 U_{t - 1}
    \label{eq:ARMA11Eq}
\end{equation}

Aplicando el operado rezago podemos rescribir la ecuación \eqref{eq:ARMA11Eq} como:
\begin{equation}
    (1 - a_1 L) X_t = \delta + (1 - b_1 L) U_t
\end{equation}

Donde \(U_t\) es un proceso pueramente aleatorio como en los casos de \(AR(p)\) y \(MA(q)\), y \(X_t\) puede ser una serie en niveles o en diferencias (ambas, en términos logarítmicos).

Así, el modelo \(ARIMA (p, q)\) también tiene una representación de Wold que estará dada por las siguientes expresiones:
\begin{equation}
    X_t = \frac{\delta}{1 - a_1} + \frac{1 - b_1 L}{1 - a_1 L} U_t
    \label{eq:ARMA11Prev}
\end{equation}

Donde \(a_1 \neq b_1\), puesto que en caso contrario \(X_t\) sería un proceso puramente aleatorio con una media \(\mu = \frac{\delta}{1 - a_1}\). Así, podemos reescribir la descomposición de Wold a partir del componente de la ecuación \eqref{eq:ARMA11Prev}:
\begin{equation}
    \frac{1 - b_1 L}{1 - a_1 L} = \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots 
    \label{eq:ARMA11EqWold}
\end{equation}

Está ecuación es equivalente a la expresión:
\begin{eqnarray}
    (1 - b_1 L) & = & (1 - a_1 L)(\psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots) \nonumber \\
    & = & \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots \nonumber \\
    &   & - a_1 \psi_0 L - a_1 \psi_1 L^2 - a_2 \psi_2 L^3 - a_1 \psi_3 L^4 - \ldots \nonumber
\end{eqnarray}

De esta forma podemos establecer el siguiente sistema de coeficientes indeterminados:
\begin{eqnarray*}
    L^0 & : & \Rightarrow \psi_0 = 1 \\
    L^1 & : & \psi_1 - a_1 \psi_0 = - b_1 \Rightarrow \psi_1 = a_1 - b_1 \\
    L^2 & : & \psi_2 - a_1 \psi_1 = 0 \Rightarrow \psi_2 = a_1(a_1 - b_1) \\
    L^3 & : & \psi_3 - a_1 \psi_2 = 0 \Rightarrow \psi_3 = a^2_1(a_1 - b_1) \\
     & \vdots &  \\
    L^j & : & \psi_j - a_1 \psi_{j - 1} = 0 \Rightarrow \psi_j = a^{j - 1}_1(a_1 - b_1)
\end{eqnarray*}

Así, la solución a la ecuación \eqref{eq:ARMA11Eq} estará dada por la siguiente generalización:
\begin{equation}
    X_t = \frac{\delta}{1 - a_1} + U_t + (a_1 - b_1) U_{t - 1} + a_1(a_1 - b_1) U_{t - 2} + a_1^2(a_1 - b_1) U_{t - 3} + \ldots
    \label{eq:ARMA11Sol}
\end{equation}

En la ecuación \eqref{eq:ARMA11Sol} las condiciones de estabilidad y de invertibilidad del sistema (de un MA a un AR, y viceversa) estarán dadas por: \$ \textbar{} a\_1 \textbar{} \textless{} 1 \$ y \$ \textbar{} b\_1 \textbar{} \textless{} 1 \$. Adicionalmente, la ecuación \eqref{eq:ARMA11Sol} expresa cómo una serie que tiene un comportamiento \(ARMA(1, 1)\) es equivalente a una serie modelada bajo un \(MA(\infty)\).

Al igual que en los demás modelos, ahora determinaremos los momentos del proceso \(ARMA(1, 1)\). La media estará dada por:
\begin{eqnarray}
    \mathbb{E}[X_t] & = & \mathbb{E}[\delta + a_1 X_{t-1} + U_t - b_1 U_{t-1}] \nonumber \\
    & = & \delta + a_1 \mathbb{E}[X_{t-1}] \nonumber \\
    & = & \frac{\delta}{1 - a_1} \nonumber \\
    & = & \mu
\end{eqnarray}

Donde hemos utilizado que \(\mathbb{E}[X_t] = \mathbb{E}[X_{t-1}] = \mu\). Es decir, la media de un \(ARMA(1, 1)\) es idéntica a la de un \(AR(1)\).

Para determinar la varianza tomaremos una estrategía similar a los casos de \(AR(p)\) y \(MA(q)\). Por lo que para todo \(\tau \geq 0\), y suponiendo por simplicidad que \(\delta = 0\) (lo que implica que \(\mu = 0\)) tendremos:
\begin{eqnarray}
    \mathbb{E}[X_{t-\tau} X_t] & = & \mathbb{E}[(X_{t-\tau}) \cdot (a_1 X_{t-1} + U_t - b_1 U_{t-1})] \nonumber \\
    & = & a_1 \mathbb{E}[X_{t-\tau} X_{t-1}] + \mathbb{E}[X_{t-\tau} U_t] - b_1 \mathbb{E}[X_{t-\tau} U_{t-1}]
    \label{eq:ARMA11Cov}
\end{eqnarray}

De la ecuación \eqref{eq:ARMA11Cov} podemos determinar una expresión para el caso de \(\tau = 0\):
\begin{eqnarray}
    \mathbb{E}[X_{t} X_t] & = & \gamma(0) \nonumber \\
    & = & a_1 \gamma(1) + \mathbb{E}[U_t X_t] - b_1 \mathbb{E}[X_t U_{t-1}] \nonumber \\
    & = & a_1 \gamma(1) + \sigma^2 + b_1 \mathbb{E}[U_{t-1} (a_1 X_{t-1} + U_t - b_1 U_{t-1})] \nonumber \\
    & = & a_1 \gamma(1) + \sigma^2 - b_1 a_1 \sigma^2 + b_1 \sigma^2 \nonumber \\
    & = & a_1 \gamma(1) + (1 - b_1 (a_1 - b_1)) \sigma^2
\end{eqnarray}

Para el caso en que \(\tau = 1\): \begin{eqnarray}
    \mathbb{E}[X_{t-1} X_t] & = & \gamma(1) \nonumber \\
    & = & a_1 \gamma(0) + \mathbb{E}[X_{t-1} U_t] - b_1 \mathbb{E}[X_{t-1} U_{t-1}] \nonumber \\
    & = & a_1 \gamma(0) - b_1 \sigma^2
\end{eqnarray}

Estas últimas expresiones podemos resolverlas como sistema para determinar los siguientes valores:
\begin{eqnarray}
    \gamma(0) & = & \frac{1 + b_1^2 - 2 a_1 b_1}{1 - a_1^2} \sigma^2 \\
    \gamma(1) & = & \frac{(a_1 - b_1)(1 - a_1 b_1)}{1 - a_1^2} \sigma^2
\end{eqnarray}

En general para cualquier valor \(\tau \geq 2\) tenemos que la autocovarianza y la función de autocorrelación serán:
\begin{eqnarray}
    \gamma(\tau) = a_1 \gamma(\tau - 1) \\
    \rho(\tau) = a_1 \rho(\tau - 1)
\end{eqnarray}

Por ejemplo, para el caso de \(\tau = 1\) tendríamos:
\begin{equation}
    \rho(1) = \frac{(a_1 - b_1)(1 - a_1 b_1)}{1 + b_1^2 - 2 a_1 b_1}
\end{equation}

De esta forma, la función de autocorrelación oscilará en razón de los valores que tome \(a_1\) y \(b_1\).

\hypertarget{armap-q}{%
\subsection{ARMA(p, q)}\label{armap-q}}

La especificación general de un \(ARMA(p, q)\) (donde \(p, q \in \mathbb{N}\)) puede ser descrita por la siguiente ecuación:
\begin{eqnarray}
    X_t & = & \delta + a_1 X_{t - 1} + a_2 X_{t - 2} + \ldots + a_p X_{t - p} \nonumber \\
    &   & + U_t - b_1 U_{t - 1} - b_2  U_{t - 2} - \ldots - b_q  U_{t - q}
    \label{eq:ARMApqEq}
\end{eqnarray}

Donde \(U_t\) es un proceso puramente aleatorio, y \(X_t\) puede ser modelada en niveles o en diferencias (ya sea en logaritmos o sin
transformación logarítmica).

Mediante el uso del operador rezago se puede escribir la ecuación \eqref{eq:ARMApqEq} como:
\begin{equation}
    (1 - a_1 L - a_2 L^2 - \ldots - a_p L^p) X_t = \delta + (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q) U_t 
    \label{eq:ARMApqEqLag}
\end{equation}

En la ecuación \eqref{eq:ARMApqEqLag} definamos dos polinomios: \(\alpha(L) = (1 - a_1 L - a_2 L^2 - \ldots - a_p L^p)\) y \(\beta(L) = (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q)\). Así, podemos reescribir la ecuación \eqref{eq:ARMApqEqLag} como:
\begin{equation}
    \alpha(L) X_t = \delta + \beta(L) U_t 
\end{equation}

Asumiendo que existe el polinomio inverso tal que: \(\alpha(L)^{-1}\alpha(L) = 1\).La solución entonces puede ser escrita como:
\begin{eqnarray}
    X_t & = & \alpha(L)^{-1} \delta + \alpha(L)^{-1} \beta(L) U_t \nonumber \\
    & = & \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + \frac{\beta(L)}{\alpha(L)} U_t \nonumber \\
    & = & \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + U_t + \psi_1 L U_t + \psi_2 L^2 U_t + \ldots
    \label{eq:ARMApqWold}
\end{eqnarray}

Donde la ecuación \eqref{eq:ARMApqWold} nos permite interpretar que un ARMA(p, q) se puede reexpresar e interpreetar como un \(MA(\infty)\) y donde las condiciones para la estabilidad de la solución y la invertibilidad es que las ráices de los polinomios característicos \(\alpha(L)\) y \(\beta(L)\) son en valor absoluto menores a 1.

Adicionalmente, la fracción en la ecuación \eqref{eq:ARMApqWold} se puede descomponer como en la forma de Wold:
\begin{equation}
    \frac{\beta(L)}{\alpha(L)} = 1 + \psi_1 L + \psi_2 L^2 + \ldots
\end{equation}

Bajo los supuestos de estacionariedad del componente \(U_t\), los valores de la media y varianza de un proceso \(ARMA(p, q)\) serán como describimos ahora. Para el caso de la media podemos partir de la ecuación \eqref{eq:ARMApqWold} para generar:
\begin{eqnarray}
    \mathbb{E}[X_t] & = & \mathbb{E}\left[ \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + U_t + \psi_1 U_{t-1} + \psi_2 U_{t-2} + \ldots \right] \nonumber \\
    & = & \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} \nonumber \\
    & = & \mu
\end{eqnarray}

Esta expresión indica que en general un proceso \(ARMA(p, q)\) converge a una media idéntica a la de un porceso \(AR(p)\). Para determinar la varianza utilizaremos la misma estratégia que hemos utilizado para otros modelos \(AR(p)\) y \(MA(q)\).

Sin pérdida de generalidad podemos asumir que \(\delta = 0\), lo que implica que \(\mu = 0\), de lo que podemos establecer una expresión de autocovarianzas para cualquier valor \(\tau = 0, 1, 2, \ldots\):
\begin{eqnarray}
    \gamma(\tau) & = & \mathbb{E}[X_{t-\tau} X_t] \nonumber \\
    & = & \mathbb{E}[X_{t-\tau} (\delta + a_1 X_{t - 1} + a_2 X_{t - 2} + \ldots + a_p X_{t - p} \nonumber \\
    &   & + U_t - b_1 U_{t - 1} - b_2  U_{t - 2} - \ldots - b_q  U_{t - q})] \nonumber \\
    & = & a_1 \gamma(\tau - 1) + a_2 \gamma(\tau - 2) + \ldots + a_p \gamma(\tau - p) \nonumber \\
    &   & + \mathbb{E}[X_{t-\tau} U_{t}] - b_1  \mathbb{E}[X_{t-\tau} U_{t-1}] - \ldots  - b_q  \mathbb{E}[X_{t-\tau} U_{t-q}] 
\end{eqnarray}

Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos nacionales de salida para estimar un \(ARMA(p, q)\) mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en diferencias logaritmicas, ya que según la gráfica en la Figura \ref{fig:fig47} esa es la que puede ser estacionaria.

A continuación, estimaremos una \(ARMA(1, 1)\) para la serie en diferencias logarimitcas (\(DLPaxNal_t\)). También incorporaremos al análisis variables exogénas tales como dummies de estacionalidad. En particular, utilizaremos los meses de enero, febrero, julio y diciembre. No debe pasar desapercibido que un análisis de estacionalidad más formal debeería considerar todos los meses para separar del término de error la parte que puedee ser explicada por los ciclos estacionales.

Así obtenemos el siguiente resultado:

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:ARMA01} ARMA(1, 1) para la variable \(DLPaxNal_t\).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
\(DLPaxNal_t\) & \(=\) & \(-0.0025\) & \(-\) & \(0.6018\) & \(DLPaxNal_{t-1}\) \\
& & \((0.0045)\) & & \((0.0964)\) & \\
& \(-\) & \(0.9064\) & \(U_{t-1}\) & & \\
& & \((0.0397)\) & & & \\
& \(-\) & \(0.0867\) & \(DEne_t\) & & \\
& & \((0.0230)\) & & & \\
& \(-\) & \(0.0409\) & \(DFeb_t\) & & \\
& & \((0.0263)\) & & & \\
& \(+\) & \(0.1529\) & \(DJul_t\) & & \\
& & \((0.0245)\) & & & \\
& \(+\) & \(0.0628\) & \(DDic_t\) & & \\
& & \((0.0223)\) & & & \\
\(\hat{\sigma}^2\) & \(=\) & \(0.007096\) & \(AIC\) & \(=\) & \(-475.12\) \\
\end{longtable}

Donde entre parentésis indicamos los errores estándar. Adicionalmente, reportamos el estadístico de Akaike (AIC). Finalmente, podemos determinar si las soluciones serán convergentes, para ello en la Figura \ref{fig:fig412} mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que tenemos una solución convergente y estable. Por su parte la Figura \ref{fig:fig413} muestra los residuales de la estimación del \(ARMA(1, 1)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_Roots\_ARMA11.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_Roots_ARMA11} 

}

\caption{Inveso de las Raíces del polinomio característico de un ARMA(1,1)}\label{fig:fig412}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_Residuals\_ARMA11.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_Residuals_ARMA11} 

}

\caption{Residuales de un $ARMA(1, 1)$ de la serie $DLPaxNal_t$}\label{fig:fig413}
\end{figure}

En lo que resta de este capítulo, utilizaremos la serie en diferencias logarítmicas de los pasajeros en vuelos nacionales de salida, \(DLPaxNal_t\), para discutir los ejemplos que ilustran cada uno de los puntos teóricos que a continuación exponemos.

\hypertarget{funciuxf3n-de-autocorrelaciuxf3n-parcial}{%
\section{Función de Autocorrelación Parcial}\label{funciuxf3n-de-autocorrelaciuxf3n-parcial}}

Ahora introduciremos el concepto de Función de Autocorrelación Parcial (PACF, por sus siglas en inglés). Primero, dadas las condiciones de estabilidad y de convergencia, si suponemos que un proceso AR, MA, ARMA o ARIMA tienen toda la información de los rezagos de la serie en conjunto y toda la información de los promedio móviles del término de error, resulta importante construir una métrica para distinguir el efecto de \(X_{t - \tau}\) o el efecto de \(U_{t - \tau}\) (para cualquier \(\tau\)) sobre \(X_t\) de forma individual.

La idea es construir una métrica de la correlación que existe entre las diferentes varibles aleatorias, si para tal efecto se ha controlado el efecto del resto de la información. Así, podemos definir la ecuación que puede responder a este planteamiento como:
\begin{equation}
    X_t = \phi_{k1} X_{t-1} + \phi_{k2} X_{t-2} + \ldots + \phi_{kk} X_{t-k} + U_t
    \label{eq:PACFEq}
\end{equation}

Donde \(\phi_{ki}\) es el coeficiente de la variable dada con el rezago \(i\) si el proceso tiene un órden \(k\). Así, los coeficientes \(\phi_{kk}\) son los coeficientes de la autocorrelación parcial (considerando un proceso AR(k)). Observemos que la autocorrelaicón parcial mide la correlación entre \(X_t\) y \(X_{t-k}\) que se mantiene cuando el efecto de las variables \(X_{t-1}\), \(X_{t-2}\), \(\ldots\) y \(X_{t-k-1}\) en \(X_{t}\) y \(X_{t-k}\) ha sido eliminado.

Dada la expresión considerada en la ecuación \eqref{eq:PACFEq}, podemos resolver el problema de establecer el valor de cada \(\phi_{ki}\) mediante la solución del sistema que se representa en lo siguiente:
\begin{equation}
    \left[ 
    \begin{array}{c}
        \rho(1) \\
        \rho(2) \\
        \vdots \\
        \rho(k)
    \end{array} 
    \right]
    = 
    \left[ 
    \begin{array}{c c c c}
        1 & \rho(1) & \ldots & \rho(k - 1)\\
        \rho(1) & 1 & \ldots & \rho(k - 2)\\
        \rho(2) & \rho(1) & \ldots & \rho(k - 3)\\
        \vdots & \vdots & \ldots & \vdots\\
        \rho(k - 1) & \rho(k - 2) & \ldots & 1\\
    \end{array} 
    \right]
    \left[ 
    \begin{array}{c}
        \phi_{k1} \\
        \phi_{k2} \\
        \phi_{k3} \\
        \vdots \\
        \phi_{kk} \\
    \end{array} 
    \right]
\end{equation}

Del cual se puede derivar una solución, resoviendo por el método de cramer, o cualquier otro método que consideremos y que permita calcular la solución de sistemas de ecuaciones.

Posterior al análisis analítico platearemos un enfoque para interpretar las funciones de autocorrelación y autocorrelación parcial. Este enfoque pretende aportar al principio de parcimonia, en el cual podemos identificar el número de parámetros que posiblemente puede describir mejor a la serie en un modelo ARMA(p, q).

En el siguiente cuadro mostramos un resumen de las caranterísticas que debemos observar para determinar el número de parámetros de cada uno de los componentes AR y MA. Lo anterior por observación de las funciones de autocorrelación y autocorrelación parcial. Este enfoque no es el más formal, más adelante implemtaremos uno más formal y que puede ser más claro de cómo determinar el númeto de parámetros.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{\label{tab:AcAcp} Relación entre la Función de Autocorrelación y la Función de Autocorrelación Parcial de una serie \(X_t\).}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Modelo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de Autocorrelación
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de Autocorrelación Parcial
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Modelo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de Autocorrelación
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de Autocorrelación Parcial
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MA(q) & Rompimienttos en la función & No hay rompimientos \\
AR(p) & No hay rompimientos & Rompimienttos en la función \\
\end{longtable}

Continuando con el ejemplo en la Figura \ref{fig:fig414} mostramos tanto la Función de Autocorrelación como la Función de Autocorrelación Parcial. En esta identificamos que ambas gráficas muestran que el modelo que explica a la variable \(DLPaxNal_t\) tiene tanto componentes AR como MA. Sin embargo, dado lo errático del comportamiento de ambas funciones, resulta complicado determinar cuál sería un buen número de parametros \(p\) y \(q\) a considerar en el \(ARMA(p,q)\). Por esta razón a continuación platearemos algunas pruebas más formales para determinar dichos parámetros.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_ACF\_PACF.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_ACF_PACF} 

}

\caption{Función de Autocorrelación y la Función de Autocorrelación Parcial de una serie $DLPaxNal_t$}\label{fig:fig414}
\end{figure}

\hypertarget{selecciuxf3n-de-las-constantes-p-q-d-en-un-arp-un-maq-un-armap-q-o-un-arimap-d-q}{%
\section{Selección de las constantes p, q, d en un AR(p), un MA(q), un ARMA(p, q) o un ARIMA(p, d, q)}\label{selecciuxf3n-de-las-constantes-p-q-d-en-un-arp-un-maq-un-armap-q-o-un-arimap-d-q}}

Respecto de cómo estimar un proceso ARMA(p, q) --en general utilizaremos este modelo para discutir, pero lo planteado en esta sección es igualmente aplicable en cualquier otro caso como aquellos modelos que incluyen variables exogénas-- existen diversas formas de estimar los paramétros \(a_i\) y \(b_i\): i) por máxima verosimilitd y ii) por mínimos cuadrados órdinarios. El primer caso requiere que conozcamos la distribución del proceso aleatorio \(U_t\). El segundo, por el contrario, no requiere el mismo supuesto. No obstante, para el curso utilizaremos el método de máxima verosimilitud.

Otra duda que debe quedar hasta el momento es ¿cómo determinar el orden \(p\) y \(q\) del proceso ARMA(p, q)? La manera más convencional y formal que existe para tal efecto es utilizar los criterios de información. Así, el orden se elije de acuerdo a aquel críterio de información que resulta ser el mínimo. En el caso de \(d\) se selecciona revisando la gráfica que parezca más estacionaria--más adelante mostraremos un proceso más formal para su selección.

Los criterios de información más comunes son los siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  FPE (Final Prediction Error):
  \begin{equation}
   FPE = \frac{T+m}{T-m}\frac{1}{T}\sum_{t=1}^{T} \left( \hat{U}_t^{(p)} \right) ^2
  \end{equation}
\item
  Akaike:
  \begin{equation}
   AIC = ln \left[ \frac{1}{T} \sum_{t=1}^{T} \left( \hat{U}_t^{(p)} \right) ^2 \right] + m \frac{2}{T}
  \end{equation}
\item
  Schwarz:
  \begin{equation}
   SC = ln \left[ \frac{1}{T} \sum_{t=1}^{T} \left( \hat{U}_t^{(p)} \right) ^2 \right] + m \frac{ln(T)}{T}
  \end{equation}
\item
  Hannan - Quinn:
  \begin{equation}
   HQ = ln \left[ \frac{1}{T} \sum_{t=1}^{T} \left( \hat{U}_t^{(p)} \right) ^2 \right] + m \frac{2 ln(ln(T))}{T}
  \end{equation}
\end{enumerate}

Donde \(\hat{U}_t^{(p)}\) son los residuales estimados mediante un proceso ARIMA y \(m\) es el número de parametros estimados: \(m = p + q + 0 + 1\) (ya que asumimos que \(d = 0\)). Una propiedad que no se debe perder de vista es que los criterios de información cumplen la siguiente relación:
\begin{equation}
    orden(SC) \leq orden(HQ) \leq orden(AIC)
\end{equation}

Por esta razón, durante el curso solo utilizaremos el criterio se Akaike para determinar el orden óptimo del proceso ARMA, ya que ello garantiza el orden más grande posible.

Ahora veamos un ejemplo de estimación del número de rezagos optimo de un \(ARMA(p, q)\). Retomemos la serie en diferencias logarítmicas de los pasajeros en vuelos nacionales de salidas, pero ahora incluiremos la variables exógenas de dummies estacionales: enero, febrero, julio y diciembre.

Como mencionamos, las gráficas de las funciones de autocorrelación permiten observar el valor de la correlación existente entre la variable en el momento \(t\) con cada uno de los rezagos. Incluso la Función de Autocorrelación Parcial puede ayudar a determinar el número máximo de rezagos que se debe incluir en el proceso \(AR(p)\). No obstante, una métrica más formal es el uso de los criterios de información. En nuestro caso, dado lo discutido, sólo utilizareemos el criterio de Akaike.

Al respecto, en el siguiente cuadro reportamos el criterio de Akaike que resultan de aplicar dicho criterio a los residuales resultantes de cada combinación de procesos \(ARMA(p, q)\). La forma de escoger será aquel modelo que reporta el criterio de Akaike menor. En la cuarta columna de la tabla se señala el valor del criterio de información que resulta ser el mínimo de todos los posibles.

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:CIARMA} Criterio de Akike para diferentes modelos \(ARMA(p, q)\) de la serie \(DLPaxNal_t\).}\tabularnewline
\toprule\noalign{}
Modelo & AR(p) & MA(p) & Akaike (AIC) & Óptimo \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Modelo & AR(p) & MA(p) & Akaike (AIC) & Óptimo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & 1 & -475.1190 & \\
2 & 1 & 2 & -473.4397 & \\
3 & 1 & 3 & -483.1239 & \\
4 & 1 & 4 & -482.4932 & \\
5 & 1 & 5 & -506.9880 & \\
6 & 1 & 6 & -533.9411 & \\
7 & 2 & 1 & -473.4758 & \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
24 & 4 & 6 & -752.8996 & * \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
36 & 6 & 6 & -752.2632 & \\
\end{longtable}

El cuadro anterior reporta los resultados para 36 diferentes modelos, todos incluyen variables exogenas. Como resultado del análisis concluimos que el modelo más adecuado es el 24, el cual considera un \(ARMA(4, 6)\), con variables dummies para controlar la estacionalidad de los meses de enero, febrero, julio y diciembre. Más adelante mostramos los resultados del modelo.

No obstante, una inspección de los residuales del modelo nos permite sospechar que requiere de incluir un par de dummies más. Ambas, asociadas con la caída del transporte aéreo en 2009, principalmente asociado con la crisis mundial de ese año. La Figura \ref{fig:fig415} muestra los residuales mencionados.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_Residuals\_ARMA46.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_Residuals_ARMA46} 

}

\caption{Residuales del ARMA(4, 6) de una serie $DLPaxNal_t$}\label{fig:fig415}
\end{figure}

Una vez incluidas dos dummies más para mayo y junio de 2009, analizamos un total de 36 modelos ARMA y determinamos que el orden que minimiza el criterio de Akaike es un \(ARMA(4, 6)\). El siguiente cuadro muestra los resultados para este nuevo modelo. No lo motramos en esta sección, pero ambos modelos reportados tienen raices de sus respectivos polinomios característicos menores a 1 en valor absoluto. En la Figura \ref{fig:fig416} mostramos los residuales ahora ajustados por las dummies de mayo y junio de 2009.

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:ARMApq} Modelo \(ARMA(p, q)\) de la serie \(DLPaxNal_t\).}\tabularnewline
\toprule\noalign{}
Variable & Coeficiente & Error Est. & Coeficiente & Error Est. \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Variable & Coeficiente & Error Est. & Coeficiente & Error Est. \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& Modelo 1 & Modelo 2 & & \\
Constante & 0.0134 & 0.0033 & 0.0145 & 0.0029 \\
\(DLPaxNal_{t-1}\) & 0.0004 & 0.0011 & 0.0014 & 0.0016 \\
\(DLPaxNal_{t-2}\) & 0.9997 & 0.0019 & 0.9988 & 0.0024 \\
\(DLPaxNal_{t-3}\) & 0.0001 & 0.0012 & 0.0002 & 0.0014 \\
\(DLPaxNal_{t-4}\) & -0.9997 & 0.0004 & -0.9993 & 0.0009 \\
\(\hat{U}_{t-1}\) & -0.2877 & 0.0670 & -0.1472 & 0.0633 \\
\(\hat{U}_{t-2}\) & -1.2028 & 0.0608 & -1.3323 & 0.0625 \\
\(\hat{U}_{t-3}\) & 0.2302 & 0.0765 & 0.1201 & 0.0756 \\
\(\hat{U}_{t-4}\) & 1.2085 & 0.0645 & 1.3142 & 0.0642 \\
\(\hat{U}_{t-5}\) & -0.2634 & 0.0708 & -0.1034 & 0.0717 \\
\(\hat{U}_{t-6}\) & -0.2171 & 0.0606 & -0.3864 & 0.0657 \\
\(DEne_{t}\) & -0.2904 & 0.0172 & -0.2865 & 0.0156 \\
\(DFeb_{t}\) & -0.1312 & 0.0170 & -0.1273 & 0.0140 \\
\(DJul_{t}\) & 0.3303 & 0.0173 & 0.3164 & 0.0156 \\
\(Dic_{t}\) & -0.0118 & 0.0169 & -0.0138 & 0.0137 \\
\(DMay2009_{t}\) & & & -0.3378 & 0.0360 \\
\(DJun2009_{t}\) & & & 0.2371 & 0.0359 \\
\(\hat{\sigma}^2\) & 0.001841 & & 0.001283 & \\
AIC & -752.9 & & -835.73 & \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_Residuals\_ARMA46\_D.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_Residuals_ARMA46_D} 

}

\caption{Residuales del ARMA(4, 6) de una serie $DLPaxNal_t$}\label{fig:fig416}
\end{figure}

\hypertarget{pronuxf3sticos}{%
\section{Pronósticos}\label{pronuxf3sticos}}

Para pronósticar el valor de la serie es necesario determinar cuál es el valor esperado de la serie en un momento \(t + \tau\) condicional en que ésta se comporta como un \(AR(p)\), un \(MA(q)\) o un \(ARMA(p, q)\) y a que los valores antes de \(t\) están dados. Por lo que el pronóstico de la serie estará dado por una expresión:
\begin{eqnarray}
    \mathbb{E}_t[X_{t+\tau}] = \delta + a_1 \mathbb{E}_t[X_{t+\tau-1}] + a_2 \mathbb{E}_t[X_{t+\tau-2}] + \ldots + + a_p \mathbb{E}_t[X_{t+\tau-p}]
    \label{eq:ARMApqFor}
\end{eqnarray}

Lo anterior para todo \(\tau = 0, 1, 2, \ldots\) y considerando que los componentes MA(q) en la eucación (\eqref{eq:ARMApqFor}) son cero dado que para todo valor \(t + \tau\) es cierto que \(\mathbb{E}_t[U_{t+\tau}]\).

Continuando con el ejemplo, en la Figura \ref{fig:fig417} mostramos el resultado del pronóstico de la serie a partir del modelo ARMA(4, 6) que hemos discutido anteriormente.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(stats)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Base\_Transporte\_ARIMA.xlsx"}\NormalTok{, }
                    \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{Pax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal, }
              \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
              \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{LPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal), }
               \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
               \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLPax\_Nal }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{Pax\_Nal), }\DecValTok{1}\NormalTok{),}
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Mar2020   }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Mar2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Abr2020   }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Abr2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jun2020   }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Jun2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jul2020 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Jul2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Mar2021 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Mar2021, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Ene }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Ene, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Feb }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Feb, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jul }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Jul, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Dic }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos}\SpecialCharTok{$}\NormalTok{D\_Dic, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{ARMA\_Ex\_DLPax\_Nal\_2 }\OtherTok{\textless{}{-}} \FunctionTok{arima}\NormalTok{(DLPax\_Nal, }\AttributeTok{order =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{),}
                             \AttributeTok{xreg =} \FunctionTok{cbind}\NormalTok{(D\_Ene, D\_Feb, D\_Jul, }
\NormalTok{                                          D\_Dic, D\_Mar2020, }
\NormalTok{                                          D\_Abr2020, D\_Jun2020, }
\NormalTok{                                          D\_Jul2020, D\_Mar2021),}
                             \AttributeTok{method =} \StringTok{"ML"}\NormalTok{)}

\NormalTok{Predict\_Datos }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Predict\_Base\_Transporte\_ARIMA.xlsx"}\NormalTok{, }
                            \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{D\_Mar2020\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Mar2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Abr2020\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Abr2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jun2020\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Jun2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jul2020\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Jul2020, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Mar2021\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Mar2021, }
                \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
                \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Ene\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Ene, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Feb\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Feb, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Jul\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Jul, }
           \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{D\_Dic\_f }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Predict\_Datos}\SpecialCharTok{$}\NormalTok{D\_Dic, }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2022}\NormalTok{, }\DecValTok{7}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLPax\_Nal\_f }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ARMA\_Ex\_DLPax\_Nal\_2, }\AttributeTok{n.ahead =} \DecValTok{24}\NormalTok{, }
                      \AttributeTok{newxreg =} \FunctionTok{cbind}\NormalTok{(D\_Ene\_f, D\_Feb\_f, D\_Jul\_f, }
\NormalTok{                                      D\_Dic\_f, D\_Mar2020\_f, }
\NormalTok{                                      D\_Abr2020\_f, D\_Jun2020\_f, }
\NormalTok{                                      D\_Jul2020\_f, D\_Mar2021\_f))}

\NormalTok{Pronostico\_Arima }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"BD/Pronostico\_Arima.xlsx"}\NormalTok{, }
                               \AttributeTok{sheet =} \StringTok{"Datos"}\NormalTok{, }\AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{Pronostico\_Arima}\SpecialCharTok{$}\NormalTok{Pax\_Nal\_f }\OtherTok{\textless{}{-}}\NormalTok{ Pronostico\_Arima}\SpecialCharTok{$}\NormalTok{Pax\_Nal}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{24}\NormalTok{)\{}
\NormalTok{  Pronostico\_Arima}\SpecialCharTok{$}\NormalTok{Pax\_Nal\_f[}\DecValTok{281} \SpecialCharTok{+}\NormalTok{ i] }\OtherTok{\textless{}{-}} 
\NormalTok{    Pronostico\_Arima}\SpecialCharTok{$}\NormalTok{Pax\_Nal\_f[}\DecValTok{281} \SpecialCharTok{+}\NormalTok{ i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ DLPax\_Nal\_f}\SpecialCharTok{$}\NormalTok{pred[i])}
\NormalTok{\}}

\FunctionTok{options}\NormalTok{(}\AttributeTok{scipen =} \DecValTok{999}\NormalTok{) }\CommentTok{\# NO notacion cientifica}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pronostico\_Arima, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Periodo)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ Pax\_Nal\_f, }\AttributeTok{color =} \StringTok{"Pax\_Nal\_f"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ Pax\_Nal, }\AttributeTok{color =} \StringTok{"Pax\_Nal"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_brewer}\NormalTok{(}\AttributeTok{type =} \StringTok{"qual"}\NormalTok{, }\AttributeTok{palette =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\#theme\_bw() + }
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"bottom"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{col =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{nrow =} \DecValTok{1}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Tiempo"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Pasajeros"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{11}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{, }
                                  \AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.margin =} \FunctionTok{unit}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\StringTok{"cm"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Pasajeros en vuelos nacionales (Salidas)"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"(Ene{-}2000 a Jun{-}2019)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Fuente: Elaboración propia"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig417-1} 

}

\caption{Pronóstico de la serie $PaxNAl_t$ a partir de una ARMA(4,6) en diferencias logaritmicas}\label{fig:fig417}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"Pax\_Nal\_f.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{20}\NormalTok{, }\AttributeTok{height =} \DecValTok{15}\NormalTok{, }\AttributeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{desestacionalizaciuxf3n-y-filtrado-de-series}{%
\chapter{Desestacionalización y filtrado de Series}\label{desestacionalizaciuxf3n-y-filtrado-de-series}}

\hypertarget{motivaciuxf3n}{%
\section{Motivación}\label{motivaciuxf3n}}

Existen múltiples enfoques para la desestacionalización de series. Algunos modelos, por ejemplo, pueden estar basados en modelos ARIMA como un conjunto de dummies. No obstante, en el caso partícular que discutiremos en este curso, estará basado en un modelo ARIMA de la serie. Este enfoque está basado en el modelo X11 de la oficina del censo de Estados Unidos (Census Bureau) el cual es conocido como el modelo X13-ARIMA-SEATS.\footnote{ La información y material respecto del modelo esta disponible en la dirección \url{https://www.census.gov/srd/www/x13as/}} El modelo X13-ARIMA-SEATS es, como su nombre lo indica, la combinación de un modelo ARIMA con componentes estacionales (por la traducción literal de la palabra: seasonal).

Un modelo ARIMA estacional emplea la serie en diferencias y como regresores los valores rezagados de las diferencia de la serie tantas veces como procesos estacionales \(s\) existan en ésta, con el objeto de remover los efectos aditivos de la estacionalidad. Sólo para entender qué significa este mecanismo, recordemos que cuando se utiliza la primera direncia de la serie respecto del periodo inmediato anterior se remueve la tendencia. Por su parte, cuando se incluye la diferencia respecto del mes \(s\) se está en el caso en que se modela la serie como una media móvil en términos del rezago \(s\).

El modelo ARIMA estacional incluye como componentes autoregresivos y de medias móviles a los valores rezagados de la serie en el periodo \(s\) en diferencias. El ARIMA(p, d, q)(P, D, Q) estacional puede ser expresado de la siguiente manera utilizando el operador rezago \(L\):
\begin{equation}
    \Theta_P(L^s) \theta_p(L) (1 - L^s)^D (1 - L)^d X_t = \Psi_Q(L^s) \psi_q(L) U_t
    (\#eq:ARIMA_seas)
\end{equation}

Donde \(\Theta_P(.)\), \(\theta_p(.)\), \(\Psi_Q(.)\) y \(\psi_q(.)\) son polinomios de \(L\) de orden \(P\), \(p\), \(Q\) y \(q\) respectivamente. En general, la representación es de una serie no estacionaria, aunque si \(D = d = 0\) y las raíces del polinomio carácteristico (de los polinomios del lado izquierdo de la ecuación @ref(eq:ARIMA\_seas) todas son más grandes que 1 en valor absoluto, el proceso modelado será estacionario.

Si bien es cierto que existen otras formas de modelar la desestacionalización, como la modelación en diferencias con dummies para identificar ciertos patrones regulares, en los algorimtos disponibles como el X11 o X13-ARIMA-SEATS se emplea la formulación de la ecuación @ref(eq:ARIMA\_seas). A continuación implementaremos la desestacionalización de una serie.

Como ejemplo utilizaremos la serie del Índice Nacional de Precios al Consumidor (INPC). Podemos ver que la serie original del INPC y su ajuste estacional bajo una metodología X13-ARIMA-SEATS son como se muestra en la Figura \ref{fig:fig51}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_INPC\_Adj.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_INPC_Adj} 

}

\caption{Índice Nacional de Precios al Consumidor ($INPC_t$) y su serie desestacionalizada utilizando un proceso X13-ARIMA-SEATS}\label{fig:fig51}
\end{figure}

El mismo procesamiento puede ser seguido para todas las series que busquemos analizar. En particular, en adelante, además del INPC que incluimos en la lista, utilzaremos las siguientes series, así como su versión desestacionalizada:

\begin{itemize}
    \item Índice Nacional de Precios al Consumidor (base 2QJul2018 = 100), $INPC_t$.
    \item Tipo de Cambio FIX, $TC_t$
    \item Tasa de rendimiento promedio mensual de los Cetes 28, en por ciento anual, $CETE28_t$
    \item Indicador global de la actividad económica (base 2013 = 100), $IGAE_t$
    \item Industrial Production Index o Índice de Producción Industrial de los Estados Unidos (base 2012 = 100), $IPI_t$
\end{itemize}

\hypertarget{filtro-hodrick-prescott}{%
\section{Filtro Hodrick-Prescott}\label{filtro-hodrick-prescott}}

Como último tema de los procesos univariados y que no necesariamente aplican a series estacionarias, a continuación desarrollaremos el procedimiento conocido como filtro de Hodrick y Prescott (1997). El trabajo de estos autores era determinar una técnica de regresión que permitiera utilizar series agregadas o macroeconómicas para separarlas en dos componentes: uno de ciclo de negocios y otro de tendencia. En su trabajo orignal Hodrick y Prescott (1997) utilizaron datos trimestrales de alguna series como el Gross Domestic Product (GNP, por sus siglas enn Inglés), los agregados montearios M1, empleo, etc., de los Estados Unidos que fueron observados posteriormente a la Segunda Guerra Mundial.

El marco conceptual de Hodrick y Prescott (1997) parte de suponer una serie \(X_t\) que se puede descomponer en la suma de componente de crecimiento tendencial, \(g_t\), y su componente de ciclio de negocios, \(c_t\), de esta forma para \(t = 1, 2, \ldots, T\) tenemos que:
\begin{equation}
    X_t = g_t + c_t
    (\#eq:HP_Eq)
\end{equation}

En la ecuación @ref(eq:HP\_Eq) se asume que el ajuste de la ruta seguida por \(g_t\) es resultado de la suma de los cuadrados de su segunda diferencia. En esa misma ecuación sumiremos que \(c_t\) son las desviaciones de \(g_t\), las cuales en el largo plazo tienen una media igual a cero (0). Por esta razón, se suele decir que el filtro de Hodrick y Prescott represeta una una descomposición de la serie en su componente de crecimiento natural y de sus desviaciones transitorias que en promedio son cero, en el largo plazo.

Estas consideraciones que hemos mencionado señalan que el procesimiento de Hodrick y Prescott (1997) implican resolver el siguiente problema minimización para determinar cada uno de los componentes en que \(X_t\) se puede descomponer:
\begin{equation}
    \min_{\{ g_t \}^T_{t = -1} } \left[ \sum^T_{t = 1} c^2_t + \lambda \sum^T_{t = 1} [ \Delta g_t - \Delta g_{t-1}]^2 \right]
\end{equation}

Donde \(\Delta g_t = g_t - g_{t-1}\) y \(\Delta g_{t-1} = g_{t-1} - g_{t-2}\); \(c_t = X_t - g_t\), y el parámetro \(\lambda\) es un número positivo que penaliza la variabilidad en el crecimiento de las series. De acuerdo con el trabajo de Hodrick y Prescott (1997) la constante \(\lambda\) debe tomar valores especificos de acuerdo con la periodicidad de la series. Así, \(\lambda\) será:

\begin{itemize}
    \item 100 si la serie es de datos anuales
    \item 1,600 si la serie es de datos trimestrales
    \item 14,400 si la serie es de datos mensuales
\end{itemize}

En resumen, podemos decir que el filtro de Hodrick y Prescott (1997) es un algoritmo que mimiza las distancias o variaciones de la trayectoria de largo plazo. De esta forma, determina una trayectoria estable de largo plazo, por lo que las desviaciones respecto de esta trayectoria serán componentes de ciclos de negocio o cambios transitorios (tanto positivos como negativos).

A contiuación, ilustraremos el filtro de Hodrick y Prescott (1997) para dos series desestacionalizadas: \(INPC_t\) y \(TC_t\). Las Figura \ref{fig:fig52} y Figura \ref{fig:fig53} muestran los resultados de la implementación del filtro.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_INPC\_HP.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_INPC_HP} 

}

\caption{Descomposición del Índice Nacional de Precios al Consumidor ($INPC_t$) en su tendencia o trayectoria de largo plazo y su ciclo de corto plazo utilizando un filtro Hodrick y Prescott (1997)}\label{fig:fig52}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/G\_TC\_HP.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/G_TC_HP} 

}

\caption{Descomposición del Tipo de Cambio FIX ($TC_t$) en su tendencia o trayectoria de largo plazo y su ciclo de corto plazo utilizando un filtro Hodrick y Prescott (1997)}\label{fig:fig53}
\end{figure}

\hypertarget{filtro-hodrick-prescott-planteado-por-st-amant-van-norden}{%
\subsection{Filtro Hodrick-Prescott planteado por St-Amant \& van Norden}\label{filtro-hodrick-prescott-planteado-por-st-amant-van-norden}}

Método tradicional de HP consiste en minimizar la serie \(\{ \tau_t \}_{t=-1}^T\):

\[\sum_{t=1}^T (y_t - \tau_t)^2 + \lambda \sum_{t=1}^{T} [(\tau_{t} - \tau_{t-1}) - (\tau_{t-1} - \tau_{t-2})]^2\]

Donde \(\lambda\) es una parámetro fijo (determinado ex-ante) y \(\tau_t\) es un componente de tendencia de \(y_t\).

Sin pérdida de generalidad, asumiremos que \(\tau_{-1}\) y \(\tau_{0}\) son cero (0). De esta manera, la forma matricial del filtro HP es:
\[(Y - G)'(Y - G) + \lambda G' K' K G\]

La derivada de los anteriores:
\[-2 Y + 2 G + \lambda 2 K' K G = 0\]

Despejando:
\[G_{hp} = [I_T + \lambda K' K]^{-1} Y\]

Donde \(G\) es el vector de tendencia, \(Y\) es el vector de la serie de datos, \(\lambda\) es la constante tradicional, y \(K\) es de dimensión \(T \times T\) y está dada por la expresión:
\[K =
\begin{pmatrix}
1 & 0 & 0 & 0 & \ldots & 0 \\
-2 & 1 & 0 & 0 & \ldots & 0 \\
1 & -2 & 1 & 0 & \ldots & 0 \\
0 & 1 & -2 & 1 & \ldots & 0 \\
\vdots & \vdots &  \vdots &  \vdots &  \vdots &  \vdots \\
0 & 0 & 0 & 0 & \ldots & 1 \\
\end{pmatrix}
\]

Así:

\[K' =
\begin{pmatrix}
1 & -2 & 1 & 0 & \ldots & 0 \\
0 & 1 & -2 & 1 & \ldots & 0 \\
0 & 0 & 1 & -2 & \ldots & 0 \\
0 & 0 & 0 & 1 & \ldots & 0 \\
\vdots & \vdots &  \vdots &  \vdots &  \vdots &  \vdots \\
0 & 0 & 0 & 0 & \ldots & 1 \\
\end{pmatrix}
\]

Método modificado de HP consiste en minimizar los valores de la serie \(\{ \tau_t \}_{t=1}^T\):
\[\sum_{t=1}^T (y_t - \tau_t)^2 + \lambda \sum_{t=2}^{T-1} [(\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1})]^2 + \lambda_{ss} \sum_{t=T-j}^{T} [\Delta \tau_t - u_{ss}]\]

Donde \(\lambda\) es una parámetro fijo (determinado ex-ante), \(\tau_t\) es un componente de tendencia de \(y_t\), y los nuevos parámetros son \(u_{ss}\) y \(\lambda_{ss}\) ajustadas por el procedimiento de Marcet y Ravn (2004).

Este procedimiento asume que parte del filtro HP y que esta versión tiene el problema de pérdida de información al final y al principio de la muestra. La razón es que es un procedimeinto univariado que requiere de mucha información futura y pasada para mejorar el ajuste.

El compoenente adicional al filtro HP es un componente de castigo por desviaciones de la tasa de crecimiento de largo plazo, \(u_{ss}\).

El proceso de selección de \(\lambda_{ss}\) es e propuesto por Marcet y Ravn (2004), el cual consiste en utilizar un \(\lambda\) convencional y el filtro HP convencional para estimar la siguiente función:
\[F(\lambda) = \frac{\sum_{t=2}^{T-1} ((\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1}))^2}{\sum_{t=1}^T (y_t - \tau_t)^2}\]

Entonces el valor de \(\lambda_{ss}\) será aquel que:
\[F(\lambda_{ss}) = \frac{\sum_{t=2}^{T-1} ((\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1}))^2}{\sum_{t=1}^T (y_t - \tau_t)^2} = F(\lambda)\]

nota: Antón (2009) estimó \(\lambda_{ss} = 1096\) para datos trimestrales del PIB.

La forma matricial del filtro HP-SAVN es:
\[(Y - G)'(Y - G) + \lambda G' K' K G + \lambda_{ss} (L^j G + \overline{u}_{ss} M^j)\]

Donde \(L^j = (0, 0, \ldots, 0, -1, 0, \ldots, 0, 1)\), en el cual el valor \(-1\) es en la posición \(T-j-1\)-ésima, y \(M^j\) es un vector que toma valores de cero hasta antes de \(T-j\) y de 1 después.

La derivada de los anteriores:
\[-2 Y + 2 G + \lambda 2 K' K G + \lambda_{ss} L'^j = 0\]

Despejando:
\[G_{SAVN} = \frac{1}{2} [I_T + \lambda K' K]^{-1} (2 Y - \lambda_{ss} L'^j)\]

\[G_{SAVN} = [I_T + \lambda K' K]^{-1} Y - \frac{1}{2} [I_T + \lambda K' K]^{-1} \lambda_{ss} L'^j\]

Donde \(G\) es el vector de tendencia, \(Y\) es el vector de la serie de datos, \(\lambda\) es la constante tradicional, y \(K\) es de dimensión \(T \times T\) y está dada por la expresión:

\[K' =
\begin{pmatrix}
1 & -2 & 1 & 0 & \ldots & 0 \\
0 & 1 & -2 & 1 & \ldots & 0 \\
\vdots & \vdots &  \vdots &  \vdots &  \vdots &  \vdots \\
0 & 0 & 0 & 0 & \ldots & 1 \\
\end{pmatrix}
\]

Dicho lo anterior, podemos modificar \(F(\lambda)\) para el filtro HP convencional como en forma matricial:
\[F(\lambda) = \frac{G' K' K G}{(Y - G)'(Y - G)}\]

\hypertarget{procesos-basados-en-vectores-autoregresivos}{%
\chapter{Procesos Basados en Vectores Autoregresivos}\label{procesos-basados-en-vectores-autoregresivos}}

\chapter{Procesos basados en Vectores Autoregresivos}

En este capítulo removeremos el supuesto de que el análisis es univariado, ya que introduciremos la posibilidad de que los procesos generadores de datos compartan información entre dos o más series. Como primer aproximación desarrollaremos el concepto de Causalidad de Granger. Mediante esta metodología discutiremos cuando dos series se causan estadísticamente. Posteriormente, introduciremos una técnica más sofisticada conocida como la metodología de Vectores Autoregresivos (VAR), la cual es una generalización de los procesos Autoregresivos (AR) que analizamos al principio del curso.

\hypertarget{causalidad-de-granger}{%
\section{Causalidad de Granger}\label{causalidad-de-granger}}

Hasta ahora hemos supuesto que una serie puede ser explicada únicamente con la información contenida en ella misma. No obstante, en adelante trataremos de analizar el caso en el que buscamos determinar relaciones entre variables y cómo el comportamiento de una serie influye en las demás. Algunas relaciones más importantes son las llamadas causalidad. En este caso analizaremos el procedimiento de Granger (1969), conocido como causalidad de Granger. En adelante asumiremos que las series involucradas son debílmente estacionarias.

Sean \(X\) y \(Y\) dos series debílmente estacionarias. Definamos a \(I_t\) un conjunto de toda la información disponible hasta el momento \(t\). Asimismo, digamos que \(\overline{X}_t\) y \(\overline{Y}_t\) son los conjuntos de toda la información disponible (actual y pasada) de \(X\) y \(Y\), respectivamente. Es decir:
\begin{eqnarray*}
    \overline{X}_t & := & \{ X_t, X_{t-1}, X_{t-2}, \ldots \} \\
    \overline{Y}_t & := & \{ Y_t, Y_{t-1}, Y_{t-2}, \ldots \} \\
    I_t & := & \overline{X}_t + \overline{Y}_t
\end{eqnarray*}

Adicionalmnete, definamos \(\sigma^2(*)\) como la varianza del término de error estimado de una regresión dada. Dicho lo anterior, digamos que:

\begin{enumerate}

\item Existe Causalidad de Granger o $X$ causa a $Y$ si y solo si, una regresión lineal da como resultado que: 
    \begin{equation}
        \sigma^2 (Y_{t+1} | I_t) < \sigma^2 (Y_{t+1} | I_t - X_t)    
    \end{equation}

Es decir, que la variabilidad del término de error de una regresión lineal de $Y$ sobre el conjunto de toda la información aplicada a un pronóstico de $Y_{t+1}$ es MENOR que la variabilidad del término de error de una regresión lineal de $Y$ sobre el conjunto de la información de $Y$ aplicada a un pronóstico de $Y_{t+1}$.

\item Existe Causalidad de Granger Instantanéa o $X$ causa de forma instantanéa a $Y$ si y solo si, una regresión lineal da como resultado:
    \begin{equation}
        \sigma^2 (Y_{t+1} | \{ I_t, X_{t+1} \}) < \sigma^2 (Y_{t+1} | I_t)
    \end{equation}

\end{enumerate}

La definición anterior aplica de igual forma si se reemplaza a \(X\) por \(Y\) y a \(Y\) por \(X\), respectivamente. De acuerdo a la definición anterior, existen 5 diferentes posibilidades de relaciones causales entre las dos series:

\begin{enumerate}
\item $X$ y $Y$ son independientes: $(X, Y)$;

\item Existe solo causalidad instantanéa: $(X - Y)$;

\item $X$ causa a $Y$: $(X \longrightarrow Y)$;

\item $Y$ causa a $X$: $(X \longleftarrow Y)$, y

\item Ambas series se causan: $(X \longleftrightarrow Y)$.

\end{enumerate}

Por lo anterior, representaremos mediante un \(AR(p)\) con variables exógenas lo siguiente:
\begin{equation}
    A(L) 
    \begin{bmatrix}
    Y_t \\ X_t
    \end{bmatrix}
    =
    \begin{bmatrix}
    a_{11}(L) & a_{12}(L) \\ a_{21}(L) & a_{22}(L)
    \end{bmatrix}
    \begin{bmatrix}
    Y_t \\ X_t
    \end{bmatrix}
    =
    \begin{bmatrix}
    V_t \\ U_t
    \end{bmatrix}
    \label{eq:GrangerEq}
\end{equation}

O en su versión \(MA(q)\) con variables exógenas:
\begin{equation}
    \begin{bmatrix}
    Y_t \\ X_t
    \end{bmatrix}
    =
    B(L)
    \begin{bmatrix}
    V_t \\ U_t
    \end{bmatrix}
    =
    \begin{bmatrix}
    b_{11}(L) & b_{12}(L) \\ b_{21}(L) & b_{22}(L)
    \end{bmatrix}
    \begin{bmatrix}
    V_t \\ U_t
    \end{bmatrix}
\end{equation}

Para determinar el test de causalidad utilizaremos una especificación similar a la de la ecuación \eqref{eq:GrangerEq}. Para probar si \(X\) causa a \(Y\) consideraremos la siguiente regresión:
\begin{equation}
    Y_t = \alpha_0 + \sum^{k_1}_{k = 1} a^k_{11} Y_{t-k} + \sum^{k_2}_{k = k_0} a^k_{12} X_{t-k} + U_{1,t}
\end{equation}

Donde \(k_0 = 1\) y, en general, se asume que \(k_1 = k_2\). Asimismo, el valor de estas constantes se puede determinar con el cirterio de Akaike (o cualquier otro criterio de información). No obstante, algunos autores sugieren que una buena práctica es considerar valores de \(k_1\) y \(k_2\) 4, 8, 12 y 16.

Dicho lo anterior, el test de causalidad de Granger se establece con una prueba F (similar a la definiada en el Apéndice de estas notas), en la cual se prueba la siguiente hipótesis nula:
\begin{equation}
    H_0: a^1_{12} = a^2_{12} = \ldots = a^{k2}_{12} = 0
\end{equation}

Ahora veámos un ejemplo. Consideremos como variables analizadas al Índice Nacional de Precios al Consumidor (\(INPC_t\)), al Tipo de Cambio (\(TDC_t\)) y al rendimiento anual de los Cetes a 28 días (\(CETE28_t\)), todas desestacionalizadas para el periodo de enero de 2000 a julio de 2019. Dado que la metodología de Granger supone que las series son estacionarias, utilizaremos las diferencias logaritmicas de cada una de las tres series (es decir, utilizaremos una transformación del tipo \(ln(X_t) - ln(X_{t-1})\)). La Figura \ref{fig:fig61} muestra las series en su transformación de diferencias logarítmicas.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(strucchange)}
\FunctionTok{library}\NormalTok{(zoo)}
\FunctionTok{library}\NormalTok{(sandwich)}
\FunctionTok{library}\NormalTok{(urca)}
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{library}\NormalTok{(vars)}

\CommentTok{\#}
\FunctionTok{load}\NormalTok{(}\StringTok{"BD/Datos\_Ad.RData"}\NormalTok{)}

\CommentTok{\#}
\NormalTok{INPC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{INPC\_Ad, }
           \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
           \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLINPC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{INPC\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{INPC\_Ad), }\DecValTok{1}\NormalTok{), }
             \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
             \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{TC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{TC\_Ad, }
         \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
         \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLTC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{TC\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{TC\_Ad), }\DecValTok{1}\NormalTok{), }
           \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
           \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{CETE28 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{CETE28\_Ad, }
             \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
             \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLCETE28 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{CETE28\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{CETE28\_Ad), }\DecValTok{1}\NormalTok{), }
               \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
               \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\CommentTok{\#png("Plots/DLGranger.png", width = 800, height = 1200)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(DLINPC, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Diferencias Logarítmicas del INPC"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(DLTC, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Diferencias Logarítmicas del Tipo de Cambio"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkblue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(DLCETE28, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Diferencias Logarítmicas de los Cetes a 28 dias"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"darkred"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig61-1} 

}

\caption{Series en diferencias logarítmicas dadas por las siguientes expresiones: $DLINPC_t = ln(DLINPC_t) - ln(DLINPC_{t-1})$, $DLTC_t = ln(TC_t) - ln(TC_{t-1})$ y $DLCETE28_t = ln(CETE28_t) - ln(CETE28_{t-1})$.}\label{fig:fig61}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\CommentTok{\#dev.off()}
\end{Highlighting}
\end{Shaded}

Por simplicidad, en el Cuadro \ref{tab:Granger} se muestra el resultado de aplicar el test de Granger a diferentes especificaciones, con rezagos 4, 8, 12 y 16, sólo para la serie de Tipo de Cambio en diferencias logarítmicas. En cada una de las pruebas se compara el modelo considerado como regresor a la variable que es candidata de causar, respecto del modelo si considerar a dicha variable.

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:Granger} Prueba de si \(DLINPC_t\) Granger causa a \(DLTC_t\).}\tabularnewline
\toprule\noalign{}
Rezagos & Estadiística F & Probabilidad (\(>\)F) & Significancia \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rezagos & Estadiística F & Probabilidad (\(>\)F) & Significancia \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4 & 3.2621 & 0.01265 & * \\
8 & 1.9079 & 0.06030 & \\
12 & 2.2577 & 0.01067 & * \\
16 & 1.6735 & 0.05495 & * \\
Notas: & *** & signif. & al 0.1\% \\
& ** & signif. & al 1\% \\
& * & signif. & al 5\% \\
\end{longtable}

De acuerdo con el Cuadro \ref{tab:Granger}, podemos concluir que existe información estadísticamente significativa para concluir que la inflación causa a la tasa de depreciación cambiaria, ambas medidas como las diferencias logaritmicas. El resto de los resultados para las otras combinaciones de causalidad se encuentran en el R Markdown llamado Clase 13 ubicado en el repositorio de GitHub.

\hypertarget{definiciuxf3n-y-representaciuxf3n-del-sistema-o-modelo-varp}{%
\section{Definición y representación del Sistema o Modelo VAR(p)}\label{definiciuxf3n-y-representaciuxf3n-del-sistema-o-modelo-varp}}

En esta sección ampliaremos la discusión planteada en el apartado anterior. En el sentido de que en la sección pasada nuestra discusión se limito al análisis de causalidad entre dos variables a la vez, que si bien es posible extenderlo a más variables es un procedimiento limitado a casos particulares por las siguientes razones.

El procediento de causalidad de Granger supone que es posible identificar un sistema de ecuaciones que debe conformarse una vez que se ha identificado el sentido de la causalidad. Así, el proceso anterior necesita del conocimiento previo de las relaciones que existen entre las varibles.

Adicionalmente, no resuleve el problema más general qué esta relacionado con cómo identificar la causalidad cuando se tienen múltiples variables con múltiples sentidos de causalidad. En esta sección analizaremos una mejor aproximación al probelma de cómo identificar la causalidad múltiple. Por lo tanto, como mécanismo para solucionar el problema planteado, analizaremos el caso de un Sistema o Modelo de Vectores Autoregresivos conocido como VAR.

El primer supuesto del que partiremos es que existe algún grado de endogenidad entre las variables considerdas en el análisis. Adicionalmente, el segundo supuesto que estableceremos es que requerimos que las variables que tengamos consideradas sean estacionarias.

Por lo anterior diremos que un VAR es un procedimiento que sigue fundado en el supuesto de que las variables consideredas son estacionarias, sin que hasta el momento hallamos podido establecer un mécanismo de detección de dicha estacionariedad. Así, hasta este momento del curso hemos pasado de modelo univariados a modelo múltivariados, pero no hemos podido dejar de asumir que las series son estacionarias.

Ahora bien, iniciaremos con el establecimiento de la representación del proceso. Digamos que tenemos un proceso estocástico \(\mathbf{X}\) estacionario de dimensión \(k\). De esta forma la expresión reducida del modelo o el proceso \(VAR(p)\) estará dado por:
\begin{equation}
    \mathbf{X}_t = \mathbf{\delta} + A_1 \mathbf{X}_{t-1} + A_2 \mathbf{X}_{t-2} + \ldots + A_p \mathbf{X}_{t-p} + \mathbf{U}_{t}
    \label{eq:VARp}
\end{equation}

Donde cada uno de las \(A_i\), \(i = 1, 2, \ldots, p\), son matrices cuadradas de dimensión \(k\) y \(\mathbf{U}_t\) representa un vector de dimensión \(k \times 1\) con los residuales en el momento del tiempo \(t\) que son un proceso pueramente aleatorio. También se incorpora un vector de términos constantes denominado como \(\mathbf{\delta}\), el cual es de dimensión \(k \times 1\).

Así, la ecuación \eqref{eq:VARp} supone la siguiente estructura de vectores:
\begin{equation*}
    \mathbf{X}_t = 
    \begin{bmatrix}
    X_{1t} \\ X_{2t} \\ \vdots \\ X_{kt}
    \end{bmatrix}
\end{equation*}

Para cualquier \(i = 1, 2, \ldots, p\):
\begin{equation*}
    \mathbf{X}_{t-i} = 
    \begin{bmatrix}
    X_{1t-i} \\ X_{2t-i} \\ \vdots \\ X_{kt-i}
    \end{bmatrix}
\end{equation*}

\begin{equation*}
    \mathbf{\delta} = 
    \begin{bmatrix}
    \delta_{1} \\ \delta_{2} \\ \vdots \\ \delta_{k}
    \end{bmatrix}
\end{equation*}

También, la ecuación \eqref{eq:VARp} supone que cada matriz \(A_i\), \(i = 1, 2, \ldots, p\), esta definida de la siguiente forma:
\begin{equation*}
    \mathbf{A}_i = 
    \begin{bmatrix}
    a^{(i)}_{11} & a^{(i)}_{12} & \ldots & a^{(i)}_{1k} \\ a^{(i)}_{21} & a^{(i)}_{22} & \ldots & a^{(i)}_{2k} \\ \vdots & \vdots & \ddots & \vdots \\ a^{(i)}_{k1} & a^{(i)}_{k2} & \ldots & a^{(i)}_{kk}
    \end{bmatrix}
\end{equation*}

Retomando la ecuación \eqref{eq:VARp} y considerando que podemos ocupar el operador rezago \(L^j\) de forma analóga al caso del modelo \(AR(p)\), pero aplicado a un vector, tenemos las siguientes ecuaciones:
\begin{eqnarray}
    \mathbf{X}_t - A_1 \mathbf{X}_{t-1} - A_2 \mathbf{X}_{t-2} - \ldots - A_p \mathbf{X}_{t-p} & = & \mathbf{\delta} + \mathbf{U}_{t} \nonumber \\
    \mathbf{X}_t - A_1 L \mathbf{X}_{t} - A_2 L^2 \mathbf{X}_{t} - \ldots - A_p L^p \mathbf{X}_{t-p} & = & \mathbf{\delta} + \mathbf{U}_{t} \nonumber \\
    (I_k - A_1 L - A_2 L^2 - \ldots - A_p L^p) \mathbf{X}_t & = & \mathbf{\delta} + \mathbf{U}_{t} \nonumber \\
    \mathbf{A}(L) \mathbf{X}_t & = & \mathbf{\delta} + \mathbf{U}_{t}
    \label{eq:VARCorto}
\end{eqnarray}

Adicionalmente, requeriremos que dado que \(\mathbf{U}_t\) es un proceso pueramente aleatorio, este debe cumplir con las siguientes condiciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  El valor esperado del término de error es cero:
  \begin{equation}
     \mathbb{E}[\mathbf{U}_t] = 0
    \end{equation}
\item
  Existe una matriz de varianzas y covarianzas entre los términos de error contemporáneos dada por:
  \begin{eqnarray}
     \mathbb{E}[\mathbf{U}_t \mathbf{U}_t'] 
     & = &
     \mathbb{E} \left[
     \begin{bmatrix}
     U^{(t)}_{1} \\ U^{(t)}_{2} \\ \vdots \\ U^{(t)}_{k}
     \end{bmatrix}
     \begin{bmatrix}
     U^{(t)}_{1} & U^{(t)}_{2} & \ldots & U^{(t)}_{k}
     \end{bmatrix}
     \right] \nonumber \\
     & = & \mathbb{E}
     \begin{bmatrix}
     U^{(t)}_{1} U^{(t)}_{1} & U^{(t)}_{1} U^{(t)}_{2} & \ldots & U^{(t)}_{1} U^{(t)}_{k} \\
     U^{(t)}_{2} U^{(t)}_{1} & U^{(t)}_{2} U^{(t)}_{2} & \ldots & U^{(t)}_{2} U^{(t)}_{k} \\
     \vdots & \vdots & \ldots & \vdots \\
     U^{(t)}_{k} U^{(t)}_{1} & U^{(t)}_{k} U^{(t)}_{2} & \ldots & U^{(t)}_{k} U^{(t)}_{k}
     \end{bmatrix} \nonumber \\
     & = & \begin{bmatrix}
     \sigma^2_1 & \rho_{12} & \ldots & \rho_{1k} \\
     \rho_{21} & \sigma^2_2 & \ldots & \rho_{2k} \\
     \vdots & \vdots & \ldots & \vdots \\
     \rho_{k1} & \rho_{k2} & \ldots & \sigma^2_k
     \end{bmatrix} \nonumber \\
     & = & \mathbf{\Sigma}_{UU}
     \label{eq:SigmaVAR}
    \end{eqnarray}
\item
  La matriz de varianzas y covarianzas no comtemporáneas es nula. Es decir, que para todo \(t \neq s\):
  \begin{eqnarray}
      \mathbb{E} [\mathbf{U}_t \mathbf{U}_s'] 
      & = &
      \mathbb{E} \left[
      \begin{bmatrix}
      U^{(t)}_{1} \\ U^{(t)}_{2} \\ \vdots \\ U^{(t)}_{k}
      \end{bmatrix}
      \begin{bmatrix}
      U^{(s)}_{1} & U^{(s)}_{2} & \ldots & U^{(s)}_{k}
      \end{bmatrix}
      \right] \nonumber \\
      & =  & \mathbb{E}
      \begin{bmatrix}
      U^{(t)}_{1} U^{(s)}_{1} & U^{(t)}_{1} U^{(s)}_{2} & \ldots & U^{(t)}_{1} U^{(s)}_{k} \\
      U^{(t)}_{2} U^{(s)}_{1} & U^{(t)}_{2} U^{(s)}_{2} & \ldots & U^{(t)}_{2} U^{(s)}_{k} \\
      \vdots & \vdots & \ldots & \vdots \\
      U^{(t)}_{k} U^{(s)}_{1} & U^{(t)}_{k} U^{(s)}_{2} & \ldots & U^{(t)}_{k} U^{(s)}_{k}
      \end{bmatrix} \nonumber \\
      & = & \mathbf{0}
      \label{eq:RhoVAR}
  \end{eqnarray}
\end{enumerate}

Las ecuaciones \eqref{eq:SigmaVAR} y \eqref{eq:RhoVAR} significan que los residuales \(\mathbf{U}_t\) pueden estar correlacionados entre ellos solo en el caso de que la información sea contemporánea, pero no tienen información en común entre residuales de otros periodos.

Al igual que en el caso del modelo o especificación \(AR(p)\) en la especificación del modelo \(VAR(p)\) existen condiciones de estabilidad. Dichas condiciones están dadas por lo siguiente, definamos el siguiente polinomio que resulta de tomar la matriz \(\mathbf{A}(L)\) en la ecuación \eqref{eq:VARCorto}:
\begin{equation}
    Det[I_t - A_1 z - A_2 z^2 - \ldots - A_p z^p] \neq 0
\end{equation}

Donde las raíces del polinomio cumplen que \(|z| \leq 1\), es decir, se ubican dentro del circulo unitario.

La ecuación \eqref{eq:VARCorto} puede ser rexpresada en una forma similar al un proceso de MA. Al respecto, de forma similar a la siguiente ecuación podemos construir un modelo \(VARMA(p,q)\), el cual no estudiamos es este curso.

Reromando el primer planteamiento, podemos escribir:
\begin{eqnarray}
    \mathbf{X}_t & = & \mathbf{A}^{-1}(L) \delta + \mathbf{A}^{-1}(L) \mathbf{U}_t \nonumber \\
    & = & \mu + \beta(L) \mathbf{U}_t
    \label{eq:VARMAq}
\end{eqnarray}

Por el lado de las matrices que representan la autocovarianza, estás resultan de resolver lo siguiente:
\begin{equation}
    \Gamma_X(\tau) = E[(\mathbf{X}_t - \mu)(\mathbf{X}_{t-\tau} - \mu)'] 
\end{equation}

Ahora, sin pérdida de generalidad digamos que la especificación VAR(p) en la ecuación \eqref{eq:VARp} no tiene constante, por lo que \(\delta = 0\), lo que implica que \(\mu = 0\). De esta forma las matrices de autocovarianza resultan de:
\begin{eqnarray*}
    \Gamma_X(\tau) & = & E[(\mathbf{X}_t)(\mathbf{X}_{t-\tau})'] \\
    & = & A_1 E[(\mathbf{X}_{t-1})(\mathbf{X}_{t-\tau})'] + A_2 E[(\mathbf{X}_{t-2})(\mathbf{X}_{t-\tau})'] \\
    &   & + \ldots + A_p E[(\mathbf{X}_{t-p})(\mathbf{X}_{t-\tau})'] + E[(\mathbf{U}_t(\mathbf{X}_{t-\tau})']
\end{eqnarray*}

Finalmente, al igual que en el caso \(AR(p)\) requerimos de una métrica que nos permita determinar el número de rezagos óptimo \(p\) en el \(VAR(p)\). Así, establecemos criterios de información similares a los del \(AR(p)\) dados por:

1.Final Prediction Error (FPE):
\begin{equation}
        FPE(p) = \left[ \frac{T + kp + 1}{T - kp - 1} \right]^k |\mathbf{\Sigma}_{\hat{U}\hat{U}}(p)|
        \end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Akaike Criterion (AIC):
  \begin{equation}
       AIC(p) = ln|\mathbf{\Sigma}_{\hat{U}\hat{U}}(p)| + (k + p k^2) \frac{2}{T}
       \end{equation}
\item
  Hannan - Quinn Criterion (HQ):
  \begin{equation}
       HQ(p) = ln|\mathbf{\Sigma}_{\hat{U}\hat{U}}(p)| + (k + p k^2) \frac{2ln(ln(2))}{T}
       \end{equation}
\item
  Schwartz Criterion (SC):
  \begin{equation}
       SC(p) = ln|\mathbf{\Sigma}_{\hat{U}\hat{U}}(p)| + (k + p k^2) \frac{ln(T)}{T}
       \end{equation}
\end{enumerate}

Donde la matriz de varianzas y covarianzas contemporáneas estará dada por:
\begin{equation*}
            \mathbf{\Sigma}_{\hat{U}\hat{U}}(p) = \mathbb{E} \left[
            \begin{bmatrix}
            U^{(t)}_{1} \\ U^{(t)}_{2} \\ \vdots \\ U^{(t)}_{k}
            \end{bmatrix}
            \begin{bmatrix}
            U^{(t)}_{1} & U^{(t)}_{2} & \ldots & U^{(t)}_{k}
            \end{bmatrix}
            \right]
        \end{equation*}

Ahora veámos un ejemplo de estimación de \(VAR(p)\). Para el ejemplo utilizaremos las series de INPC, Tipo de Cambio, rendimiento de los Cetes a 28 días, el IGAE y el Índice de Producción Industrial de los Estados Unidos, todas desestacionalizadas y para el período de enero de 2000 a julio de 2019. Dado que el supuesto estacionariedad sigue presente en nuestro análisis, emplearemos cada una de las series en su versión de diferencias logaritmicas. Las Figuras \ref{fig:fig62} y \ref{fig:fig63} muestra las series referidas.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(strucchange)}
\FunctionTok{library}\NormalTok{(zoo)}
\FunctionTok{library}\NormalTok{(sandwich)}
\FunctionTok{library}\NormalTok{(urca)}
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{library}\NormalTok{(vars)}

\CommentTok{\#}
\FunctionTok{load}\NormalTok{(}\StringTok{"BD/Datos\_Ad.RData"}\NormalTok{)}

\CommentTok{\#}
\NormalTok{DLINPC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{INPC\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{INPC\_Ad), }\DecValTok{1}\NormalTok{), }
             \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
             \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLTC }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{TC\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{TC\_Ad), }\DecValTok{1}\NormalTok{), }
           \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
           \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLCETE28 }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{CETE28\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{CETE28\_Ad), }\DecValTok{1}\NormalTok{), }
               \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
               \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLIGAE }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{IGAE\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{IGAE\_Ad), }\DecValTok{1}\NormalTok{), }
             \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
             \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{DLIPI }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{IPI\_Ad) }\SpecialCharTok{{-}} \FunctionTok{lag}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos\_Ad}\SpecialCharTok{$}\NormalTok{IPI\_Ad), }\DecValTok{1}\NormalTok{), }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(DLINPC, DLTC, DLCETE28, DLIGAE, DLIPI))}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos[}\DecValTok{2} \SpecialCharTok{:} \DecValTok{282}\NormalTok{, ], }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{freq =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(Datos, }\AttributeTok{plot.type =} \StringTok{"s"}\NormalTok{, }
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"black"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Series en Diferencias logaritmicas"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Variacion"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomright"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"INPC"}\NormalTok{, }\StringTok{"TC"}\NormalTok{, }\StringTok{"CETES28"}\NormalTok{, }\StringTok{"IGAE"}\NormalTok{, }\StringTok{"IPI"}\NormalTok{),}
       \AttributeTok{cex =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }
       \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"black"}\NormalTok{, }\StringTok{"purple"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig62-1} 

}

\caption{Series en diferencias logarítmicas (Forma 1)}\label{fig:fig62}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(Datos, }\AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Series en Diferencias logaritmicas"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig63-1} 

}

\caption{Series en diferencias logarítmicas (Forma 2)}\label{fig:fig63}
\end{figure}

Dicho lo anterior, a continuación mostraremos la tabla que resume el valor de los distintos criterios de información una especificación de un \(VAR(p)\) con constante. Notése que es posible especificar un \(VAR(p)\) con tendencia, caso que no aplica hasta este momento, ya que nuestro análisis de estacionariedad es claro respecto a la media constante (más adelante relajaremos este supuesto), lo cual elimina la poisiblidad de incluir una tendencia.

En el Cuadro \ref{tab:SelectVAR} reportamos los resultados de aplicar una prueba de criterios de información para diferentes valores de reagos. Del cual se concluye que el número óptimo de residuales es 2 (según el crietrio AIC y el FPE) y 1 (según el criterio HQ y el SC). Recordemos que es común que el criterio AIC siempre reporte el mayor valor de rezagos, por lo que es una buena práctica utilizarlo como referente principal.

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:SelectVAR} Criterios de información para diferentes especificaciones de modelos VAR(p) con término constante de la series \(DLINPC_t\), \(DLTC_t\), \(DLCETE28_t\), \(DLIGAE_t\) y \(DLIPI_t\).}\tabularnewline
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & -4.636412e+01 & -4.617847e+01 & -4.590430e+01 & 7.317262e-21 \\
2 & -4.639541e+01 & -4.605506e+01 & -4.555241e+01 & 7.094216e-21 \\
3 & -4.635305e+01 & -4.585799e+01 & -4.512686e+01 & 7.407479e-21 \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
\end{longtable}

De esta forma, justificamos la estimación de un \(VAR(2)\). Los resultados del mismo se repotartan en los siguientes cuadros, en los que se reporta el resultado de una de las ecuaciones. Los resultados restantes se encuentran en el Scrip Clase 14 que se encuentra en repositorio de GitHub. Primero mostraremos los resutlados de las raíces del polinomio caracteristico en el Cuadro \ref{tab:RootsVAR}, seguido de un cuadro para la ecuación del IGAE en el Cuadro @ref(tab:IGAE\_VAR) (por simplicidad se omiten las otras cuatro ecuaciones del VAR(2)), y del Cuadro \ref{tab:SigmaVARp} con la matriz \(\mathbf{\Sigma}_{\hat{U}\hat{U}}\) estimada del VAR.

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:RootsVAR} Raíces del polinomio característico de un VAR(2).}\tabularnewline
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0.7452 & 0.4403 & 0.4403 & 0.3503 & 0.3503 \\
0.3342 & 0.3342 & 0.3339 & 0.3339 & 0.06951 \\
\end{longtable}

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:IGAEVAR} Criterios de información para diferentes especificaciones de modelos VAR(p) con término constante de la series \(DLINPC_t\), \(DLTC_t\), \(DLCETE28_t\), \(DLIGAE_t\) y \(DLIPI_t\).}\tabularnewline
\toprule\noalign{}
Variable & Coeficiente & Error Est. & Estad. t & Prob.(\(>\) t) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Variable & Coeficiente & Error Est. & Estad. t & Prob.(\(>\) t) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(DLINPC_{t-1}\) & -0.2584978 & 0.1658396 & -1.559 & 0.120493 \\
\(DLTC_{t-1}\) & 0.0022016 & 0.0152876 & 0.144 & 0.885620 \\
\(DLCETE28_{t-1}\) & 0.0009547 & 0.0049115 & 0.194 & 0.846054 \\
\(DLIGAE_{t-1}\) & -0.2351453 & 0.0699797 & -3.360 & 0.000917 *** \\
\(DLIPI_{t-1}\) & 0.2442406 & 0.0600502 & 4.067 & 6.62e-05 *** \\
\(DLINPC_{t-2}\) & -0.0775039 & 0.1694809 & -0.457 & 0.647904 \\
\(DLTC_{t-2}\) & -0.0413316 & 0.0144650 & -2.857 & 0.004680 ** \\
\(DLCETE28_{t-2}\) & 0.0005341 & 0.0048058 & 0.111 & 0.911612 \\
\(DLIGAE_{t-2}\) & -0.0646890 & 0.0693711 & -0.933 & 0.352092 \\
\(DLIPI_{t-2}\) & 0.1796286 & 0.0620861 & 2.893 & 0.004195 ** \\
\(\delta_4\) & 0.0030377 & 0.0008077 & 3.761 & 0.000217 *** \\
& Notas: & *** & signif. & al 0.1\% \\
& & ** & signif. & al 1\% \\
& & * & signif. & al 5\% \\
\end{longtable}

\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tab:SigmaVARp} Matriz \(\mathbf{\Sigma}_{\hat{U}\hat{U}}\) estimada del VAR(2).}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& \(DLINPC_t\) & \(DLTC_t\) & \(DLCE28_t\) & \(DLIGAE_t\) & \(DLIGAE_t\) \\
\(DLINPC_t\) & 3.95e-06 & 3.19e-06 & -1.83e-06 & -5.29-07 & 1.34e-06 \\
\(DLTC_t\) & 3.19e-06 & 5.04e-04 & 4.27e-04 & 9.81e-06 & 1.61e-05 \\
\(DLCE28_t\) & -1.83e-06 & 4.27e-04 & 4.63e-03 & 1.26e-05 & 2.76e-05 \\
\(DLIGAE_t\) & -5.29e-07 & 9.81e-06 & 1.26e-05 & 2.43e-05 & 8.75e-06 \\
\(DLIGAE_t\) & 1.34e-06 & 1.61e-05 & 2.76e-05 & 8.75e-06 & 3.13e-05 \\
\end{longtable}

Finalmente, en el Cuadro \ref{tab:DiagnosVAR} reportamos las pruebas de diagnóstico del VAR(2). Incluímos las pruebas de normalidad, autocorrelación parcial y de heterocedásticidad.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}@{}}
\caption{\label{tab:DiagnosVAR} Pruebas de diagnóstico sobre los residuales del VAR(2).}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadística (rezagos)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Coeficiente
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
p-value
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Conclusión
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadística (rezagos)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Coeficiente
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
p-value
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Conclusión
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Correlación Serial (\(\chi^2 (2)\)) & 59.436 & 0.1696 & Existe autocorrelación serial \\
Correlación Serial (\(\chi^2 (4)\)) & 127.17 & 0.03461 & No existe autocorrelación serial \\
Correlación Serial (\(\chi^2 (6)\)) & 183.14 & 0.03393 & No existe autocorrelación serial \\
Normalidad - JB (\(\chi^2\)) & 2335 & 0.0000 & Los residuales no son normales \\
ARCH (\(\chi^2 (2)\)) & 691.58 & 0.0000 & Los residuales no son homocedásticos \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{VARselect}\NormalTok{(Datos, }\AttributeTok{lag.max =} \DecValTok{12}\NormalTok{, }\AttributeTok{type =} \StringTok{"const"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $selection
## AIC(n)  HQ(n)  SC(n) FPE(n) 
##      2      1      1      2 
## 
## $criteria
##                                    1                             2
## AIC(n) -43.4369385930444451560106245 -43.4878280980991220872056147
## HQ(n)  -43.2759374580961733158801508 -43.1926593506939511257769482
## SC(n)  -43.0360414131631969780755753 -42.7528499349835016118959174
## FPE(n)   0.0000000000000000001366449   0.0000000000000000001298899
##                                    3                             4
## AIC(n) -43.4268489491758202802884625 -43.3868843889051234441467386
## HQ(n)  -42.9975125893137573029889609 -42.8233804165861613455490442
## SC(n)  -42.3577898028258275076041173 -41.9837442593207583740877453
## FPE(n)   0.0000000000000000001381225   0.0000000000000000001438821
##                                   5                             6
## AIC(n) -43.293163285544032703455741 -43.2431704133633161291072611
## HQ(n)  -42.595491700768178588987212 -42.4113312161305699987678963
## SC(n)  -41.555942172725302441449458 -41.1718683173102135697263293
## FPE(n)   0.000000000000000000158246   0.0000000000000000001667106
##                                    7                             8
## AIC(n) -43.2902076769675190348607430 -43.2419352439015938216471113
## HQ(n)  -42.3242008672778737832231855 -42.1417608217550565541387186
## SC(n)  -40.8848245976800441781051632 -40.5024711813797466675168835
## FPE(n)   0.0000000000000000001595179   0.0000000000000000001680601
##                                    9                            10
## AIC(n) -43.2201406224138153788771888 -43.1788072276712782127106038
## HQ(n)  -41.9857985878103789900706033 -41.8102975806109569134605408
## SC(n)  -40.1465955766575959273723129 -39.7711811986806935692584375
## FPE(n)   0.0000000000000000001726236   0.0000000000000000001810365
##                                   11                            12
## AIC(n) -43.1191364389135785017970193 -43.0502244962885995960277796
## HQ(n)  -41.6164591793963580812487635 -41.4133796243144800541813311
## SC(n)  -39.3774294266886144555428473 -38.9744365008292632523989596
## FPE(n)   0.0000000000000000001936459   0.0000000000000000002093856
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VAR\_p }\OtherTok{\textless{}{-}} \FunctionTok{VAR}\NormalTok{(Datos, }\AttributeTok{p =} \DecValTok{2}\NormalTok{, }\AttributeTok{type =} \StringTok{"const"}\NormalTok{)}

\FunctionTok{summary}\NormalTok{(VAR\_p)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## VAR Estimation Results:
## ========================= 
## Endogenous variables: DLINPC, DLTC, DLCETE28, DLIGAE, DLIPI 
## Deterministic variables: const 
## Sample size: 279 
## Log Likelihood: 4142.895 
## Roots of the characteristic polynomial:
##  0.53  0.53 0.4501 0.4501 0.4425 0.4425 0.3251 0.3251 0.1677 0.1677
## Call:
## VAR(y = Datos, p = 2, type = "const")
## 
## 
## Estimation results for equation DLINPC: 
## ======================================= 
## DLINPC = DLINPC.l1 + DLTC.l1 + DLCETE28.l1 + DLIGAE.l1 + DLIPI.l1 + DLINPC.l2 + DLTC.l2 + DLCETE28.l2 + DLIGAE.l2 + DLIPI.l2 + const 
## 
##              Estimate Std. Error t value           Pr(>|t|)    
## DLINPC.l1    0.387061   0.063100   6.134 0.0000000030610259 ***
## DLTC.l1     -0.004611   0.005286  -0.872             0.3839    
## DLCETE28.l1  0.001229   0.002078   0.592             0.5546    
## DLIGAE.l1   -0.022088   0.015077  -1.465             0.1441    
## DLIPI.l1     0.009878   0.019363   0.510             0.6104    
## DLINPC.l2   -0.006707   0.063621  -0.105             0.9161    
## DLTC.l2      0.009608   0.005496   1.748             0.0816 .  
## DLCETE28.l2  0.001827   0.002051   0.891             0.3737    
## DLIGAE.l2    0.006544   0.014289   0.458             0.6473    
## DLIPI.l2    -0.015245   0.019632  -0.777             0.4381    
## const        0.002325   0.000294   7.908 0.0000000000000688 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## Residual standard error: 0.002176 on 268 degrees of freedom
## Multiple R-Squared: 0.1783,  Adjusted R-squared: 0.1476 
## F-statistic: 5.815 on 10 and 268 DF,  p-value: 0.00000006289 
## 
## 
## Estimation results for equation DLTC: 
## ===================================== 
## DLTC = DLINPC.l1 + DLTC.l1 + DLCETE28.l1 + DLIGAE.l1 + DLIPI.l1 + DLINPC.l2 + DLTC.l2 + DLCETE28.l2 + DLIGAE.l2 + DLIPI.l2 + const 
## 
##              Estimate Std. Error t value   Pr(>|t|)    
## DLINPC.l1   -1.344803   0.745382  -1.804    0.07233 .  
## DLTC.l1      0.315786   0.062442   5.057 0.00000079 ***
## DLCETE28.l1 -0.039912   0.024542  -1.626    0.10506    
## DLIGAE.l1    0.379306   0.178102   2.130    0.03411 *  
## DLIPI.l1    -0.514827   0.228727  -2.251    0.02521 *  
## DLINPC.l2    0.071779   0.751538   0.096    0.92398    
## DLTC.l2     -0.183813   0.064926  -2.831    0.00499 ** 
## DLCETE28.l2  0.030125   0.024228   1.243    0.21481    
## DLIGAE.l2    0.070713   0.168797   0.419    0.67561    
## DLIPI.l2    -0.166610   0.231909  -0.718    0.47312    
## const        0.006463   0.003473   1.861    0.06388 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## Residual standard error: 0.0257 on 268 degrees of freedom
## Multiple R-Squared: 0.1425,  Adjusted R-squared: 0.1105 
## F-statistic: 4.454 on 10 and 268 DF,  p-value: 0.000008102 
## 
## 
## Estimation results for equation DLCETE28: 
## ========================================= 
## DLCETE28 = DLINPC.l1 + DLTC.l1 + DLCETE28.l1 + DLIGAE.l1 + DLIPI.l1 + DLINPC.l2 + DLTC.l2 + DLCETE28.l2 + DLIGAE.l2 + DLIPI.l2 + const 
## 
##              Estimate Std. Error t value Pr(>|t|)  
## DLINPC.l1    3.933798   1.861561   2.113   0.0355 *
## DLTC.l1      0.112997   0.155945   0.725   0.4693  
## DLCETE28.l1  0.113300   0.061292   1.849   0.0656 .
## DLIGAE.l1   -0.588758   0.444803  -1.324   0.1868  
## DLIPI.l1     1.174496   0.571237   2.056   0.0407 *
## DLINPC.l2   -2.213087   1.876936  -1.179   0.2394  
## DLTC.l2      0.117661   0.162151   0.726   0.4687  
## DLCETE28.l2  0.063398   0.060509   1.048   0.2957  
## DLIGAE.l2   -0.237974   0.421565  -0.565   0.5729  
## DLIPI.l2     1.110203   0.579183   1.917   0.0563 .
## const       -0.007514   0.008674  -0.866   0.3872  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## Residual standard error: 0.06419 on 268 degrees of freedom
## Multiple R-Squared: 0.08823, Adjusted R-squared: 0.05421 
## F-statistic: 2.593 on 10 and 268 DF,  p-value: 0.005122 
## 
## 
## Estimation results for equation DLIGAE: 
## ======================================= 
## DLIGAE = DLINPC.l1 + DLTC.l1 + DLCETE28.l1 + DLIGAE.l1 + DLIPI.l1 + DLINPC.l2 + DLTC.l2 + DLCETE28.l2 + DLIGAE.l2 + DLIPI.l2 + const 
## 
##              Estimate Std. Error t value       Pr(>|t|)    
## DLINPC.l1    0.719855   0.393617   1.829         0.0685 .  
## DLTC.l1     -0.218508   0.032974  -6.627 0.000000000188 ***
## DLCETE28.l1  0.007718   0.012960   0.596         0.5520    
## DLIGAE.l1    0.037559   0.094051   0.399         0.6900    
## DLIPI.l1     0.389894   0.120785   3.228         0.0014 ** 
## DLINPC.l2   -0.737653   0.396868  -1.859         0.0642 .  
## DLTC.l2      0.073830   0.034286   2.153         0.0322 *  
## DLCETE28.l2 -0.013542   0.012794  -1.058         0.2908    
## DLIGAE.l2   -0.142845   0.089138  -1.603         0.1102    
## DLIPI.l2    -0.154835   0.122465  -1.264         0.2072    
## const        0.001637   0.001834   0.893         0.3729    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## Residual standard error: 0.01357 on 268 degrees of freedom
## Multiple R-Squared: 0.3272,  Adjusted R-squared: 0.3021 
## F-statistic: 13.03 on 10 and 268 DF,  p-value: < 0.00000000000000022 
## 
## 
## Estimation results for equation DLIPI: 
## ====================================== 
## DLIPI = DLINPC.l1 + DLTC.l1 + DLCETE28.l1 + DLIGAE.l1 + DLIPI.l1 + DLINPC.l2 + DLTC.l2 + DLCETE28.l2 + DLIGAE.l2 + DLIPI.l2 + const 
## 
##              Estimate Std. Error t value      Pr(>|t|)    
## DLINPC.l1    0.042383   0.326611   0.130        0.8968    
## DLTC.l1     -0.163742   0.027361  -5.985 0.00000000693 ***
## DLCETE28.l1  0.012143   0.010754   1.129        0.2598    
## DLIGAE.l1    0.098821   0.078041   1.266        0.2065    
## DLIPI.l1     0.067742   0.100224   0.676        0.4997    
## DLINPC.l2   -0.524835   0.329309  -1.594        0.1122    
## DLTC.l2      0.053353   0.028449   1.875        0.0618 .  
## DLCETE28.l2 -0.016237   0.010616  -1.529        0.1273    
## DLIGAE.l2   -0.088483   0.073964  -1.196        0.2326    
## DLIPI.l2    -0.082982   0.101618  -0.817        0.4149    
## const        0.002361   0.001522   1.551        0.1220    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## Residual standard error: 0.01126 on 268 degrees of freedom
## Multiple R-Squared: 0.1978,  Adjusted R-squared: 0.1679 
## F-statistic:  6.61 on 10 and 268 DF,  p-value: 0.000000003715 
## 
## 
## 
## Covariance matrix of residuals:
##                 DLINPC          DLTC    DLCETE28       DLIGAE       DLIPI
## DLINPC    0.0000047345 -0.0000001939 0.000004559  0.000006652  0.00000700
## DLTC     -0.0000001939  0.0006606619 0.000369751 -0.000035441 -0.00003174
## DLCETE28  0.0000045591  0.0003697510 0.004120747  0.000063618  0.00008525
## DLIGAE    0.0000066522 -0.0000354410 0.000063618  0.000184234  0.00011641
## DLIPI     0.0000069998 -0.0000317443 0.000085254  0.000116407  0.00012685
## 
## Correlation matrix of residuals:
##             DLINPC      DLTC DLCETE28   DLIGAE   DLIPI
## DLINPC    1.000000 -0.003466  0.03264  0.22524  0.2856
## DLTC     -0.003466  1.000000  0.22409 -0.10159 -0.1097
## DLCETE28  0.032640  0.224095  1.00000  0.07301  0.1179
## DLIGAE    0.225240 -0.101585  0.07301  1.00000  0.7615
## DLIPI     0.285629 -0.109656  0.11792  0.76147  1.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# Diagnostic tests}

\DocumentationTok{\#\#\#\# Normalidad:}

\FunctionTok{normality.test}\NormalTok{(VAR\_p)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $JB
## 
##  JB-Test (multivariate)
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 36186, df = 10, p-value < 0.00000000000000022
## 
## 
## $Skewness
## 
##  Skewness only (multivariate)
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 1261, df = 5, p-value < 0.00000000000000022
## 
## 
## $Kurtosis
## 
##  Kurtosis only (multivariate)
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 34925, df = 5, p-value < 0.00000000000000022
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\# Autocorrelacion Serial:}

\DocumentationTok{\#\#\#\# LAGS = 2:}

\FunctionTok{serial.test}\NormalTok{(VAR\_p, }\AttributeTok{lags.bg =} \DecValTok{2}\NormalTok{, }\AttributeTok{type =} \StringTok{"BG"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Breusch-Godfrey LM test
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 74.839, df = 50, p-value = 0.013
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\# LAGS = 4:}

\FunctionTok{serial.test}\NormalTok{(VAR\_p, }\AttributeTok{lags.bg =} \DecValTok{4}\NormalTok{, }\AttributeTok{type =} \StringTok{"BG"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Breusch-Godfrey LM test
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 131.69, df = 100, p-value = 0.01849
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\# LAGS = 6:}

\FunctionTok{serial.test}\NormalTok{(VAR\_p, }\AttributeTok{lags.bg =} \DecValTok{6}\NormalTok{, }\AttributeTok{type =} \StringTok{"BG"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Breusch-Godfrey LM test
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 201.63, df = 150, p-value = 0.003147
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\# Homocedasticidad:}

\FunctionTok{arch.test}\NormalTok{(VAR\_p, }\AttributeTok{lags.multi =} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  ARCH (multivariate)
## 
## data:  Residuals of VAR object VAR_p
## Chi-squared = 2122.4, df = 1350, p-value < 0.00000000000000022
\end{verbatim}

\hypertarget{anuxe1lisis-de-impulso-respuesta}{%
\section{Análisis de Impulso-Respuesta}\label{anuxe1lisis-de-impulso-respuesta}}

Una de las grandes ventajas que aporta el análisis de los modelos VAR es el análisis de Impulso-Respuesta. Dicho análisis busca cuantificar el efecto que tiene en \(\mathbf{X}_t\) una innovación o cambio en los residuales de cualquiera de las variables en un momento definido. Partamos dela ecuación \eqref{eq:VARMAq} de forma que tenemos:
\begin{eqnarray}
    \mathbf{X}_t & = & \mathbf{A}^{-1}(L) \delta + \mathbf{A}^{-1}(L) \mathbf{U}_t \nonumber \\
    & = & \mu + \mathbf{B}(L) \mathbf{U}_t \nonumber \\
    & = & \mu + \Psi_0 \mathbf{U}_t + \Psi_1 \mathbf{U}_{t-1} + \Psi_2 \mathbf{U}_{t-2} + \Psi_3 \mathbf{U}_{t-3} + \ldots
\end{eqnarray}

Donde \(\Psi_0 = I\) y cada una de las \(\Psi_i = - \mathbf{B}_i\), \(i = 1, 2, \ldots\). De esta forma se verifica el efecto que tiene en \(\mathbf{X}_t\) cada las innovaciones pasadas. Por lo que el análisis de Impulso-Respuesta cuantifica el efecto de cada una de esas matrices en las que hemos descompuesto a \(\mathbf{B}(L)\).

Retomando el modelo \(VAR(2)\) anteriormente estimado, en las siguientes figuras reportamos las gráficas de Impulso-respuesta de la serie \(DLTC_t\) ante cambios en los residuales del resto de las series y de la propia serie.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{IR\_DLINPC }\OtherTok{\textless{}{-}} \FunctionTok{irf}\NormalTok{(VAR\_p, }\AttributeTok{n.ahead =} \DecValTok{12}\NormalTok{, }\AttributeTok{boot =} \ConstantTok{TRUE}\NormalTok{, }
                 \AttributeTok{ci =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{response =} \StringTok{"DLINPC"}\NormalTok{)}

\NormalTok{IR\_DLINPC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Impulse response coefficients
## $DLINPC
##                 DLINPC
##  [1,]  0.0021759002410
##  [2,]  0.0008094393250
##  [3,]  0.0002429936391
##  [4,]  0.0001048999556
##  [5,]  0.0000430519256
##  [6,]  0.0000257195308
##  [7,]  0.0000108405478
##  [8,]  0.0000011471582
##  [9,] -0.0000014256627
## [10,] -0.0000009999499
## [11,] -0.0000003443770
## [12,] -0.0000001512886
## [13,] -0.0000001157354
## 
## $DLTC
##                 DLINPC
##  [1,]  0.0000000000000
##  [2,] -0.0000826837093
##  [3,]  0.0003117546911
##  [4,]  0.0002648974979
##  [5,]  0.0000587162871
##  [6,] -0.0000289491380
##  [7,] -0.0000105463736
##  [8,]  0.0000105785893
##  [9,]  0.0000076216336
## [10,] -0.0000004038885
## [11,] -0.0000021138204
## [12,] -0.0000004691794
## [13,]  0.0000003771599
## 
## $DLCETE28
##                  DLINPC
##  [1,]  0.00000000000000
##  [2,]  0.00006486928725
##  [3,]  0.00013182636385
##  [4,]  0.00003487943931
##  [5,]  0.00004740702286
##  [6,]  0.00003336371156
##  [7,]  0.00001571609856
##  [8,]  0.00000377046957
##  [9,]  0.00000005672766
## [10,]  0.00000025569500
## [11,]  0.00000033794064
## [12,]  0.00000004626880
## [13,] -0.00000011376620
## 
## $DLIGAE
##                  DLINPC
##  [1,]  0.00000000000000
##  [2,] -0.00021156780483
##  [3,] -0.00017900748374
##  [4,] -0.00001453803984
##  [5,]  0.00004387550079
##  [6,]  0.00001348412556
##  [7,] -0.00000660541189
##  [8,] -0.00000344927548
##  [9,]  0.00000223865243
## [10,]  0.00000206681740
## [11,]  0.00000008258756
## [12,] -0.00000046595182
## [13,] -0.00000009698431
## 
## $DLIPI
##                  DLINPC
##  [1,]  0.00000000000000
##  [2,]  0.00007038187903
##  [3,] -0.00011077803202
##  [4,] -0.00003218007799
##  [5,] -0.00001697303009
##  [6,]  0.00000048565947
##  [7,]  0.00001045292187
##  [8,]  0.00000469541763
##  [9,]  0.00000035996398
## [10,] -0.00000051048646
## [11,]  0.00000005294854
## [12,]  0.00000026647657
## [13,]  0.00000009015073
## 
## 
## Lower Band, CI= 0.95 
## $DLINPC
##                DLINPC
##  [1,]  0.001864170847
##  [2,]  0.000499776775
##  [3,]  0.000002450675
##  [4,] -0.000078104730
##  [5,] -0.000075950781
##  [6,] -0.000037958817
##  [7,] -0.000025483439
##  [8,] -0.000012332298
##  [9,] -0.000011329253
## [10,] -0.000007641493
## [11,] -0.000004043746
## [12,] -0.000001841703
## [13,] -0.000001172170
## 
## $DLTC
##                DLINPC
##  [1,]  0.000000000000
##  [2,] -0.000286990353
##  [3,]  0.000061870696
##  [4,]  0.000078542144
##  [5,] -0.000039820370
##  [6,] -0.000095870183
##  [7,] -0.000050900347
##  [8,] -0.000019789658
##  [9,] -0.000005574237
## [10,] -0.000008547257
## [11,] -0.000009189057
## [12,] -0.000004530429
## [13,] -0.000001945539
## 
## $DLCETE28
##                DLINPC
##  [1,]  0.000000000000
##  [2,] -0.000230649362
##  [3,] -0.000196536071
##  [4,] -0.000126449052
##  [5,] -0.000058700460
##  [6,] -0.000023095154
##  [7,] -0.000007659372
##  [8,] -0.000008557329
##  [9,] -0.000008242220
## [10,] -0.000005060508
## [11,] -0.000002432306
## [12,] -0.000001136291
## [13,] -0.000001066601
## 
## $DLIGAE
##                DLINPC
##  [1,]  0.000000000000
##  [2,] -0.000410323921
##  [3,] -0.000418493922
##  [4,] -0.000146714896
##  [5,] -0.000044408954
##  [6,] -0.000035327961
##  [7,] -0.000035119635
##  [8,] -0.000022423812
##  [9,] -0.000012260613
## [10,] -0.000003350492
## [11,] -0.000003212534
## [12,] -0.000004039474
## [13,] -0.000002483970
## 
## $DLIPI
##                 DLINPC
##  [1,]  0.0000000000000
##  [2,] -0.0001982996896
##  [3,] -0.0003103493634
##  [4,] -0.0001445269721
##  [5,] -0.0001147657072
##  [6,] -0.0000494580078
##  [7,] -0.0000148574620
##  [8,] -0.0000103989132
##  [9,] -0.0000059299583
## [10,] -0.0000046364719
## [11,] -0.0000029746270
## [12,] -0.0000012355125
## [13,] -0.0000008043852
## 
## 
## Upper Band, CI= 0.95 
## $DLINPC
##               DLINPC
##  [1,] 0.002423055334
##  [2,] 0.001069138548
##  [3,] 0.000514403106
##  [4,] 0.000299906999
##  [5,] 0.000185297033
##  [6,] 0.000101768840
##  [7,] 0.000056864142
##  [8,] 0.000028728717
##  [9,] 0.000018624195
## [10,] 0.000012817976
## [11,] 0.000006987585
## [12,] 0.000004523406
## [13,] 0.000002520736
## 
## $DLTC
##               DLINPC
##  [1,] 0.000000000000
##  [2,] 0.000137344529
##  [3,] 0.000583804216
##  [4,] 0.000433186162
##  [5,] 0.000171212748
##  [6,] 0.000036307348
##  [7,] 0.000034282255
##  [8,] 0.000038723787
##  [9,] 0.000024964010
## [10,] 0.000009783037
## [11,] 0.000003517692
## [12,] 0.000003748501
## [13,] 0.000003845745
## 
## $DLCETE28
##               DLINPC
##  [1,] 0.000000000000
##  [2,] 0.000304305857
##  [3,] 0.000373465696
##  [4,] 0.000167853443
##  [5,] 0.000127305791
##  [6,] 0.000089751434
##  [7,] 0.000049983292
##  [8,] 0.000025579016
##  [9,] 0.000012448007
## [10,] 0.000006485072
## [11,] 0.000004515005
## [12,] 0.000002515525
## [13,] 0.000001179168
## 
## $DLIGAE
##                DLINPC
##  [1,]  0.000000000000
##  [2,] -0.000006014034
##  [3,]  0.000035752798
##  [4,]  0.000101880979
##  [5,]  0.000107697317
##  [6,]  0.000067291001
##  [7,]  0.000019302644
##  [8,]  0.000009260325
##  [9,]  0.000010330953
## [10,]  0.000010351320
## [11,]  0.000004299667
## [12,]  0.000002280664
## [13,]  0.000001077557
## 
## $DLIPI
##                DLINPC
##  [1,] 0.0000000000000
##  [2,] 0.0002938283073
##  [3,] 0.0001164391542
##  [4,] 0.0000642643310
##  [5,] 0.0000621769713
##  [6,] 0.0000441663489
##  [7,] 0.0000332198998
##  [8,] 0.0000181489496
##  [9,] 0.0000082995640
## [10,] 0.0000034179891
## [11,] 0.0000034672138
## [12,] 0.0000024110405
## [13,] 0.0000009791902
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#plot(IR\_DLINPC)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{IR\_DLTC }\OtherTok{\textless{}{-}} \FunctionTok{irf}\NormalTok{(VAR\_p, }\AttributeTok{n.ahead =} \DecValTok{12}\NormalTok{, }\AttributeTok{boot =} \ConstantTok{TRUE}\NormalTok{, }
               \AttributeTok{ci =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{response =} \StringTok{"DLTC"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(IR\_DLTC)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig64-1} 

}

\caption{Impulso - Respuesta en $DLTC_t$}\label{fig:fig64-1}
\end{figure}
\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig64-2} 

}

\caption{Impulso - Respuesta en $DLTC_t$}\label{fig:fig64-2}
\end{figure}
\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig64-3} 

}

\caption{Impulso - Respuesta en $DLTC_t$}\label{fig:fig64-3}
\end{figure}
\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig64-4} 

}

\caption{Impulso - Respuesta en $DLTC_t$}\label{fig:fig64-4}
\end{figure}
\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig64-5} 

}

\caption{Impulso - Respuesta en $DLTC_t$}\label{fig:fig64-5}
\end{figure}

Los resultados muestran que la respuesta de \(DLTC_t\) ante impulsos en los términos de error fue estadísticamente significativo sólo para alguunos de los casos y en periodos cortos de tiempo. El resto de los resultados de Impulso-Respuesta se encuentra en el Scrip llamado Clase 15 que se ubica en el repositorio de GitHub.

\hypertarget{procesos-no-estacionarios}{%
\chapter{Procesos No Estacionarios}\label{procesos-no-estacionarios}}

\hypertarget{definiciuxf3n-y-formas-de-no-estacionariedad}{%
\section{Definición y formas de No Estacionariedad}\label{definiciuxf3n-y-formas-de-no-estacionariedad}}

Hasta ahora hemos planteado una serie de técnicas de regresión que aplican sólo a procesos o series estacionarias. En esta sección relajaremos la definición de estacionariedad y plantearemos pruebas para determinar cuando una serie es estacionaria bajo tres diferentes especificiones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Estacionariedad al rededor de una tendencia determinística;
\item
  Estacionariedad al rededor de una media, y
\item
  Estacionariedad al rededor del cero.
\end{enumerate}

A continuación discutiremos cómo es posible que una serie sea estacionaria al rededor de una tendencia determinística. Diremos que una tendencia es determinística si ésta puede ser aproximada o modelada por un polinomio en función de \(t\), la cual incluye posibles transformaciones logarítmicas.

Bajo este enfoque, el proceso está lejos de cumplir con la defición de estacionariedad que hemos establecido en capítulos previos, pero relajaremos el supuesto y reconoceremos que una serie puede ser estacionaria en varianza bajo una tendencia determinística. Así, diremos que la serie será descrita por una ecuación dada por:
\begin{equation}
    Y_t = \sum^m_{j = 0} \delta_j t^j + X_t
    \label{eq:YTrend}
\end{equation}

Donde \(X_t\) es un proceso \(ARMA(p, q)\) con media cero, que se puede ver como:
\begin{equation}
    \alpha(L) X_t = \beta(L) U_t
\end{equation}

Entonces, los momentos y variaza de la ecuación \eqref{eq:YTrend} estaran dados por:
\begin{equation}
    \mathbb{E}[Y_t] = \sum^m_{j = 0} \delta_j t^j = \mu_t
    \label{eq:ETrend}
\end{equation}

Dada la ecuación \eqref{eq:ETrend} podemos plantear la siguiente ecuación de covarainzas:
\begin{eqnarray}
    \mathbb{E}[(Y_t - \mu_t) \cdot (Y_{t+\tau} - \mu_{t+\tau})] & = & \mathbb{E}[X_t \cdot X_{t+\tau}] \nonumber \\
    & = & \gamma_X(\tau)
    \label{eq:CovTrend}
\end{eqnarray}

Utilizando el resultado de la ecuación \eqref{eq:CovTrend} podemos establecer que:
\begin{equation}
    \mathbb{E}[(Y_t - \mu_t)^2] = \mathbb{E}[X_t^2] = \sigma_X^2
    \label{eq:VarTrend}
\end{equation}

Así, las ecuaciones \eqref{eq:ETrend} y \eqref{eq:VarTrend} significan que el proceso descrito por la ecuación \eqref{eq:YTrend} es estacionario pero en varianza. De esta forma a partir de este momento diremos que una serie será estacionaria al rededor de una tendencia determinística si cumple con las condiciones establecidas en las ecuaciones \eqref{eq:YTrend}, \eqref{eq:ETrend} y \eqref{eq:VarTrend}.

Dicho lo anterior estudiaremos el concepto de raíz unitaria de un proceso estocástico o de una serie de tiempo. Partamos de platear que un proceso AR(1) tiene raíz unitaria cuando el cual el coeficiente \(a_1 = 1\), es decir:
\begin{equation}
    Y_t = Y_{t-1} + U_t
    \label{eq:UR1}
\end{equation}

Donde \(U_t\) es un proceso pueramente aleatorio con media cero, varianza constante y autocovarianza cero (0), al cual nos referiremos simplemente como ruido blanco. Supongamos ahora que incluímos un término constante en la ecuación \eqref{eq:UR1}, de forma que tenemos:
\begin{equation}
    Y_t = \delta + Y_{t-1} + U_t
    \label{eq:UR2}
\end{equation}

Tomando a la ecuación \eqref{eq:UR2} y suponiendo que existe un valor inicial \(Y_0\) de la serie podemos plantear la sguiente secuencia de expresiones:
\begin{eqnarray*}
    Y_1 & = & \delta + Y_0 + U_1 \\
    Y_2 & = & \delta + Y_1 + U_2 \\
    & = & \delta + (\delta + Y_0 + U_1) + U_2 \\
    & = & 2 \times \delta + Y_0 + U_1 + U_2
\end{eqnarray*}

Si repitieramos la sustitución sucesiva anterior hasta el momento \(t\) encontrariamos que la ecuación de la solución general que describe a un \(AR(1)\) con término constante que tiene raíz unitaria es de la forma:
\begin{equation}
    Y_t = t \delta + Y_0 + \sum_{i=1}^t U_i
    \label{eq:UR3}
\end{equation}

La ecuación \eqref{eq:UR3} es equivalente a la ecuación \eqref{eq:YTrend}. A la ecuación \eqref{eq:UR3} también se le conoce como proceso con Drift o con término constante, indistintamente, ya que el componente de Drift suele asociarse a la posibilidad de incorporar el efecto de los residuales pasados, lo cual es posible simplemente agregando una constante.s

Si revisamos el comportamiento de sus momentos y varianza de la ecuación \eqref{eq:UR3} encontramos que:
\begin{eqnarray*}
    \mathbb{E}[Y_t] & = & Y_0 + \delta t = \mu_t \\
    Var[Y_t] & = & t \sigma^2 = \gamma(0, t) \\
    Cov(Y_t, Y_{t+\tau}) & = & (t - \tau) \sigma^2 = \gamma(t, \tau)
\end{eqnarray*}

De esta forma, la ecuación \eqref{eq:UR3} no describe un proceso estacionario, sólo podría ser estacionario si \(t = 1\), en cualquier otro caso sería no estacionario en varianza. Ahora hagamos un resumen y acordemos notación que se utilizará en esta sección. Supongamos un proceso o serie de tiempo que es decrito por la siguiente ecuación:
\begin{equation}
    Y_t = \delta + Y_{t-1} + X_t
    \label{eq:UR4}
\end{equation}

Donde \(X_t\) es un \(ARMA(p, q)\) con media cero. Si definimos a \(\Delta Y_t = Y_t - Y_{t-1}\), entonces la ecuación \eqref{eq:UR4} la podemos escribir como:
\begin{equation}
    \Delta Y_t = \delta + X_t
    \label{eq:UR5}
\end{equation}

A la ecuación \eqref{eq:UR5} la denominaremos como un proceso estacionario en diferencias o simplemente como un proceso integrado. Así utilizaremos la siguiente definición.

Sea un proceso estocástico \(Y\), decimos que este es integrado de orden \(d\), \(I(d)\), si este puede transformarse a uno estacionacionario, que sea invertible, mediante la diferenciación del mismo \(d\)-veces, es decir:
\begin{equation}
    (1 - L)^d Y_t = \delta + X_t
    \label{eq:UR6}
\end{equation}

Donde \(X_t\) es un proceso \(ARMA(p, q)\). De lo cual se infiere que en la ecuación \eqref{eq:UR6} \(Y_t\) será una \(ARIMA(p, d, q)\), el cual contiene \(d\) raíces unitarias. A estos procesos también se les conoce como procesos con tendencia estocástica.

Dada la discusión annterior, a continuación platearemos un resumen de cuales son los dos casos a los cuales nos referiremos como procesos que no son estacionarios en media, pero que si lo son en varianza. Estos casos son:
\begin{eqnarray}
    Y_t & = & Y_0 + \delta t + U_t \\
    Y_t & = & Y_0 + \delta + \sum_{i = 1}^t U_t
\end{eqnarray}

Ambos casos no son estacionarios en media, pero si lo son en varianza. De ambos podemos decir que los choques o innovaciones del término de error tienen un efecto transitorio en el primero, pero permanentes en el segundo.

\hypertarget{pruebas-de-rauxedces-unitarias}{%
\section{Pruebas de Raíces Unitarias}\label{pruebas-de-rauxedces-unitarias}}

En esta sección plantearemos una serie de pruebas estadísticas para determinar cuando una serie puede ser estacionaria bajo tres posibles casos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Estacionariedad al rededor de una tendencia determinística;
\item
  Estacionariedad al rededor de una media, y
\item
  Estacionariedad al rededor del cero.
\end{enumerate}

\hypertarget{dickey---fuller-df}{%
\section{Dickey - Fuller (DF)}\label{dickey---fuller-df}}

Partamos de una forma del proceso \(Y_t\) dada por:
\begin{equation}
    Y_t = \sum_{j = 0}^m \delta_j t^j + X_t
    \label{eq:URDFG}
\end{equation}

Donde \(X_t\) es un \(ARMA(p, q)\) con media cero. Esta prueba asume que \(m = 1\), por lo que utilizaremos un modelo del tipo:
\begin{equation}
    Y_t = \alpha + \delta t + \rho Y_{t-1} + U_t
    \label{eq:URDF}
\end{equation}

Si, el \(AR(1)\) planteado tiene raíz unitaria, es decir, \(\rho = 1\), entonces tendríamos:
\begin{eqnarray*}
    Y_t & = & \alpha + \delta t + Y_{t-1} + U_t \\
    \Delta Y_t & = & \alpha + \delta t + U_t
\end{eqnarray*}

De esta forma, para determinar si una serie tiene raíz unitaria basta con probar la hipótesis nula de que \(H_0 : \rho = 1\), junto con las diferentes combinaciones que impliquen restricciones respecto a \(\delta\) y \(\alpha\).

En resumen, la prueba DF consiste en asumir un modelo general dado por la ecuación \eqref{eq:URDF} y probar tres especificaciones distintas que serían válidas bajo \(H_0 : \rho = 1\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Modelo A: con intercepto y tendencia:
  \begin{equation*}
   \Delta Y_t = \alpha + \delta t + \beta Y_{t-1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una tendencia determinística.
\item
  Modelo B: con intercepto:
  \begin{equation*}
   \Delta Y_t = \alpha + \beta Y_{t-1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una constante.
\item
  Modelo C: sin intercepto y tendencia:
  \begin{equation*}
   \Delta Y_t = \beta Y_{t-1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario sin considerar una constante o una tendencia determinística, es decir, es un proceso puramente aleatorio.
\end{enumerate}

\hypertarget{dickey---fuller-aumentada-adf}{%
\subsection{Dickey - Fuller Aumentada (ADF)}\label{dickey---fuller-aumentada-adf}}

A diferencia de un modelo AR(1) para el caso de una prueba DF como en la ecuación \eqref{eq:URDF}, en una prueba ADF se asume que el proceso es un AR(p) de la forma (por simplicidad hemos omitido el término constante y el término de tendencia determinística):
\begin{equation}
    Y_t = a_1 Y_{t-1} + a_2 Y_{t-2} + \ldots + a_p Y_{t-p} + U_t
    \label{eq:URADF}
\end{equation}

Haciendo una sustitución de términos similar a las que hemos planteado en otras secciones podemos reexpresar la ecuación \eqref{eq:URADF} en su versión en diferencias siguiendo el proceso:
\begin{equation}
    Y_t = \rho Y_{t-1} + \theta_1 \Delta Y_{t-1} + \theta_2 \Delta Y_{t-2} + \ldots + + \theta_{p-1} \Delta Y_{t-p+1} + U_t 
\end{equation}

Donde \(\rho = \theta_0 = \sum_{j = 1}^p a_j\), \(\theta_i = - \sum_{j = i + 1}^p a_j\), \(i = 1, 2, \ldots, p-1\). Así, si el proceso AR(p) tiene raíz unitaria entonces ceremos que:
\begin{eqnarray*}
    1 - a_1 - a_2 - \ldots - a_p & = & 0 \\
    \rho & = & 1
\end{eqnarray*}

De donde podemos establecer que el modelo general de una prueba ADF será:
\begin{equation}
    \Delta Y_{t-1} = \alpha + \beta t + (\rho - 1) Y_{t-1} + \theta_1 \Delta Y_{t-1} + \theta_2 \Delta Y_{t-2} + \ldots + \theta_k \Delta Y_{t-k} + U_t
\end{equation}

Donde \(U_t\) es un proceso puramente aleatorio y \(k\) es elegido de tal manera que los residuales sean un proceso puramente aleatorio. En resumen, la prueba DF consiste en asumir un modelo general dado por la ecuación \eqref{eq:URADF}, que incluya constante y tendencia, y probar tres especificaciones distintas que serían válidas bajo \(H_0 : \rho = 1\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Modelo A: con intercepto y tendencia:
  \begin{equation*}
  \Delta Y_t = \alpha + \delta t + \beta Y_{t-1} + \theta_1 \Delta Y_{t-1} + \theta_2 \Delta Y_{t-2} + \ldots + \theta_{p-1} \Delta Y_{t-p+1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una tendencia determinística.
\item
  Modelo B: con intercepto:
  \begin{equation*}
   \Delta Y_t = \alpha + \beta Y_{t-1} + \theta_1 \Delta Y_{t-1} + \theta_2 \Delta Y_{t-2} + \ldots + \theta_{p-1} \Delta Y_{t-p+1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una constante.
\item
  Modelo C: sin intercepto y tendencia:
  \begin{equation*}
   \Delta Y_t = \beta Y_{t-1} + \theta_1 \Delta Y_{t-1} + \theta_2 \Delta Y_{t-2} + \ldots + \theta_{p-1} \Delta Y_{t-p+1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \beta = \rho - 1 = 0\) contra \(H_a : \beta < 0\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario sin considerar una constante o una tendencia determinística, es decir, es un proceso puramente aleatorio.
\end{enumerate}

\hypertarget{phillips---perron-pp}{%
\subsection{Phillips - Perron (PP)}\label{phillips---perron-pp}}

Una tercera prueba es la de PP, la cual también está basada en una AR(1) dado por la ecuación:
\begin{equation}
    Y_t = d \eta + \rho Y_{t-1} + U_t
    \label{eq:URPP}
\end{equation}

Donde \(d\) incluye a cualquiera de los componentes determinísticos como constante y tendencia. Al igual que los casos pasados, la hipótesis a probar era \(H_0 : \rho = 1\) contra la alternativa \(H_a : | \rho | < 1\), y asumimos una estructura MA(q) es el término de error de la forma \(U_t = \psi(L) \varepsilon_t = \psi_0 \varepsilon_t + \psi_1 \varepsilon_{t-1} + \ldots + \psi_p \varepsilon_{t-p}\), con \(\varepsilon_t\) es un ruido blanco con media cero y varianza \(\sigma^2\). En este modelo se elige el valor \(p\) que hace que el componente sea un MA(p). Las tablas estadísticas de PP para esta prueba pueden utilizar una estadística \(Z_\tau\) o \(Z_\rho\), las cuales se pueden emplear indistintamente.

En resumen, la prueba PP consiste en asumir un modelo general dado por la ecuación \eqref{eq:URPP} y probar dos especificaciones distintas que serían válidas bajo \(H_0 : \rho = 1\), ambas considerando un compenente Drift:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Modelo A: con intercepto y tendencia:
  \begin{equation*}
   Y_t = \alpha + \delta t + \rho Y_{t-1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \rho = 1\) contra \(H_a : | \rho | < 1\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una tendencia determinística.
\item
  Modelo B: con intercepto:
  \begin{equation*}
   Y_t = \alpha + \rho Y_{t-1} + U_t
    \end{equation*}
  Buscamos probar si \(H_0 : \rho = 1\) contra \(H_a : | \rho | < 1\), por lo que es una prueba de una cola. Otra forma de decirlo, es probamos si el proceso tiene raíz unitaria contra si el proceso es estacionario al rededor de una constante.
\end{enumerate}

\hypertarget{kwiatkowsky---phillips---schmidt---shin-kpss}{%
\subsection{Kwiatkowsky - Phillips - Schmidt - Shin (KPSS)}\label{kwiatkowsky---phillips---schmidt---shin-kpss}}

La prueba KPSS considera que el proceso es estacionario bajo la hipótesis nula, lo cual hace una diferencia respecto de las anteriores pruebas. El modelo considerado es:
\begin{equation}
    Y_t = \delta t + \xi_t + U_t
\end{equation}

Donde \(U_t\) es un proceso estacionario y \(\xi_t\) es un ruido blanco descrito por la forma: \(\xi_t = \xi_{t-1} + \varepsilon_t\), donde \(\varepsilon_t\) es un proceso normalmente distribuido con media cero y varianza \(\sigma^2_\varepsilon\).

Así, bajo la hipótesis nula \(H_0 : \sigma^2_\varepsilon = 0\), \(\xi\) se vuelve una constante y el proceso puede tener una tendencia estacionaria. Dado el planteamiento de la prueba, los valores críticos al 95\% son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  0.146, para un modelo con tendencia
\item
  0.463, para un modelo con constante
\end{enumerate}

\hypertarget{ejemplo-con-aplicaciuxf3n-de-todas-las-pruebas-de-rauxedces-unitarias}{%
\subsection{Ejemplo con aplicación de todas las pruebas de raíces unitarias}\label{ejemplo-con-aplicaciuxf3n-de-todas-las-pruebas-de-rauxedces-unitarias}}

A continuación, mostraremos como ejemplo la aplicación de las pruebas de raíces unitarias a la serie de Tipo de Cambio en forma logaritmica y de diferencias logaritmicas. Asumamos que determinamos el valor de los rezagos de la prueba con el criterio de \(p = int\{ 4 (T/100)^{1/4} \}\). En la práctica, existen otras formas de determinar el valor de \(p\), como el criterio de AIC, pero es decisión del investigador cual usar.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(strucchange)}
\FunctionTok{library}\NormalTok{(zoo)}
\FunctionTok{library}\NormalTok{(sandwich)}
\FunctionTok{library}\NormalTok{(urca)}
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{library}\NormalTok{(vars)}

\CommentTok{\#}
\FunctionTok{load}\NormalTok{(}\StringTok{"BD/Datos\_Ad.RData"}\NormalTok{)}

\CommentTok{\#}
\DocumentationTok{\#\# Conversion a series de tiempo:}
\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos\_Ad[}\DecValTok{7}\SpecialCharTok{:} \DecValTok{11}\NormalTok{], }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{LDatos }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(Datos)}

\NormalTok{DLDatos }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos, }\AttributeTok{base =} \FunctionTok{exp}\NormalTok{(}\DecValTok{1}\NormalTok{)), }
                \AttributeTok{lag =} \DecValTok{1}\NormalTok{, }
                \AttributeTok{differences =} \DecValTok{1}\NormalTok{)}

\NormalTok{DaLDatos }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos, }\AttributeTok{base =} \FunctionTok{exp}\NormalTok{(}\DecValTok{1}\NormalTok{)), }
                 \AttributeTok{lag =} \DecValTok{12}\NormalTok{, }
                 \AttributeTok{differences =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(LDatos, }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Series en Logaritmos"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig71-1} 

}

\caption{Series en Logaritmos}\label{fig:fig71}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(DLDatos, }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Series en Diferencias Logaritmicas"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig72-1} 

}

\caption{Series en Diferencias Logaritmicas}\label{fig:fig72}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(DaLDatos, }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Series en Diferencias Anuales Logaritmicas"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig73-1} 

}

\caption{Series en Diferencias Anuales Logaritmicas}\label{fig:fig73}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(DLDatos, DaLDatos), }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Comparacion de Series en Diferencias"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig74-1} 

}

\caption{Comparacion de Series en Diferencias Anuales}\label{fig:fig74}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(LDatos, DLDatos), }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \AttributeTok{main =} \StringTok{"Comparacion de Series en Diferencias"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig75-1} 

}

\caption{Comparacion de Series en Diferencias}\label{fig:fig75}
\end{figure}

En los siguientes mostramos los resultados de aplicar las pruebas de raíces unitarias a la serie \(LTC_t\), considerando \(p = int \{ 4 (234/100)^{(1/4)} \} = 4\) para aquellas pruebas que requieren de rezagos: ADF, PP y KPSS.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Dickey{-}Fuller:}

\DocumentationTok{\#\#\# NIVELES: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.083973 -0.015415 -0.002526  0.009332  0.170645 
## 
## Coefficients:
##                Estimate  Std. Error t value Pr(>|t|)  
## (Intercept)  0.08700923  0.04029878   2.159   0.0317 *
## z.lag.1     -0.03844435  0.01852595  -2.075   0.0389 *
## tt           0.00011203  0.00006246   1.794   0.0740 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02705 on 278 degrees of freedom
## Multiple R-squared:  0.01629,    Adjusted R-squared:  0.00921 
## F-statistic: 2.301 on 2 and 278 DF,  p-value: 0.102
## 
## 
## Value of test-statistic is: -2.0752 2.1124 2.3013 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -3.98 -3.42 -3.13
## phi2  6.15  4.71  4.05
## phi3  8.34  6.30  5.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"drift"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.089442 -0.014571 -0.002497  0.009620  0.171964 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)
## (Intercept)  0.020316   0.015600   1.302    0.194
## z.lag.1     -0.006946   0.005925  -1.172    0.242
## 
## Residual standard error: 0.02716 on 279 degrees of freedom
## Multiple R-squared:  0.004903,   Adjusted R-squared:  0.001336 
## F-statistic: 1.375 on 1 and 279 DF,  p-value: 0.242
## 
## 
## Value of test-statistic is: -1.1724 1.5477 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.44 -2.87 -2.57
## phi1  6.47  4.61  3.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"none"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression none 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 - 1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.089736 -0.014701 -0.003293  0.010359  0.169748 
## 
## Coefficients:
##          Estimate Std. Error t value Pr(>|t|)
## z.lag.1 0.0007280  0.0006161   1.181    0.238
## 
## Residual standard error: 0.0272 on 280 degrees of freedom
## Multiple R-squared:  0.004961,   Adjusted R-squared:  0.001407 
## F-statistic: 1.396 on 1 and 280 DF,  p-value: 0.2384
## 
## 
## Value of test-statistic is: 1.1815 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau1 -2.58 -1.95 -1.62
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# DIFERENCIAS: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.09095 -0.01306 -0.00158  0.01055  0.17069 
## 
## Coefficients:
##                 Estimate   Std. Error t value            Pr(>|t|)    
## (Intercept)  0.002881589  0.003163345   0.911               0.363    
## z.lag.1     -0.736373275  0.058071315 -12.680 <0.0000000000000002 ***
## tt          -0.000009351  0.000019483  -0.480               0.632    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02634 on 277 degrees of freedom
## Multiple R-squared:  0.3673, Adjusted R-squared:  0.3628 
## F-statistic: 80.41 on 2 and 277 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -12.6805 53.6071 80.4095 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -3.98 -3.42 -3.13
## phi2  6.15  4.71  4.05
## phi3  8.34  6.30  5.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"drift"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.090664 -0.013492 -0.001331  0.010702  0.169754 
## 
## Coefficients:
##              Estimate Std. Error t value            Pr(>|t|)    
## (Intercept)  0.001566   0.001577   0.993               0.322    
## z.lag.1     -0.735658   0.057972 -12.690 <0.0000000000000002 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02631 on 278 degrees of freedom
## Multiple R-squared:  0.3668, Adjusted R-squared:  0.3645 
## F-statistic:   161 on 1 and 278 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -12.6899 80.5185 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.44 -2.87 -2.57
## phi1  6.47  4.61  3.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"none"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression none 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 - 1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.089121 -0.011916  0.000311  0.012192  0.171310 
## 
## Coefficients:
##         Estimate Std. Error t value            Pr(>|t|)    
## z.lag.1 -0.73093    0.05777  -12.65 <0.0000000000000002 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02631 on 279 degrees of freedom
## Multiple R-squared:  0.3646, Adjusted R-squared:  0.3623 
## F-statistic: 160.1 on 1 and 279 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -12.6515 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau1 -2.58 -1.95 -1.62
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Augmented Dickey {-} Fuller}

\DocumentationTok{\#\#\# NIVELES: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.077054 -0.014133 -0.002281  0.011551  0.167611 
## 
## Coefficients:
##                Estimate  Std. Error t value    Pr(>|t|)    
## (Intercept)  0.10899655  0.04255838   2.561      0.0110 *  
## z.lag.1     -0.04919274  0.01969939  -2.497      0.0131 *  
## tt           0.00015118  0.00006679   2.263      0.0244 *  
## z.diff.lag1  0.32887766  0.06112000   5.381 0.000000162 ***
## z.diff.lag2 -0.12845492  0.06432008  -1.997      0.0468 *  
## z.diff.lag3 -0.01064885  0.06462312  -0.165      0.8692    
## z.diff.lag4  0.05690285  0.06350714   0.896      0.3711    
## z.diff.lag5 -0.01668349  0.06151762  -0.271      0.7864    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02597 on 268 degrees of freedom
## Multiple R-squared:  0.1196, Adjusted R-squared:  0.09662 
## F-statistic: 5.202 on 7 and 268 DF,  p-value: 0.00001414
## 
## 
## Value of test-statistic is: -2.4972 2.5862 3.2058 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -3.98 -3.42 -3.13
## phi2  6.15  4.71  4.05
## phi3  8.34  6.30  5.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"drift"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.081102 -0.013688 -0.002598  0.011536  0.167963 
## 
## Coefficients:
##              Estimate Std. Error t value    Pr(>|t|)    
## (Intercept)  0.019078   0.015382   1.240      0.2160    
## z.lag.1     -0.006575   0.005837  -1.126      0.2610    
## z.diff.lag1  0.306455   0.060772   5.043 0.000000845 ***
## z.diff.lag2 -0.156749   0.063575  -2.466      0.0143 *  
## z.diff.lag3 -0.034594   0.064238  -0.539      0.5907    
## z.diff.lag4  0.038455   0.063463   0.606      0.5451    
## z.diff.lag5 -0.041998   0.060954  -0.689      0.4914    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02617 on 269 degrees of freedom
## Multiple R-squared:  0.1028, Adjusted R-squared:  0.08277 
## F-statistic: 5.136 on 6 and 269 DF,  p-value: 0.00005131
## 
## 
## Value of test-statistic is: -1.1265 1.2978 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.44 -2.87 -2.57
## phi1  6.47  4.61  3.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"none"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression none 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.080975 -0.014773 -0.002006  0.011681  0.165789 
## 
## Coefficients:
##               Estimate Std. Error t value    Pr(>|t|)    
## z.lag.1      0.0006247  0.0006081   1.027      0.3052    
## z.diff.lag1  0.3052416  0.0608250   5.018 0.000000947 ***
## z.diff.lag2 -0.1599301  0.0635869  -2.515      0.0125 *  
## z.diff.lag3 -0.0366726  0.0642802  -0.571      0.5688    
## z.diff.lag4  0.0367316  0.0635108   0.578      0.5635    
## z.diff.lag5 -0.0449750  0.0609677  -0.738      0.4613    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.0262 on 270 degrees of freedom
## Multiple R-squared:  0.1027, Adjusted R-squared:  0.08271 
## F-statistic: 5.148 on 6 and 270 DF,  p-value: 0.00004979
## 
## 
## Value of test-statistic is: 1.0273 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau1 -2.58 -1.95 -1.62
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# DIFERENCIAS: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.069846 -0.013941 -0.001969  0.011796  0.166553 
## 
## Coefficients:
##                Estimate  Std. Error t value         Pr(>|t|)    
## (Intercept)  0.00398042  0.00326372   1.220           0.2237    
## z.lag.1     -0.96600985  0.13032157  -7.413 0.00000000000164 ***
## tt          -0.00001242  0.00001981  -0.627           0.5310    
## z.diff.lag1  0.27428705  0.11800103   2.324           0.0209 *  
## z.diff.lag2  0.11502927  0.10628825   1.082           0.2801    
## z.diff.lag3  0.07837533  0.09095430   0.862           0.3896    
## z.diff.lag4  0.09775877  0.07423509   1.317           0.1890    
## z.diff.lag5  0.07280186  0.06082666   1.197           0.2324    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02605 on 267 degrees of freedom
## Multiple R-squared:  0.3901, Adjusted R-squared:  0.3741 
## F-statistic: 24.39 on 7 and 267 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -7.4125 18.3632 27.5402 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -3.98 -3.42 -3.13
## phi2  6.15  4.71  4.05
## phi3  8.34  6.30  5.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"drift"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.070858 -0.014250 -0.001793  0.011998  0.165361 
## 
## Coefficients:
##              Estimate Std. Error t value         Pr(>|t|)    
## (Intercept)  0.002197   0.001601   1.372           0.1711    
## z.lag.1     -0.963143   0.130094  -7.403 0.00000000000172 ***
## z.diff.lag1  0.272137   0.117818   2.310           0.0217 *  
## z.diff.lag2  0.113463   0.106139   1.069           0.2860    
## z.diff.lag3  0.077366   0.090837   0.852           0.3951    
## z.diff.lag4  0.097369   0.074148   1.313           0.1903    
## z.diff.lag5  0.072725   0.060758   1.197           0.2324    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02602 on 268 degrees of freedom
## Multiple R-squared:  0.3892, Adjusted R-squared:  0.3755 
## F-statistic: 28.46 on 6 and 268 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -7.4034 27.41 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.44 -2.87 -2.57
## phi1  6.47  4.61  3.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.df}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"none"}\NormalTok{, }\AttributeTok{lags =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression none 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.069424 -0.012002  0.000317  0.013820  0.167787 
## 
## Coefficients:
##             Estimate Std. Error t value         Pr(>|t|)    
## z.lag.1     -0.92780    0.12773  -7.264 0.00000000000407 ***
## z.diff.lag1  0.24302    0.11608   2.094           0.0372 *  
## z.diff.lag2  0.08889    0.10479   0.848           0.3970    
## z.diff.lag3  0.05875    0.08997   0.653           0.5143    
## z.diff.lag4  0.08492    0.07371   1.152           0.2503    
## z.diff.lag5  0.06500    0.06060   1.073           0.2844    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02607 on 269 degrees of freedom
## Multiple R-squared:  0.3849, Adjusted R-squared:  0.3712 
## F-statistic: 28.05 on 6 and 269 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic is: -7.2639 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau1 -2.58 -1.95 -1.62
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# PP: Phillips {-} Perron Test}

\DocumentationTok{\#\#\# NIVELES: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.pp}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"Z{-}tau"}\NormalTok{, }\AttributeTok{model =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{use.lag =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ################################## 
## # Phillips-Perron Unit Root Test # 
## ################################## 
## 
## Test regression with intercept and trend 
## 
## 
## Call:
## lm(formula = y ~ y.l1 + trend)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.083973 -0.015415 -0.002526  0.009332  0.170645 
## 
## Coefficients:
##               Estimate Std. Error t value            Pr(>|t|)    
## (Intercept) 0.10275012 0.04851421   2.118              0.0351 *  
## y.l1        0.96155565 0.01852595  51.903 <0.0000000000000002 ***
## trend       0.00011203 0.00006246   1.794              0.0740 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02705 on 278 degrees of freedom
## Multiple R-squared:  0.9903, Adjusted R-squared:  0.9902 
## F-statistic: 1.416e+04 on 2 and 278 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic, type: Z-tau  is: -2.5039 
## 
##            aux. Z statistics
## Z-tau-mu              1.1638
## Z-tau-beta            2.2617
## 
## Critical values for Z statistics: 
##                      1pct      5pct     10pct
## critical values -3.994127 -3.427199 -3.136601
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.pp}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"Z{-}tau"}\NormalTok{, }\AttributeTok{model =} \StringTok{"constant"}\NormalTok{, }\AttributeTok{use.lag =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ################################## 
## # Phillips-Perron Unit Root Test # 
## ################################## 
## 
## Test regression with intercept 
## 
## 
## Call:
## lm(formula = y ~ y.l1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.089442 -0.014571 -0.002497  0.009620  0.171964 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(>|t|)    
## (Intercept) 0.020316   0.015600   1.302               0.194    
## y.l1        0.993054   0.005925 167.617 <0.0000000000000002 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02716 on 279 degrees of freedom
## Multiple R-squared:  0.9902, Adjusted R-squared:  0.9901 
## F-statistic: 2.81e+04 on 1 and 279 DF,  p-value: < 0.00000000000000022
## 
## 
## Value of test-statistic, type: Z-tau  is: -1.2297 
## 
##          aux. Z statistics
## Z-tau-mu            1.3459
## 
## Critical values for Z statistics: 
##                      1pct     5pct     10pct
## critical values -3.455219 -2.87195 -2.572274
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# DIFERENCIAS: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.pp}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"Z{-}tau"}\NormalTok{, }\AttributeTok{model =} \StringTok{"trend"}\NormalTok{, }\AttributeTok{use.lag =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ################################## 
## # Phillips-Perron Unit Root Test # 
## ################################## 
## 
## Test regression with intercept and trend 
## 
## 
## Call:
## lm(formula = y ~ y.l1 + trend)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.09095 -0.01306 -0.00158  0.01055  0.17069 
## 
## Coefficients:
##                 Estimate   Std. Error t value   Pr(>|t|)    
## (Intercept)  0.001572438  0.001579672   0.995      0.320    
## y.l1         0.263626725  0.058071315   4.540 0.00000841 ***
## trend       -0.000009351  0.000019483  -0.480      0.632    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02634 on 277 degrees of freedom
## Multiple R-squared:  0.07036,    Adjusted R-squared:  0.06365 
## F-statistic: 10.48 on 2 and 277 DF,  p-value: 0.00004089
## 
## 
## Value of test-statistic, type: Z-tau  is: -12.3906 
## 
##            aux. Z statistics
## Z-tau-mu              1.2352
## Z-tau-beta           -0.4753
## 
## Critical values for Z statistics: 
##                      1pct      5pct     10pct
## critical values -3.994237 -3.427252 -3.136632
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.pp}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"Z{-}tau"}\NormalTok{, }\AttributeTok{model =} \StringTok{"constant"}\NormalTok{, }\AttributeTok{use.lag =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ################################## 
## # Phillips-Perron Unit Root Test # 
## ################################## 
## 
## Test regression with intercept 
## 
## 
## Call:
## lm(formula = y ~ y.l1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.090664 -0.013492 -0.001331  0.010702  0.169754 
## 
## Coefficients:
##             Estimate Std. Error t value   Pr(>|t|)    
## (Intercept) 0.001566   0.001577   0.993      0.322    
## y.l1        0.264342   0.057972   4.560 0.00000768 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02631 on 278 degrees of freedom
## Multiple R-squared:  0.06959,    Adjusted R-squared:  0.06624 
## F-statistic: 20.79 on 1 and 278 DF,  p-value: 0.000007682
## 
## 
## Value of test-statistic, type: Z-tau  is: -12.4037 
## 
##          aux. Z statistics
## Z-tau-mu             0.969
## 
## Critical values for Z statistics: 
##                      1pct      5pct     10pct
## critical values -3.455298 -2.871985 -2.572293
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# KPSS: }

\DocumentationTok{\#\#\# NIVELES: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.kpss}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"tau"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ####################### 
## # KPSS Unit Root Test # 
## ####################### 
## 
## Test is of type: tau with 5 lags. 
## 
## Value of test-statistic is: 0.3433 
## 
## Critical value for a significance level of: 
##                 10pct  5pct 2.5pct  1pct
## critical values 0.119 0.146  0.176 0.216
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.kpss}\NormalTok{(LDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"mu"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ####################### 
## # KPSS Unit Root Test # 
## ####################### 
## 
## Test is of type: mu with 5 lags. 
## 
## Value of test-statistic is: 4.429 
## 
## Critical value for a significance level of: 
##                 10pct  5pct 2.5pct  1pct
## critical values 0.347 0.463  0.574 0.739
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# DIFERENCIAS: Tipo de cambio}

\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.kpss}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"tau"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ####################### 
## # KPSS Unit Root Test # 
## ####################### 
## 
## Test is of type: tau with 5 lags. 
## 
## Value of test-statistic is: 0.0701 
## 
## Critical value for a significance level of: 
##                 10pct  5pct 2.5pct  1pct
## critical values 0.119 0.146  0.176 0.216
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{ur.kpss}\NormalTok{(DLDatos[, }\DecValTok{2}\NormalTok{], }\AttributeTok{type =} \StringTok{"mu"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ####################### 
## # KPSS Unit Root Test # 
## ####################### 
## 
## Test is of type: mu with 5 lags. 
## 
## Value of test-statistic is: 0.0801 
## 
## Critical value for a significance level of: 
##                 10pct  5pct 2.5pct  1pct
## critical values 0.347 0.463  0.574 0.739
\end{verbatim}

\hypertarget{cointegraciuxf3n}{%
\chapter{Cointegración}\label{cointegraciuxf3n}}

Hasta ahora en el curso hemos usado el supuesto de que las series son estacionarias para el conjunto de técnicas \(ARMA(p,q)\) y \(VAR(p)\). No obstante, dado que relajamos el supuesto de estacionariedad (incluyendo la estacionariedad en varianza) y que establecimos una serie de pruebas para determinar cuando una serie es estadísticamente estacionaria, ahora podemos plantear una técnica llamada Cointegración. Para esta técnica consideraremos sólo series que son \(I(1)\) y reconoceremos que se originó con los trabajos de Engle y Granger (1987), Stock (1987) y Johansen (1988).

\hypertarget{definiciuxf3n-y-propiedades-del-proceso-de-cointegraciuxf3n}{%
\section{Definición y propiedades del proceso de cointegración}\label{definiciuxf3n-y-propiedades-del-proceso-de-cointegraciuxf3n}}

Cointegración puede ser caracterizada o definida en palabras sencillas como que dos o más variables tienen una relación común estable en el largo plazo. Es decir, estas no suelen tomar caminos o trayectorias diferentes, excepto por periodos de tiempo transitorios y eventuales. A continuación, utilizaremos la definición de Engle y Grnager (1984) de cointegración.

Sea \(\mathbf{Y}\) un vector de k-series de tiempo, decimos que los elementos en \(\mathbf{Y}\) están cointegrados en un orden (d, c), es decir, \(\mathbf{Y} \sim CI(d, c)\), si todos los elementos de \(\mathbf{Y}\) son series integradas de orden d, I(d), y si existe al menos una combinación lineal no trivial \(\mathbf{Z}\) de esas variables que es de orden I(d - c), donde \(d \geq c > 0\), si y sólo si:
\begin{equation}
    \boldsymbol{\beta}_i' \mathbf{Y}_t = \mathbf{Y}_{it} \sim I(d-c)
\end{equation}

Donde \(i = 1, 2, \ldots, r\) y \(r < k\).

A los diferentes vectores \(\boldsymbol{\beta}_i\) se les denomina como vectores de cointegración. El rango de la matriz de vectores de cointegración \(r\) es el número de vectores de cointegración linealmente independientes. En general diremos que los vectores de la matriz de cointegración \(\boldsymbol{\beta}\) tendrá la forma de:
\begin{equation}
    \boldsymbol{\beta}' \mathbf{Y}_t = \mathbf{Z}_t
\end{equation}

Antes de continuar hagamos algunas observaciones. Si todas las variables de \(\mathbf{Y}\) son I(1) y \(0 \leq r < k\), diremos que las series no cointegran si \(r = 0\). Si esto pasa, entonces, como demostraremos más adelante, la mejor opción será estimar un modelo VAR(p) en diferencias. Adicionalmente, asumiremos que \(c = d = 1\), por lo que la relación de cointegración, en su caso, generará combinaciones lineales \(\mathbf{Z}\) estacionarias.

\hypertarget{cointegraciuxf3n-para-modelos-de-muxe1s-de-una-ecuaciuxf3n-o-para-modelos-basados-en-vectores-autoregresivos}{%
\section{Cointegración para modelos de más de una ecuación o para modelos basados en Vectores Autoregresivos}\label{cointegraciuxf3n-para-modelos-de-muxe1s-de-una-ecuaciuxf3n-o-para-modelos-basados-en-vectores-autoregresivos}}

Sean \(Y_1, Y_2, \ldots, Y_k\) son series que forman \(\mathbf{Y}\) y que todas son I(1), entonces los siguientes casos son posibles:
1. Si \(r = 1\) entonces se trata de un caso de cointegración de Granger.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Si \(r \geq 1\) entonces se trata de un caso de cointegración múltiple de Johansen.
\end{enumerate}

Por lo anterior, en este curso analizaremos el caso de Cointegración de Johansen. Ahora plantearemos la forma de estimar el proceso de cointegración. El primer paso para ello es determinar un modelo VAR(p) con las k-series no estacionarias (series en niveles). Alegimos el valor de \(p\) mediante el uso de los criterios de información. De esta forma tendremos una especificación similar a:
\begin{equation}
    \mathbf{Y}_t = \sum_{j=1}^p \mathbf{A}_j \mathbf{Y}_{t-j} + \mathbf{D}_t + \mathbf{U}_t
    \label{eq:VARCI}
\end{equation}

Donde \(\mathbf{U}_t\) es un término de error k-dimensional puramente aleatorio; \(\mathbf{D}_t\) contiene los compeoentes deterministicos de constante y tendencia, y \(\mathbf{A}_i\), \(i = 1, 2, \ldots, p\), son matrices de \(k \times k\) coeficientes. Notemos que el VAR(p) involucrado en este caso, a diferencia del VAR anteriormente estudiado, puede incluir un término de tendencia. Esto en razón de que hemos relajado el concepto de estacionariedad.

Si reescribimos la ecuación \eqref{eq:VARCI} en su forma de Vector Corrector de Errores (VEC, por sus siglas en inglés) tenemos:
\begin{eqnarray}
    \mathbf{Y}_t - \mathbf{Y}_{t-1} & = & \Delta \mathbf{Y}_t \nonumber \\
    & = & \sum_{j=1}^p \mathbf{A}_j \mathbf{Y}_{t-j} + \mathbf{D}_t - \mathbf{Y}_{t-1} + \mathbf{U}_t \nonumber \\
    & = & (\mathbf{A}_1 - \mathbf{I}) \mathbf{Y}_{t-1} + \mathbf{A}_2 \mathbf{Y}_{t-2} + \ldots + \mathbf{A}_p \mathbf{Y}_{t-p} + \mathbf{D}_t + \mathbf{U}_t \nonumber \\
    & = & \left( \sum_{j=1}^{p} \mathbf{A}_j - \mathbf{I} \right) \mathbf{Y}_{t-1} + \sum_{j=1}^{p-1} \mathbf{A}^*_j \Delta \mathbf{Y}_{t-j} + \mathbf{D}_t \mathbf{U}_t \nonumber \\
    & = & - \left( \mathbf{I} - \sum_{j=1}^{p} \mathbf{A}_j \right) \mathbf{Y}_{t-1} + \sum_{j=1}^{p-1} \mathbf{A}^*_j \Delta \mathbf{Y}_{t-j} + \mathbf{D}_t \mathbf{U}_t \nonumber \\
    \Delta \mathbf{Y}_t & = & - \Pi \mathbf{Y}_{t-1} + \sum_{j=1}^{p-1} \mathbf{A}^*_j \Delta \mathbf{Y}_{t-j} + \mathbf{D}_t + \mathbf{U}_t
    \label{eq:VARVEC}
\end{eqnarray}

Donde \(\mathbf{A}_j^* = - \sum_{i=j+1}^p \mathbf{A}_i\), \(i = 1, 2, \ldots, p-1\), y la matriz \(\Pi\) representa todas las relaciones de largo plazo entre las variables, por lo que la matriz es de rango completo \(k \times k\). Por lo tanto, tenemos que dicha matriz en la ecuación \eqref{eq:VARVEC} se puede factorizar como:
\begin{equation}
    \Pi_{(k \times k)} = \Gamma_{(k \times r)} \boldsymbol{\beta}_{(r \times k)}'
    \label{Pi_Matrix}
\end{equation}

Donde \(\boldsymbol{\beta}_{(r \times k)}' \mathbf{Y}_{t-1}\) son \(r\) combinaciones linealmente independientes que son estacionarias.

Dada la ecuación \eqref{eq:VARVEC} podemos establecer la aproximación de Johansen (1988) que se realiza mediante una estimación por Máxima Verosimilitud de la ecuación:
\begin{equation}
    \Delta \mathbf{Y}_t + \Gamma \boldsymbol{\beta}' \mathbf{Y}_{t-1} = \sum_{j=1}^{p-1} \mathbf{A}^*_j \Delta \mathbf{Y}_{t-j} + \mathbf{D}_t + \mathbf{U}_t
\end{equation}

Donde una vez estimado el sistema:
\begin{equation}
    \boldsymbol{\beta} = [v_1, v_2, \ldots, v_r]
\end{equation}

Cada \(v_i\), \(i = 1, 2, \ldots, r\), es un vector propio que asociado a los \(r\) valores propios positivos, mismos que estás asociados con la prueba de hipótesis de cointegración. Dicha hipótesis está basada en dos estadísticas con las que se determina el rango \(r\) de \(\Pi\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Prueba de Traza:
  \(H_0 :\) Existen al menos \(r\) valores propios positivos o Existen al menos \(r\) relaciones de largo plazo estacionarias.
\item
  Prueba del valor propio máximo o \(\lambda_{max}\):
  \(H_0 :\) Existen \(r\) valores propios positivos o Existen \(r\) relaciones de largo plazo estacionarias.
\end{enumerate}

\hypertarget{ejemplo-de-cointegraciuxf3n}{%
\section{Ejemplo de cointegración}\label{ejemplo-de-cointegraciuxf3n}}

Para ejemplificar el procedimiento de cointegración utilizaremos las series de INPC, Tipo de Cambio, rendimiento de los Cetes a 28 días, IGAE e Índice de Producción Industrial de Estados Unidos. Quizá el marco teórico de la relación entre las variables no sea del todo correcta, pero dejando de lado ese problema estimaremos si las 5 series cointegran.

En el Scrip Clase 17 y Clase 18 del GitHub se encuentra el desarrollo de este ejemplo. Por principio, probaremos que todas las series son I(1), lo cual es cierto (ver Scrip para mayores detalles). En las Figuras \ref{fig:fig81}, \ref{fig:fig82} y \ref{fig:fig83} se muestran las series en niveles y en diferencias, con lo cual ilustramos como es viable que las series sean I(1).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(strucchange)}
\FunctionTok{library}\NormalTok{(zoo)}
\FunctionTok{library}\NormalTok{(sandwich)}
\FunctionTok{library}\NormalTok{(urca)}
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{library}\NormalTok{(vars)}

\CommentTok{\#}
\FunctionTok{load}\NormalTok{(}\StringTok{"BD/Datos\_Ad.RData"}\NormalTok{)}

\CommentTok{\#}
\DocumentationTok{\#\# Conversion a series de tiempo:}
\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(Datos\_Ad[}\DecValTok{7}\SpecialCharTok{:} \DecValTok{11}\NormalTok{], }
            \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
            \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{LDatos }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(Datos)}

\NormalTok{DLDatos }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(}\FunctionTok{log}\NormalTok{(Datos, }\AttributeTok{base =} \FunctionTok{exp}\NormalTok{(}\DecValTok{1}\NormalTok{)), }
                \AttributeTok{lag =} \DecValTok{1}\NormalTok{, }
                \AttributeTok{differences =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(LDatos, }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \CommentTok{\#main = "Series en Logaritmos", }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig81-1} 

}

\caption{Series en niveles (logatirmos) para la prueba de Cointegración}\label{fig:fig81}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(DLDatos, }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \CommentTok{\#main = "Series en Diferencias Logaritmicas", }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig82-1} 

}

\caption{Series en Diferencias Logaritmicas para la prueba de Cointegración}\label{fig:fig82}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(LDatos, DLDatos), }
     \AttributeTok{plot.type =} \StringTok{"m"}\NormalTok{, }\AttributeTok{nc =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"darkgreen"}\NormalTok{, }\StringTok{"darkblue"}\NormalTok{, }\StringTok{"darkred"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"purple"}\NormalTok{), }
     \CommentTok{\#main = "Comparacion de Series en Diferencias", }
     \AttributeTok{xlab =} \StringTok{"Tiempo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig83-1} 

}

\caption{Comparacion de Series en Diferencias para la prueba de Cointegración}\label{fig:fig83}
\end{figure}

Posteriormente, determinamos cuál es el orden adecuado de un VAR(p) en niveles. En el Cuadro \ref{tab:SelectVARVEC} mostramos los resultados de los criterios de información para determinar el número de rezagos óptimos, el cual resultó en \(p = 3\) para los criterios AIC y FPE, \(p = 2\) para el criterio HQ y \(p = 1\) para el citerio SC. Por lo tanto decidiremos utilizar un VAR(3) con tendencia y constante. Notese que es posible elegir otros modelos de VAR que incluyan: solo tendencia, solo constante o ninguno de estos elementos.

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:SelectVARVEC} Criterios de información para diferentes especificaciones de modelos VAR(p) con término constante y tendencia de las series \(LINPC_t\), \(LTC_t\), \(LCETE28_t\), \(LIGAE_t\) y \(LIPI_t\).}\tabularnewline
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rezagos & AIC & HQ & SC & FPE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & -4.606707e+01 & -4.585260e+01 & -4.553568e+01 & 9.848467e-21 \\
2 & -4.643287e+01 & -4.606521e+01 & -4.552191e+01 & 6.834064e-21 \\
3 & -4.647783e+01 & -4.595697e+01 & -4.518730e+01 & 6.539757e-21 \\
4 & -4.645834e+01 & -4.578428e+01 & -4.478824e+01 & 6.679778e-21 \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
\end{longtable}

El mismo número de rezagos los utilizaremos para probar la Cointegración ya sea por una estadística de la Traza o por una de el máximo valor propio. Derivado de la exploración de los resultados sólo mostraremos uno de los caso en que las series cointegran y sólo para el caso de la prueba de la traza (el otro caso está disponible en el código incluido en GitHub). En el Cuadro \ref{tab:TrazaTest} reportamos los resultados del Test de Cointegración para un modelo con 3 rezagos.

Cuadro: \label{tab:TrazaTest} Prueba de la traza para cointegración considerando un VAR(p) con término constante y tendencia de las series \(LINPC_t\), \(LTC_t\), \(LCETE28_t\), \(LIGAE_t\) y \(LIPI_t\).

\begin{longtable}[]{@{}ccccc@{}}
\toprule\noalign{}
r \(\leq\) & Estadística & 10\% & 5\% & 1\% \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4 & 3.38 & 10.49 & 12.25 & 16.26 \\
3 & 17.09 & 22.76 & 25.32 & 30.45 \\
2 & 31.66 & 39.06 & 42.44 & 48.45 \\
1 & 56.88 & 59.14 & 62.99 & 70.05 \\
0 & 89.69 & 83.20 & 87.31 & 96.58 \\
\end{longtable}

Los resutados del Cuadro \ref{tab:TrazaTest} indican que aceptamos la hipótesis nula para el caso de \(r \leq 1\) al \(5\%\), por lo que podemos concluir que existe evidencia estadística para probar que existen al menos 1 vector de cointegración. Por lo que dicho vector es:
\begin{equation}
    \boldsymbol{\beta} = \left[ 
    \begin{matrix}
    1.00000000 \\
    0.151162436 \\
    -0.042650912 \\
    0.163804862 \\
    0.229295743 \\
    -0.004350646 \\
    \end{matrix} \right]
\end{equation}

Donde el vector esta normalizado para la serie \(LINPC_t\), por lo que concluímos que la relación de largo plazo que encontramos cointegra estará dada por:
\begin{eqnarray*}
    LINPC_t & = & -0.151162436 LTC_t + 0.042650912 LCETE28_t \\
    &  & - 0.163804862 LIGAE_t - 0.229295743 LIPI_t \\
    &  & + 0.004350646 t
\end{eqnarray*}

Considerando lo anterior, podemos determinar \(\hat{U}_t\) para esta ecuación de cointegración. En la Figura \ref{fig:fig84} mostramos los residuales estimados. Derivado de la impección visual parecería que estos no son estacionarios, condición que debería ser cierta. De esta forma, una prueba deseable es aplicar todas la pruebas de raíces unitarias a esta serie para mostrar que es I(0). En el Scrip llamado Clase 18 en la carpeta de GoogleDrive se muestran algunas pruebas sobre esta serie y se encuentra que es posible que no sea estacionaria.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TT }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{282}\NormalTok{), }
         \AttributeTok{start =} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1}\NormalTok{), }
         \AttributeTok{freq =} \DecValTok{12}\NormalTok{)}

\NormalTok{U }\OtherTok{\textless{}{-}}\NormalTok{ LDatos[ , }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+} \FloatTok{0.2100057} \SpecialCharTok{*}\NormalTok{LDatos[ , }\DecValTok{2}\NormalTok{] }\SpecialCharTok{+} \FloatTok{0.4812626}\SpecialCharTok{*}\NormalTok{LDatos[ , }\DecValTok{3}\NormalTok{] }\SpecialCharTok{{-}} \FloatTok{2.8386112}\SpecialCharTok{*}\NormalTok{LDatos[ , }\DecValTok{4}\NormalTok{] }\SpecialCharTok{{-}} \FloatTok{1.2576912}\SpecialCharTok{*}\NormalTok{LDatos[ , }\DecValTok{5}\NormalTok{] }\SpecialCharTok{+} \FloatTok{14.2887887}

\CommentTok{\#}

\FunctionTok{plot}\NormalTok{(U, }
     \AttributeTok{main =} \StringTok{"Residuales de la Ecuación de Cointegración"}\NormalTok{,}
     \AttributeTok{type =} \StringTok{"l"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"darkred"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{Notas-Series-Tiempo_files/figure-latex/fig84-1} 

}

\caption{Residuales estimados de la ecuación de cointegración}\label{fig:fig84}
\end{figure}

\hypertarget{modelos-adrl}{%
\chapter{Modelos ADRL}\label{modelos-adrl}}

\hypertarget{teoruxeda}{%
\section{Teoría}\label{teoruxeda}}

Una vez que hemos analizado diversas técnicas de series de tiempo, el problema consiste en seleccionar el modelo correcto. La Figura \ref{fig:fig91} muestra un esquema o diagrama de cómo podríamos proceder para seleccionar el modelo correcto.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"Plots/TimeSeries\_Models.png"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Plots/TimeSeries_Models} 

}

\caption{Method selection for time series data. OLS: Ordinary least squares; VAR: Vector autoregressive; ARDL: Autoregressive distributed lags; ECM: Error correction models, retomado de: Shrestha y Bhatta (2018)}\label{fig:fig91}
\end{figure}

En este caso incorporaremos a los modelos autogregressive distributed lag models (ARDL, por sus siglas en inglés). En estos casos el procedimiento de Johansen no podría aplicarse directamennte cuando las variables incluidas son de un orden mixto o cuando simplemente todas no son estacionarias. Un modelo ARDL está basado en procedimientos de MCO.

Este tipo de modelos toma suficientes rezagos para capturar el mecanismo generador de datos. También es posible llegar a una especificación del mecanismo corrector de errores a partir de una trasformación lineal del ARDL.

Consideremos la siguiente ecuación:
\begin{equation}
    Y_t = \alpha + \delta X_t + \gamma Z_t + U_t
    \label{eq:EqARDL}
\end{equation}

Dada la ecuación \eqref{eq:EqARDL} podemos establecer su forma de mecanismo corrector de errores en forma ARDL dada por:
\begin{eqnarray*}
    \Delta Y_t & = & \alpha + \sum_{i = 1}^p \beta_i \Delta Y_{t-i} + \sum_{i = 1}^p \delta_i \Delta X_{t-i} + \sum_{i = 1}^p \gamma_i \Delta Z_{t-i} \\ 
    &  & + \lambda_1 Y_{t-1} + \lambda_2 X_{t-1} + \lambda_3 Z_{t-1} + U_t
\end{eqnarray*}

Donde los coeficientes \(\beta_i\), \(\delta_i\), \(\gamma_i\) representan la dinámica de corto plazo y las \(\lambda\)'s la dinámica de largo plazo.

La hipótesis nula (\(H_0\)) es que las \(\lambda_1 + \lambda_2 + \lambda_3 = 0\), es decir, que no existe relación de largo plazo.

En la práctica estimamos una especificación con rezafos distribuidos:
\begin{equation}
    Y_t = \alpha + \sum_{i = 1}^p \beta_i Y_{t-i} + \sum_{i = 1}^p \delta_i X_{t-i} + \sum_{i = 1}^p \gamma_i Z_{t-i} + U_t
\end{equation}

Además de verificar si las series involucradas son estacionarias y decidir el número de reagos \(p\) mediante criterios de información.

\hypertarget{ejemplo}{%
\section{Ejemplo}\label{ejemplo}}

\hypertarget{descripciuxf3n-del-problema}{%
\subsection{DESCRIPCIÓN DEL PROBLEMA}\label{descripciuxf3n-del-problema}}

Supongamos que queremos modelar el logaritmo de dinero (M2) como una función de LRY (logarithm of real income), IBO (bond rate) e IDE (bank deposit rate).

\begin{itemize}
\item
  El problema es que la aplicación de una regresión de MCO en datos no estacionarios daría lugar a una regresión espúria.
\item
  Los parámetros estimados serían consistentes solo si las series estuvieran cointegradas.
\end{itemize}

\hypertarget{importamos-datos-desde-un-dataset-de-r}{%
\subsection{Importamos Datos desde un dataset de R:}\label{importamos-datos-desde-un-dataset-de-r}}

A data frame with 55 rows and 5 variables. Time period from 1974:Q1 until 1987:Q3.

LRM: logarithm of real money, M2

LRY: logarithm of real income

LPY: logarithm of price deflator

IBO: bond rate

IDE: bank deposit rate

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(zoo) }
\FunctionTok{library}\NormalTok{(xts) }
\FunctionTok{library}\NormalTok{(ARDL)}

\CommentTok{\#}
\FunctionTok{data}\NormalTok{(denmark)}

\FunctionTok{names}\NormalTok{(denmark)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "LRM" "LRY" "LPY" "IBO" "IDE"
\end{verbatim}

\hypertarget{procedimiento}{%
\subsection{Procedimiento:}\label{procedimiento}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculamos un auto ADRL para determinar la combinación óptima de rezagos.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{auto\_ardl}\NormalTok{(LRM }\SpecialCharTok{\textasciitilde{}}\NormalTok{ LRY }\SpecialCharTok{+}\NormalTok{ IBO }\SpecialCharTok{+}\NormalTok{ IDE, }\AttributeTok{data =}\NormalTok{ denmark, }\AttributeTok{max\_order =} \DecValTok{5}\NormalTok{)}

\FunctionTok{names}\NormalTok{(models)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "best_model" "best_order" "top_orders"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\NormalTok{models}\SpecialCharTok{$}\NormalTok{top\_orders}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    LRM LRY IBO IDE       AIC
## 1    3   1   3   2 -251.0259
## 2    3   1   3   3 -250.1144
## 3    2   2   0   0 -249.6266
## 4    3   2   3   2 -249.1087
## 5    3   2   3   3 -248.1858
## 6    2   2   0   1 -247.7786
## 7    2   1   0   0 -247.5643
## 8    2   2   1   1 -246.6885
## 9    3   3   3   3 -246.3061
## 10   2   2   1   2 -246.2709
## 11   2   1   1   1 -245.8736
## 12   2   2   2   2 -245.7722
## 13   1   1   0   0 -245.6620
## 14   2   1   2   2 -245.1712
## 15   3   1   2   2 -245.0996
## 16   1   0   0   0 -244.4317
## 17   1   1   0   1 -243.7702
## 18   5   5   5   5 -243.3120
## 19   4   1   3   2 -243.0728
## 20   4   1   3   3 -242.4378
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\NormalTok{models}\SpecialCharTok{$}\NormalTok{best\_order}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## LRM LRY IBO IDE 
##   3   1   3   2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\NormalTok{models}\SpecialCharTok{$}\NormalTok{best\_model}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Time series regression with "zooreg" data:
## Start = 1974 Q4, End = 1987 Q3
## 
## Call:
## dynlm::dynlm(formula = full_formula, data = data, start = start, 
##     end = end)
## 
## Coefficients:
## (Intercept)    L(LRM, 1)    L(LRM, 2)    L(LRM, 3)          LRY    L(LRY, 1)  
##      2.6202       0.3192       0.5326      -0.2687       0.6728      -0.2574  
##         IBO    L(IBO, 1)    L(IBO, 2)    L(IBO, 3)          IDE    L(IDE, 1)  
##     -1.0785      -0.1062       0.2877      -0.9947       0.1255      -0.3280  
##   L(IDE, 2)  
##      1.4079
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\NormalTok{BestMod }\OtherTok{\textless{}{-}}\NormalTok{ models}\SpecialCharTok{$}\NormalTok{best\_model}

\FunctionTok{summary}\NormalTok{(BestMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Time series regression with "zooreg" data:
## Start = 1974 Q4, End = 1987 Q3
## 
## Call:
## dynlm::dynlm(formula = full_formula, data = data, start = start, 
##     end = end)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.029939 -0.008856 -0.002562  0.008190  0.072577 
## 
## Coefficients:
##             Estimate Std. Error t value   Pr(>|t|)    
## (Intercept)   2.6202     0.5678   4.615 0.00004187 ***
## L(LRM, 1)     0.3192     0.1367   2.336   0.024735 *  
## L(LRM, 2)     0.5326     0.1324   4.024   0.000255 ***
## L(LRM, 3)    -0.2687     0.1021  -2.631   0.012143 *  
## LRY           0.6728     0.1312   5.129 0.00000832 ***
## L(LRY, 1)    -0.2574     0.1472  -1.749   0.088146 .  
## IBO          -1.0785     0.3217  -3.353   0.001790 ** 
## L(IBO, 1)    -0.1062     0.5858  -0.181   0.857081    
## L(IBO, 2)     0.2877     0.5691   0.505   0.616067    
## L(IBO, 3)    -0.9947     0.3925  -2.534   0.015401 *  
## IDE           0.1255     0.5545   0.226   0.822161    
## L(IDE, 1)    -0.3280     0.7213  -0.455   0.651847    
## L(IDE, 2)     1.4079     0.5520   2.550   0.014803 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.0191 on 39 degrees of freedom
## Multiple R-squared:  0.988,  Adjusted R-squared:  0.9843 
## F-statistic: 266.8 on 12 and 39 DF,  p-value: < 0.00000000000000022
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  UECM (Unrestricted Error Correction Model) of the underlying ARDL.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{UECM\_BestMod }\OtherTok{\textless{}{-}} \FunctionTok{uecm}\NormalTok{(BestMod)}

\FunctionTok{summary}\NormalTok{(UECM\_BestMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Time series regression with "zooreg" data:
## Start = 1974 Q4, End = 1987 Q3
## 
## Call:
## dynlm::dynlm(formula = full_formula, data = data, start = start, 
##     end = end)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.029939 -0.008856 -0.002562  0.008190  0.072577 
## 
## Coefficients:
##              Estimate Std. Error t value   Pr(>|t|)    
## (Intercept)   2.62019    0.56777   4.615 0.00004187 ***
## L(LRM, 1)    -0.41685    0.09166  -4.548 0.00005154 ***
## L(LRY, 1)     0.41538    0.11761   3.532    0.00108 ** 
## L(IBO, 1)    -1.89172    0.39111  -4.837 0.00002093 ***
## L(IDE, 1)     1.20534    0.44690   2.697    0.01028 *  
## d(L(LRM, 1)) -0.26394    0.10192  -2.590    0.01343 *  
## d(L(LRM, 2))  0.26867    0.10213   2.631    0.01214 *  
## d(LRY)        0.67280    0.13116   5.129 0.00000832 ***
## d(IBO)       -1.07852    0.32170  -3.353    0.00179 ** 
## d(L(IBO, 1))  0.70701    0.46874   1.508    0.13953    
## d(L(IBO, 2))  0.99468    0.39251   2.534    0.01540 *  
## d(IDE)        0.12546    0.55445   0.226    0.82216    
## d(L(IDE, 1)) -1.40786    0.55204  -2.550    0.01480 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.0191 on 39 degrees of freedom
## Multiple R-squared:  0.7458, Adjusted R-squared:  0.6676 
## F-statistic: 9.537 on 12 and 39 DF,  p-value: 0.00000003001
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  RECM (Restricted Error Correction Model) of the underlying ARDL
  Obs: allowing the constant to join the short-run relationship (case 2), instead of the long-run (case 3)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RECM\_BestMod }\OtherTok{\textless{}{-}} \FunctionTok{recm}\NormalTok{(UECM\_BestMod, }\AttributeTok{case =} \DecValTok{2}\NormalTok{)}

\FunctionTok{summary}\NormalTok{(RECM\_BestMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Time series regression with "zooreg" data:
## Start = 1974 Q4, End = 1987 Q3
## 
## Call:
## dynlm::dynlm(formula = full_formula, data = data, start = start, 
##     end = end)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.029939 -0.008856 -0.002562  0.008190  0.072577 
## 
## Coefficients:
##              Estimate Std. Error t value    Pr(>|t|)    
## d(L(LRM, 1)) -0.26394    0.09008  -2.930    0.005405 ** 
## d(L(LRM, 2))  0.26867    0.09127   2.944    0.005214 ** 
## d(LRY)        0.67280    0.11591   5.805 0.000000703 ***
## d(IBO)       -1.07852    0.30025  -3.592    0.000837 ***
## d(L(IBO, 1))  0.70701    0.44359   1.594    0.118300    
## d(L(IBO, 2))  0.99468    0.36491   2.726    0.009242 ** 
## d(IDE)        0.12546    0.48290   0.260    0.796248    
## d(L(IDE, 1)) -1.40786    0.48867  -2.881    0.006160 ** 
## ect          -0.41685    0.07849  -5.311 0.000003633 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.01819 on 43 degrees of freedom
##   (0 observations deleted due to missingness)
## Multiple R-squared:  0.7613, Adjusted R-squared:  0.7113 
## F-statistic: 15.24 on 9 and 43 DF,  p-value: 0.00000000009545
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  long-run levels relationship (cointegration)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bounds\_f\_test}\NormalTok{(BestMod, }\AttributeTok{case =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Bounds F-test (Wald) for no cointegration
## 
## data:  d(LRM) ~ L(LRM, 1) + L(LRY, 1) + L(IBO, 1) + L(IDE, 1) + d(L(LRM,     1)) + d(L(LRM, 2)) + d(LRY) + d(IBO) + d(L(IBO, 1)) + d(L(IBO,     2)) + d(IDE) + d(L(IDE, 1))
## F = 5.1168, p-value = 0.004418
## alternative hypothesis: Possible cointegration
## null values:
##    k    T 
##    3 1000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Long-run multipliers (with standard errors, t-statistics and p-values)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{multipliers}\NormalTok{(BestMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          Term   Estimate Std. Error   t value           Pr(>|t|)
## 1 (Intercept)  6.2856579  0.7719160  8.142930 0.0000000006107445
## 2         LRY  0.9964676  0.1239310  8.040503 0.0000000008358472
## 3         IBO -4.5381160  0.5202961 -8.722180 0.0000000001058619
## 4         IDE  2.8915201  0.9950853  2.905801 0.0060092393605960
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#}
\NormalTok{Result }\OtherTok{\textless{}{-}} \FunctionTok{coint\_eq}\NormalTok{(BestMod, }\AttributeTok{case =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{make-the-plot}{%
\subsection{Make the plot}\label{make-the-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{cbind.zoo}\NormalTok{(}\AttributeTok{LRM =}\NormalTok{ denmark[,}\StringTok{"LRM"}\NormalTok{], Result)}

\NormalTok{Datos }\OtherTok{\textless{}{-}} \FunctionTok{xts}\NormalTok{(Datos)}

\FunctionTok{plot}\NormalTok{(Datos, }\AttributeTok{legend.loc =} \StringTok{"right"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{Notas-Series-Tiempo_files/figure-latex/fig92-1} 

}

\caption{Gráfica de la ecuación de cointegración}\label{fig:fig92}
\end{figure}

  \bibliography{book.bib,packages.bib}

\end{document}
