# Modelos Univariados y Multivariados de Volatilidad

## Motivación

En este capítulo discutiremos los modelos de Heterocedasticidad Condicional Autoregresiva (ARCH, por sus siglas en inglés) y modelos de Heterocedasticidad Condicional Autoregresiva Generalizados (GARCH, por sus siglas en inglés) tienen la característica de modelar situaciones como las que ilustra la Figura \@ref(fig:fig102). Es decir: 

1) Existen zonas donde la variación de los datos es mayor y zonas donde la variación es más estable--a estas situaciones se les conoce como de variabilidad por clúster--, y 

2) los datos corresponden a innformación de alta frecuencia.

Iniciemos por las bibliotecas necesarias:

```{r SetUp_ARCH, warning=FALSE, message=FALSE}

library(expm)
library(Matrix)
library(ggplot2)
library(quantmod)
library(moments)
library(dynlm)
library(broom)
library(FinTS)
library(lubridate)
library(forecast)
library(readxl)
library(MASS)
library(rugarch)
library(tsbox)
library(MTS)
library(rmgarch)
library(Rcpp)

```

Para el análisis de temas financieros existe una librería de mucha utilidad llamada __quantmod__. En primer lugar esta librería permite acceder a datos financieros de un modo muy simple, es posible decargar series financieras desde _yahoo_, la _FRED (Federal Reserve Economic Data)_, _google_, etc. Por otro lado, también es una librería que permite realizar gráficos altamente estéticos con unas cuantas líneas de código. Ahora, usaremos datos de Yahoo Finance respecto de la cotización del bitcoin (ticker: "BTC-USD"). 
```{r Data_ARCH, warning=FALSE, message=FALSE}

options("getSymbols.warning4.0"=FALSE)

BTC <-getSymbols("BTC-USD", src = "yahoo", auto.assign = FALSE)

BTC <- na.omit(BTC)

chartSeries(BTC,TA='addBBands();
                    addBBands(draw="p");
                    addVo();
                    addMACD()',# subset='2021',
                theme="white")

head(BTC)

tail(BTC)

```

Para fines del ejercicio de esta clase, usaremos el valor de la acción ajustado. Esto nos servirá para calcular el rendimiento diario, o puesto en lenguaje de series temporales podemos decir que usaremos la serie en diferencias logarítmicas. 

```{r fig101, fig.cap = "Evolución del precio del Bitcoin", fig.align='center'}

plot(BTC$`BTC-USD.Adjusted`)

```
Una de las preguntas relevantes al observar la serie en diferencias, es si podríamos afirmar que esta serie cumple con el supuesto de homoscedasticidad. Para ello, la Figura \@ref(fig:fig102) muestra que las variaciones en el precio del Bitcoin muestran un escenario en el que no se cumple el supuesto de la homocedasticidad.

```{r fig102, fig.cap = "Evolución del rendimiento (diferenccias logarítmicas) del Bitcoin", fig.align='center'}

logret <- ts(diff(log(BTC$`BTC-USD.Adjusted`))[-1])

plot(logret)

```
### Value at Risk (VaR)

Utilicemos como ejemplo el Valor en Riesgo. Este es básicamente es un cálculo que nos permite estimar el monto que una acción o portafolio podría perder dada una probabilidad $(1-\alpha)$. Supongamos un $\alpha = 0.05$, de esta forma, la Figura \@ref(fig:fig103) ilustra la región de la distribución que consideraríamos como el VaR.

```{r VaR, message=FALSE, warning=FALSE}

alpha <- 0.05

VaR <- quantile( logret, alpha )

round( VaR, 4 )*100

```

```{r fig103, fig.cap = "Histograma de rendimientos del Bitcoin", fig.align='center', message=FALSE, warning=FALSE}

qplot(logret , geom = 'histogram') + 
  geom_histogram(fill = 'lightblue' , bins = 30) +
  geom_histogram( aes(logret[logret < quantile(logret , 0.05)]) , 
                  fill = 'red' , bins = 30) +
  labs(x = 'Daily Returns')

```

Ahora bien, una de las preguntas que nos podemos hacer es si los rendimientos del Bitcoin se aproximan a una distribución normal. Para ello, la Figura \@ref(fig:fig104) ilustra esta comparación, de la cual podemos observar que una prueba de normalidad rechaza esa hipótesis--el estadístico Jarque-Bera indica que la serie de rendimientos no tiene una distribución normal--.

```{r fig104, fig.cap = "Densidad de rendimientos del Bitcoin Vs. una distribución normal", fig.align='center', message=FALSE, warning=FALSE}

normal_dist <- rnorm(100000, mean(logret), sd(logret))
VaR_n <- quantile(normal_dist, 0.05)
ES_n <- mean(normal_dist[normal_dist<VaR])
  
ggplot()+
  geom_density(aes(logret, geom ='density', col = 'returns'))+
  geom_density(aes(normal_dist, col = 'normal'))

```


```{r DescStatARCH, warning=FALSE}

vector_ret <- as.vector(logret)

##Kurtosis
round(kurtosis(vector_ret),2)
##Sesgo
round(skewness(vector_ret),2)

```

## Prueba de normalidad 

$H_o: K=S=0$

```{r JB_ARCH}

jarque.test(vector_ret)

```

## Modelos ARCH y GARCH Univariados

Para plantear el modelo, supongamos--por simplicidad--que hemos construido y estimado un modelo AR(1). Es decir, asumamos que el proceso subyacente para la media condicional está dada por:
\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + U_t
\end{equation}

Donde $| a_1 |< 1$ para garantizar la convergencia del proceso en el largo plazo, en el cual:
\begin{eqnarray*}
    \mathbb{E}[X_t] & = & \frac{a_0 }{1 - a_1} = \mu \\
    Var[X_t] & = & \frac{\sigma^2}{1 - a_1^2}
\end{eqnarray*}

Ahora, supongamos que este tipo de modelos pueden ser extendidos y generalizados a un modelo ARMA(p, q), que incluya otras variables exógenas. Denotemos a $\mathbf{Z}_t$ como el conjunto que incluye los componentes AR, MA y variables exógenas que pueden explicar a $X_t$ de forma que el proceso estará dado por:
\begin{equation}
    X_t = \mathbf{Z}_t \boldsymbol{\beta} + U_t
\end{equation}

Donde $U_t$ es un proceso estacionario que representa el error asociado a un proceso ARMA(p, q) y donde siguen diendo válidos los supuestos:
\begin{eqnarray*}
    \mathbb{E}[U_t] & = & 0 \\
    Var[U_t^2] & = & \sigma^2
\end{eqnarray*}

No obstante, en este caso podemos suponer que existe autocorrelación en el término de error al cuadrado que puede ser capturada por un proceso similar a uno de medias móviles (MA) dado por:
\begin{equation}
    U_t^2 = \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2 + \nu_t
\end{equation}

Donde $\nu_t$ es un ruido blanco y $U_{t-i} = X_{t-i} - \mathbf{Z}_{t-i} \boldsymbol{\beta}$, $i = 1, 2 ,\ldots $. Si bien los procesos son estacionarios por los supuestos antes enunciados, la varianza condicional estará dada por:
\begin{eqnarray*}
    \sigma^2_{t | t-1} & = & Var[ U_t | \Omega_{t-1} ] \\
    & = & \mathbb{E}[ U^2_t | \Omega_{t-1} ]
\end{eqnarray*}

Donde $\Omega_{t-1} = \{U_{t-1}, U_{t-2}, \ldots \}$ es el conjunto de toda la información pasada de $U_t$ y observada hasta el momento $t-1$, por lo que:
\begin{equation*}
    U_t | \Omega_{t-1} \sim \mathbb{D}(0, \sigma^2_{t | t-1})
\end{equation*}

Así, de forma similar a un proceso MA(q) podemos decir que la varianza condicional tendrá efectos ARCH de orden $q$ (ARCH(q)) cuando:
\begin{equation}
    \sigma^2_{t | t-1} = \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2
    (\#eq:ARCHEffect)
\end{equation}

Donde $\mathbb{E}[\nu_t] = 0$ y $\gamma_0$ y $\gamma_i \geq 0$, para $i = 1, 2, \ldots, q-1$ y  $\gamma_q > 0$. Estas condiciones son necesarias para garantizar que la varianza sea positiva. En general, la varianza condicional se expresa de la forma $\sigma^2_{t | t-1}$, no obstante, para facilitar la notación, nos referiremos en cada caso a esta simplemente como $\sigma^2_{t}$.

Podemos generalizar esta situación si asumimos a la varianza condicional como dependiente de los valores de la varianza rezagados, es decir, como si fuera un proceso AR de orden $p$ para la varianza y juntándolo con la ecuación \@ref(eq:ARCHEffect). Bollerslev (1986) y Taylor (1986) generalizaron el problema de heterocedasticidad condicional. El modelo se conoce como GARCH(p, q), el cual se especifica como:
\begin{eqnarray}
    \sigma^2_t & = & \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2 \\ \nonumber 
    & & + \beta_1 \sigma^2_{t-1} + \beta_2 \sigma^2_{t-2} + \ldots + \beta_p \sigma^2_{t-p}
    (\#eq:GARCHEffect)
\end{eqnarray}

Donde las condiciones de no negatividad son que $\gamma_0 > 0$, $\gamma_i \geq 0$, $i = 1, 2, \ldots, q-1$, $\beta_j \geq 0$, $j = 1, 2, \ldots, p-1$, $\gamma_q > 0$ y $\beta_p > 0$. Además, otra condición de convergencia es que:
\begin{equation*}
    \gamma_1 + \ldots + \gamma_q + \beta_1 + \ldots + \beta_p < 1
\end{equation*}

Usando el operador rezago $L$ en la ecuación \@ref(eq:GARCHEffect) podemos obtener:
\begin{equation}
    \sigma^2_t = \gamma_0 + \alpha(L) U_t^2 + \beta(L) \sigma^2_t
    (\#eq:GARCHEffectL)
\end{equation}

De donde podemos establecer:
\begin{equation}
    \sigma^2_t = \frac{\gamma_0}{1 - \beta(L)} + \frac{\alpha(L)}{1 - \beta(L)} U_t^2 
\end{equation}

Por lo que la ecuación \@ref(eq:GARCHEffect) del GARCH(p, q) representa un ARCH($\infty$):
\begin{equation}
    \sigma^2_t = \frac{a_0}{1 - b_1 - b_2 - \ldots - b_p} + \sum_{i = 1}^\infty U_{t-i}^2 
\end{equation}

### Ejemplo ARCH(1) 

Hasta ahora, las distribuciones utilizadas para medir el Valor en Riesgo de un activo (Bitcoin, en este caso) asumen que no existe correlación serial en los retornos diarios del activo. Observemos un par de gráficas de la función de autocorrelación para corroborar este hecho--ver la Figura \@ref(fig:fig105)--. 

```{r fig105, fig.cap = "Función de autocorrelación parcial de lo rendimientos del Bitcoin", fig.align='center', message=FALSE, warning=TRUE}

acf(logret)

```

La idea de clusterización de volatilidad asume que períodos de alta volatilidad serán seguidos por alta volatilidad y viceversa. Por esta razón, la función de autocorrelación útil para saber si existen clústers de volatilidad es utilizando el valor absoluto, ya que lo que importa es saber si la serie está autocorrelacionada en la magnitud de los movimientos. La Figura \@ref(fig:fig106) muestra el comportamiento de los rendimientos en valor absoluto y la Figura \@ref(fig:fig107) la función de autocorrelación parcial.

```{r fig106, fig.cap = "Evolución de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=TRUE}

plot(abs(logret))

```

```{r fig107, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=TRUE}

acf(abs(logret))

```

Otra manera de corroborar esta idea es volviendo IID nuestra serie de datos y observar que de este modo se pierde la autocorrelación serial, lo que refuerza la idea de que en esta serie existen clusters de volatilidad. 

```{r fig108, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=FALSE}

logret_random <- sample(as.vector(logret), size =  length(logret), replace = FALSE)

acf(abs(logret_random))

```

```{r fig109, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=FALSE}

par(mfrow = c(1,2))
plot(logret)
plot(logret_random, type = 'l')

```

Ahora busquemos una prueba formal. El primer enfoque para comprobar aceptar o rechazar la hipótesis de que necesitamos estimar un ARCH(q) es realizar una prueba de efectos ARCH. De acuerdo con esta, nuestros datos de Bitcoin muestran que se rechaza la hipótesis de no efectos ARCH. Esta prueba resulta del siguiente código de R:

```{r ArchTest}
logret_mean = dynlm(logret~1)

summary(logret_mean)

ehatsq = ts(resid(logret_mean)^2)

ARCH_m = dynlm(ehatsq~L(ehatsq))

summary(ARCH_m)


acf(ARCH_m$residuals)
acf(abs(ARCH_m$residuals))

ArchTest(logret, lags = 1, demean = TRUE)
```

La prueba puede repetirse para diferentes especificaciones de ARCH, sin embargo, para efectos ilustrativos usaremos un ARCH(1). Estimemos un ARCH(1), considerando la siguente especificación:

\begin{eqnarray*}
    Y_t & = & \mu+\sqrt{h_t}\varepsilon_t \\
    h_t & = & \omega+\alpha_ih_{t-i}+u_t \\
    \varepsilon & \sim & N(0,1)
\end{eqnarray*}

Considerando que la media es una AR(2), los resultados de esta estimación son los siguientes:

Table: (\#tab:arima-summary) Resumen de la estimación ARIMA(2,0,0) con media distinta de cero (y posible componente GARCH) _\( \sigma^2 = 0.001324, \ \text{log-likelihood} = 7170.99,\ \text{AIC}=-14333.99,\ \text{AICc}=-14333.97,\ \text{BIC}=-14309.03 \)_  

| **Parameter** | **Estimate**    | **Std. Error**   | **t value**   | **Pr(\(>\mid t\mid\))** |
|:--------------|-----------------:|-----------------:|--------------:|------------------------:|
| mu            |  0.001642394    | 0.0003553101     |  4.622424     |  3.792818e-06          |
| ar1           | -0.051859993    | 0.0160262284     | -3.235945     |  1.212408e-03          |
| ar2           | -0.001225748    | 0.0132050756     | -0.092824     |  9.260434e-01          |
| omega         |  0.001956396    | 0.0004839458     |  4.042593     |  5.286335e-05          |
| alpha1        |  0.730450078    | 0.2140120509     |  3.413126     |  6.422226e-04          |
| shape         |  2.347586356    | 0.1135148037     | 20.680883     |  0.000000e+00          |

---

**Notas**:

1. **Primera línea** en **negrita** como título de la tabla (Markdown no tiene un `\caption{}` como LaTeX).  
2. Bajo el título, se añade un párrafo en _itálicas_ con los valores adicionales (\(\sigma^2\), log-likelihood, AIC, etc.).  
3. La fila de encabezados va seguida por una fila de separadores (`|:---|---:|` etc.) para indicar la **alineación** a la izquierda, derecha o centro.  
4. Las celdas con datos numéricos se alinean a la **derecha** (`:---:` o `---:`) para mantener la estética de los números.  
5. Si prefieres, puedes omitir la columna de “**Notas**” y añadir la información directamente en el título de la tabla o en un párrafo posterior.

```{r ARCH_1}

library(rugarch)

auto.arima(logret)

#?ugarchspec

model.spec = ugarchspec( variance.model = list(model = 'sGARCH' , 
                                               garchOrder = c(1, 0)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")

#?ugarchfit

arch.fit = ugarchfit(spec = model.spec , data = logret, 
                     solver = 'solnp')

arch.fit@fit$matcoef

boot.garch <- ugarchboot(arch.fit,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")

boot.garch

```

## Ejemplo GARCH(0,1)

Estimemos un GARCH(0,1) usando la siguiente especificación:
\begin{eqnarray*}
Y_t & = & \mu+\sqrt{h_t}\varepsilon_t \\
    h_t & = & \omega+\beta_i \sigma^2_{t-i}+u_t \\
    \varepsilon & \sim & N(0,1) 
\end{eqnarray*}

Considerando que la media es una AR(2), los resultados de esta estimación son los siguientes:

Table: (\#tab:estimaciones) Resumen de estimaciones del modelo GARCH(0,1)

| Parameter | Estimate     | Std. Error    | t value     | Pr(>\|t\|)      |
|:----------|------------:|-------------:|-----------:|---------------:|
| mu        | 1.743510e-03 | 3.728562e-04 |  4.6760931 | 2.923919e-06   |
| ar1       | -6.104183e-02 | 1.366530e-02 | -4.4669219 | 7.935308e-06   |
| ar2       | -4.231427e-03 | 1.311300e-02 | -0.3226895 | 7.469304e-01   |
| omega     | 3.843436e-06  | 6.414905e-08 | 59.9141495 | 0.000000e+00   |
| beta1     | 9.981016e-01  | 3.215075e-05 | 31044.4303 | 0.000000e+00   |
| shape     | 2.515980e+00  | 2.796609e-02 | 89.9653552 | 0.000000e+00   |

```{r GARCH_0_1}
model.spec = ugarchspec(variance.model = list(model = 'sGARCH' , 
                                              garchOrder = c(0,1)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")

fit.garch.n = ugarchfit(spec = model.spec, data = logret, 
                        solver = "solnp")

fit.garch.n@fit$matcoef

boot.garch <- ugarchboot(fit.garch.n,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")
boot.garch

```

### Selección GARCH(p,q) óptimo

¿Cómo seleccionamos el órden adecuado para un GARCH(p,q)? Acá una respuesta.

$Y_t = \mu+\sqrt{h_t}\varepsilon_t$

$h_t = \omega+\beta_ih_{t-i}+\alpha_i\varepsilon^2_{t-i}+u_t$

$\varepsilon \sim N(0,1)$

#### Criterios de información 

Table: (\#tab:info-criteria) Comparación de criterios de información.

| **Criterio**   | **Valor**   |
|:---------------|------------:|
| Akaike         | -4.083927   |
| Bayes          | -4.074035   |
| Shibata        | -4.083932   |
| Hannan-Quinn   | -4.080410   |


```{r AIC_GARCH}

infocriteria(fit.garch.n)

```

#### Selección del modelo óptimo

Podemos hacer una búsqueda del mejor modelo de entre varios que probemos en un espectro de hasta un GARCH(4,4). Los resultados son los reportados en el siguiente Cuadro.

Table: (\#tab:criterios) Resumen de criterios de información en función de \texttt{p} y \texttt{q} de un GARCH(p,q).

| **q** | **p** | **AIC**     | **Óptimo** |
|-----:|-----:|-----------:|-----------:|
| 1 | 1 | -10.93647 | 0 |
| 1 | 2 | -10.93657 | 0 |
| 1 | 3 | -10.93799 | 0 |
| 1 | 4 | -10.93727 | 0 |
| 2 | 1 | -10.93579 | 0 |
| 2 | 2 | -10.93607 | 0 |
| 2 | 3 | -10.93743 | 0 |
| 2 | 4 | -10.93510 | 0 |
| 3 | 1 | -10.93524 | 0 |
| 3 | 2 | -10.93510 | 0 |
| 3 | 3 | -10.93765 | 0 |
| 3 | 4 | -10.93645 | 0 |
| 4 | 1 | -10.93840 | 0 |
| 4 | 2 | -10.93935 | 1 |
| 4 | 3 | -10.93924 | 0 |
| 4 | 4 | -10.93816 | 0 |

```{r LagOptGARCH}

source("Lag_Opt_GARCH.R")

Lag_Opt_GARCH(ehatsq,4,4)

```

#### Estimación de modelo óptimo 

De esta forma, el modelo óptimo es un GARCH(2,4). Los resultados de la estimación son los del Cuadro

Table: (\#tab:garch-estimates) Resumen de estimaciones del modelo (parámetros, errores estándar, estadísticos t y p-values).

| **Parameter** | **Estimate**   | **Std. Error**  | **t value**    | **Pr(>\|t\|)**  |
|:-------------|---------------:|----------------:|---------------:|----------------:|
| mu      | 1.353612e-03  | 3.233488e-04  |  4.186229e+00 | 2.836277e-05  |
| ar1     | -4.916331e-02 | 1.495855e-02  | -3.286636e+00 | 1.013919e-03  |
| ar2     | 7.273432e-04  | 1.385161e-02  |  5.250964e-02 | 9.581226e-01  |
| omega   | 2.759072e-05  | 5.151381e-06  |  5.355984e+00 | 8.509188e-08  |
| alpha1  | 1.290996e-01  | 2.165606e-02  |  5.961363e+00 | 2.501419e-09  |
| alpha2  | 1.768468e-07  | 3.676320e-02  |  4.810430e-06 | 9.999962e-01  |
| alpha3  | 6.424436e-08  | 2.663630e-02  |  2.411910e-06 | 9.999981e-01  |
| alpha4  | 3.333343e-02  | 2.238762e-02  |  1.488923e+00 | 1.365077e-01  |
| beta1   | 4.260058e-01  | 2.263614e-01  |  1.881972e+00 | 5.983983e-02  |
| beta2   | 4.105609e-01  | 1.819274e-01  |  2.256730e+00 | 2.402498e-02  |
| shape   | 3.183045e+00  | 1.305307e-01  |  2.438541e+01 | 0.000000e+00  |

```{r}

model.spec = ugarchspec(variance.model = list(model = 'sGARCH', 
                                              garchOrder = c(4,2)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")


model.fit = ugarchfit(spec = model.spec , data = logret, 
                      solver = 'solnp')

model.fit@fit$matcoef


boot.garch <- ugarchboot(model.fit,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")

boot.garch

```

#### Forecasting with GARCH(1,1)

Para realizar pronósticos con la estimación de un GARCH, utilizando la librería _rugarch_, es necesario utilizar la función __ugarchforecast()__. 

```{r}
model.spec = ugarchspec(variance.model = list(model = 'sGARCH', 
                                              garchOrder = c(1,1)), 
                        mean.model = list(armaOrder = c(4,2)), 
                        distribution.model = "std")

model.fit = ugarchfit(spec = model.spec , data = logret, 
                      solver = 'solnp')

spec = getspec(model.fit)

setfixed(spec) <- as.list(coef(model.fit))
```

Esta función precisa como argumentos nuestra estimación del modelo GARCH, con una modificación en la manera en que se presentan los coeficientes, realizada en la última línea del código anterior y que llamamos _spec_. _n.ahead_ es el número de periodos que vamos a pronosticar, _n.roll_ señala el número de pronósticos móviles que utilizaremos, en caso de que haya más información para realizar el pronóstico. Finalmente damos como input nuestro set de datos y como producto obtendremos el pronostico de Sigma tanto como de la serie.

```{r}
forecast = ugarchforecast(spec, n.ahead = 12, n.roll = 0, logret)

sigma(forecast)

fitted(forecast)

forecast
```

## Modelos ARCH y GARCH Multivariados

De forma similar a los modelos univariados, los modelos multivariados de heterocedasticidad condicional asumen una estructura de la media condicional. En este caso, descrita por un VAR(p) cuyo proceso estocástico $\mathbf{X}$ es estacionario de dimensión $k$. De esta forma, la expresión reducida del modelo o el proceso VAR(p) estará dado por:
\begin{equation}
    \mathbf{X}_t = \boldsymbol{\delta} + \mathbf{A_1} \mathbf{X}_{t-1} + \mathbf{A_2} \mathbf{X}_{t-2} + \ldots + \mathbf{A_p} \mathbf{X}_{t-p} + \mathbf{U}_{t}
\end{equation}

Donde cada uno de las $\mathbf{A_i}$, $i = 1, 2, \ldots, p$, son matrices cuadradas de dimensión $k$ y $\mathbf{U}_t$ representa un vector de dimensión $k \times 1$ con los residuales en el momento del tiempo $t$ que son un proceso puramente aleatorio. También se incorpora un vector de términos constantes denominado como $\boldsymbol{\delta}$, el cual es de dimensión $k \times 1$ --en este caso también es posible incorporar procesos determinísticos adicionales--.

Así, suponemos que el término de error tendrá estructura de vector:
\begin{equation*}
    \mathbf{U}_t = 
    \begin{bmatrix}
    U_{1t} \\ U_{2t} \\ \vdots \\ U_{Kt}
    \end{bmatrix}
\end{equation*}

De forma que diremos que:
\begin{equation*}
    \mathbf{U}_t | \Omega_{t-1} \sim (0, \Sigma_{t | t-1})
\end{equation*}

Dicho lo anterior, entonces, el modelo ARCH(q) multivariado será descrito por:
\begin{equation}
    Vech(\Sigma_{t | t-1}) = \boldsymbol{\gamma}_0 + \Gamma_1 Vech(\mathbf{U}_{t-1} \mathbf{U}_{t-1}') + \ldots + \Gamma_q Vech(\mathbf{U}_{t-q} \mathbf{U}_{t-q}')
    (\#eq:M_ARCH)
\end{equation}

Donde $Vech$ es un operador que apila en un vector la parte superior de la matriz a la cual se le aplique, $\boldsymbol{\gamma}_0$ es un vector de constantes, $\Gamma_i$, $i = 1, 2, \ldots$ son matrices de coeficientes asociados a la estimación.

Para ilustrar la ecuación \@ref(eq:M_ARCH), tomemos un ejemplo de $K = 2$, de esta forma tenemos que un M-ARCH(1) será:
\begin{equation*}
    \Sigma_{t | t-1} = 
    \begin{bmatrix}
    \sigma^2_{1, t | t-1} & \sigma_{12, t | t-1} \\ \sigma_{21, t | t-1} & \sigma^2_{2, t | t-1}
    \end{bmatrix} = 
    \begin{bmatrix}
    \sigma_{11, t} & \sigma_{12, t} \\ \sigma_{21, t} & \sigma_{22, t}
    \end{bmatrix} =
    \Sigma_{t}
\end{equation*}

Donde hemos simplificado la notación de las varianzas y la condición de que están en función de $t-1$. Así,
\begin{equation*}
    Vech(\Sigma_{t}) = 
    Vech \begin{bmatrix}
    \sigma_{11, t} & \sigma_{12, t} \\ \sigma_{21, t} & \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix}
\end{equation*}

De esta forma, podemos establecer el modelo M-ARCH(1) con $K = 2$ será de la forma:
\begin{equation*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & \gamma_{12} & \gamma_{13} \\ \gamma_{21} & \gamma_{22} & \gamma_{23} \\ \gamma_{31} & \gamma_{32} & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix}
\end{equation*}

Como notarán, este tipo de procedimientos implica la estimación de muchos parámetros. En esta circunstancia, se suelen estimar modelos restringidos para reducir el número de coeficientes estimados. Por ejemplo, podríamos querer estimar un caso como:
\begin{equation*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & 0 & 0 \\ 0 & \gamma_{22} & 0 \\ 0 & 0 & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix}
\end{equation*}

Finalmente y de forma análoga al caso univariado, podemos plantear un modelo M-GARCH(p, q) como:
\begin{equation}
    Vech(\Sigma_{t | t-1}) = \boldsymbol{\gamma}_0 + \sum_{j = 1}^q \Gamma_j Vech(\mathbf{U}_{t-j} \mathbf{U}_{t-j}') + \sum_{m = 1}^p \mathbf{G}_m Vech(\Sigma_{t-m | t-m-1})
    \label{M_GARCH}
\end{equation}

Donde cada una de las $\mathbf{G}_m$ es una matriz de coeficientes. Para ilustrar este caso, retomemos el ejemplo anterior, pero ahora para un modelo M-GARCH(1, 1) con $K = 2$ de forma que tendríamos:
\begin{eqnarray*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} & = &
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & \gamma_{12} & \gamma_{13} \\ \gamma_{21} & \gamma_{22} & \gamma_{23} \\ \gamma_{31} & \gamma_{32} & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix} \\
    & & + 
    \begin{bmatrix}
    g_{11} & g_{12} & g_{13} \\ g_{21} & g_{22} & g_{23} \\ g_{31} & g_{32} & g_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    \sigma_{11, t-1} \\ \sigma_{12, t-1} \\ \sigma_{22, t-1}
    \end{bmatrix}
\end{eqnarray*}

## Pruebas para detectar efectos ARCH

La prueba que mostraremos es conocida como una ARCH-LM, la cual está basada en una regresión de los residuales estimados de un modelo VAR(p) o cualquier otra estimación que deseemos probar, con el objeto de determinar si existen efectos ARCH --esta prueba se puede simplificar para el caso univariado--.

Partamos de plantear:
\begin{eqnarray}
    Vech(\hat{\mathbf{U}}_t \hat{\mathbf{U}}_t') & = & \mathbf{B}_0 + \mathbf{B}_1 Vech(\hat{\mathbf{U}}_{t-1} \hat{\mathbf{U}}_{t-1}') + \ldots \\ \nonumber
    & & + \mathbf{B}_q Vech(\hat{\mathbf{U}}_{t-q} \hat{\mathbf{U}}_{t-q}') + \varepsilon_t
    (\#eq:ARCH-LM)
\end{eqnarray}

Dada la estimación en la ecuación \@ref(eq:ARCH-LM), plantearemos la estructura de hipótesis dada por:
\begin{eqnarray*}
    H_0 & : & \mathbf{B}_1 = \mathbf{B}_2 = \ldots = \mathbf{B}_q = 0 \\
    H_a & : & No H_0    
\end{eqnarray*}

La estadística de prueba será determinada por:
\begin{equation}
    LM_{M-ARCH} = \frac{1}{2} T K (K + 1) - Traza \left( \hat{\Sigma}_{ARCH} \hat{\Sigma}^{-1}_{0} \right) \sim \chi^2_{[q K^2 (K + 1)^2 / 4]}
\end{equation}

Donde la matriz $\hat{\Sigma}_{ARCH}$ se calcula de acuerdo con la ecuación \@ref(eq:ARCH-LM) y la matriz $\hat{\Sigma}_{0}$ sin considerar una estructura dada para los errores.
